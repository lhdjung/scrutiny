[{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement jung-lukas@gmx.net. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://lhdjung.github.io/scrutiny/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://lhdjung.github.io/scrutiny/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Implementing consistency tests","text":"implementing consistency tests R, shouldn’t start zero. vignette introduces scrutiny’s support system writing new consistency testing functions. Following vignette dramatically simplify implementation basic advanced testing routines via function factories. enable write entire families functions streamlined way: familiar one scrutiny-style consistency test, immediately able make sense ones. true across levels consistency testing. outline levels, present vignette, GRIM paradigmatic example. valid consistency test newly implemented least first step, ’ll happy accept pull request scrutiny. means ’ll implement core test , without even reading vignette . bare-bones, non-exported (!) function testing single set cases, grim_scalar(). vectorized version single-case function, grim(). specialized mapping function applies single-case function data frame, grim_map(). method audit() generic summarizes results number 3. visualization function plots results number 3, grim_plot(). mapping function checks slightly varied input values consistent respective reported values, grim_map_seq(). mapping function used total sample size reported (study two groups), individual group sizes, grim_map_total_n(). audit_seq() audit_total_n() already work output numbers 6 7, respectively. still specifically documented. use toy test called SCHLIM model demonstrate minimal steps needed implement consistency tests, scrutiny-style. Note SCHLIM doesn’t significance beyond standing serious consistency tests. real implementation might well complex brief code snippets . also recur existing functions implement actual tests, reader may familiar . Please make sure follow tidyverse style guide well scrutiny-specific conventions laid , wherever applicable. ’d like write new package, work Hadley Wickham’s book R Packages (Wickham 2015) recent version, free online.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"single-case","dir":"Articles","previous_headings":"","what":"1. Single-case","title":"Implementing consistency tests","text":"first function important one. contains core implementation test. Although exported , steps build , exported. function takes two arguments length 1 meant tested consistency . Typically, coercible numeric. means either numeric strings can converted numbers. function returns Boolean value length 1: ’s TRUE inputs mutually consistent, FALSE aren’t. arguments might still necessary, especially function reconstructs rounded numbers. argument determines function round numbers called rounding. function internally call reround(). goes “unrounding” (.e., reconstructing rounding bounds) unround(). See also vignette(\"rounding\"). single-case function performs rounding also need helper count decimal places, decimal_places_scalar(). function’s name test lowercase, followed _scalar refers one-case limit. function happens applicable multiple value sets already due R’s natural vectorization, leave _scalar skip next section. ’re building package, export function. (rarely case every single argument needs vectorized.)","code":"schlim_scalar <- function(y, n) {    y <- as.numeric(y)    n <- as.numeric(n)    all(y / 3 > n)  }  schlim_scalar(y = 30, n = 4) #> [1] TRUE schlim_scalar(y = 2, n = 7) #> [1] FALSE"},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"vectorized","dir":"Articles","previous_headings":"","what":"2. Vectorized","title":"Implementing consistency tests","text":"easiest way turn scalar function vectorized (.e., multiple-case) function run Vectorize() . name resulting function lower-case name test , also name single-case function without _scalar: Functions created way can useful quick testing, won’t used remaining part vignette. ’s functions like schlim() great build upon — unlike mapper functions, discussed next.","code":"schlim <- Vectorize(schlim_scalar)  schlim(y = 10:15, n = 4) #> [1] FALSE FALSE FALSE  TRUE  TRUE  TRUE"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"introduction-1","dir":"Articles","previous_headings":"3. Basic mapper","what":"Introduction","title":"Implementing consistency tests","text":"important practical use consistency test within scrutiny apply entire data frames , grim_map() . ’s also starting point every function . functions discussed remaining part vignette deal data frames. always use tibbles, strongly recommend . ’s guarantee functions works non-tibble data frames tibbles.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"creating-basic-mappers-with-function_map","dir":"Articles","previous_headings":"3. Basic mapper","what":"Creating basic mappers with function_map()","title":"Implementing consistency tests","text":"safest easiest way create (basic) mapper via function_map(). function written way also guaranteed fulfill requirements mapper functions listed . ’s major benefit list requirements long, follow-functions remaining vignette assume mapper fulfills . troubles function_map(): important arguments: .fun single-case function section 1. .reported string vector naming reported statistics .fun tests consistency . need arguments .fun, .fun may arguments, well. .name_test simply names consistency test.","code":"schlim_map <- function_map(   .fun = schlim_scalar,   .reported = c(\"y\", \"n\"),   .name_test = \"SCHLIM\" )  # Example data: df1 <- tibble::tibble(y = 16:25, n = 3:12)  schlim_map(df1) #> # A tibble: 10 × 3 #>        y     n consistency #>    <int> <int> <lgl>       #>  1    16     3 TRUE        #>  2    17     4 TRUE        #>  3    18     5 TRUE        #>  4    19     6 TRUE        #>  5    20     7 FALSE       #>  6    21     8 FALSE       #>  7    22     9 FALSE       #>  8    23    10 FALSE       #>  9    24    11 FALSE       #> 10    25    12 FALSE"},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"context-and-export","dir":"Articles","previous_headings":"3. Basic mapper > Creating basic mappers with function_map()","what":"Context and export","title":"Implementing consistency tests","text":"can see, function_map() helper used inside functions creating function() — instead, takes place function() . makes -called function factory, precisely, function operator, .k.. decorator (Wickham 2019, ch. 10-11). already met base::Vectorize() section 2, also function operator, general straightforward one. export function manufactured way package, make sure follow purrr FAQ. (Incredible sounds, scrutiny take role purrr.) version look like :","code":"schlim_map <- function(...) \"dummy\"  .onLoad <- function(lib, pkg) {   schlim_map <<- scrutiny::function_map(     .fun = schlim_scalar,     .reported = c(\"y\", \"n\"),     .name_test = \"SCHLIM\"   ) }"},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"identifying-columns","dir":"Articles","previous_headings":"3. Basic mapper > Creating basic mappers with function_map()","what":"Identifying columns","title":"Implementing consistency tests","text":"factory-made functions come special convenience feature: .reported values inserted list function’s parameters. means don’t need data frame column names .reported values. Instead, can specify arguments names names actual columns: columns neither present data frame identified via arguments, precise error:","code":"df2 <- df1 names(df2) <- c(\"foo\", \"bar\")  df2 #> # A tibble: 10 × 2 #>      foo   bar #>    <int> <int> #>  1    16     3 #>  2    17     4 #>  3    18     5 #>  4    19     6 #>  5    20     7 #>  6    21     8 #>  7    22     9 #>  8    23    10 #>  9    24    11 #> 10    25    12  schlim_map(df2, y = foo, n = bar) #> # A tibble: 10 × 3 #>        y     n consistency #>    <int> <int> <lgl>       #>  1    16     3 TRUE        #>  2    17     4 TRUE        #>  3    18     5 TRUE        #>  4    19     6 TRUE        #>  5    20     7 FALSE       #>  6    21     8 FALSE       #>  7    22     9 FALSE       #>  8    23    10 FALSE       #>  9    24    11 FALSE       #> 10    25    12 FALSE schlim_map(df2, y = foo) #> Error in `check_factory_key_args_names()` at scrutiny/R/function-factory-helpers.R:274:2: #> ! Column `n` is missing from `data`. #> ✖ It should be a column of the input data frame. #> ℹ Alternatively, specify the `n` argument of `absorb_key_args()` as the name of #>   the equivalent column.  # With a wrong identification: schlim_map(df2, n = mike) #> Error in `check_factory_key_args_values()` at scrutiny/R/function-factory-helpers.R:273:2: #> ! `mike` is not a column name of `data`. #> ✖ The `n` argument of `absorb_key_args()` was specified as `mike`, but there is #>   no column in `data` called `mike`."},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"drawbacks","dir":"Articles","previous_headings":"3. Basic mapper > Creating basic mappers with function_map()","what":"Drawbacks","title":"Implementing consistency tests","text":"function_map() helpful, ever use ? four reasons: Functions produced function_map() don’t tailor-made checks, messages, transformations specific consistency test. (general checks error messages.) limited capabilities create columns internally \"consistency\": Values columns need produced basic *_scalar() function. (might replace tailor-made functionality creating reason column output handwritten grimmer_map(), currently experimental.) don’t support helper columns (see Terminology ). Finally, calling manufactured function, test-specific arguments user might specify via … (dots) won’t trigger RStudio’s autocomplete. dangerous functions use dots , calling function produced function_map(), misspelled argument names always throw error. grim_map(), grimmer_map(), debit_map() “handwritten” flexibility columns beyond \"consistency\". example, show_rec argument grim_map() ratio column function’s output possible function_map(). However, issues don’t affect \"consistency\" results, simply going function_map() might often better option. ’s choose , skip right section 4.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"introduction-2","dir":"Articles","previous_headings":"3. Basic mapper > Writing mappers manually","what":"Introduction","title":"Implementing consistency tests","text":"remaining part section 3 explains manually write mapper functions like grim_map(), grimmer_map(), debit_map(). quite detailed ’s important get things right: Every function rest vignette builds . Still, practical steps complicated, can see code examples.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"terminology","dir":"Articles","previous_headings":"3. Basic mapper > Writing mappers manually","what":"Terminology","title":"Implementing consistency tests","text":"’s important distinguish key arguments columns arguments columns. key arguments scalar vectorized consistency-testing function values tested consistency , x n grim(). extension, key columns contain values. Every key column name respective key argument. helper column column key , still factors consistency test. example optional items column grim_map()’s input data frame: transforms n column, turn affects test outcomes. However, helper columns need work via key columns. Key helper columns tested columns factor test. columns non-tested.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"requirements","dir":"Articles","previous_headings":"3. Basic mapper > Writing mappers manually","what":"Requirements","title":"Implementing consistency tests","text":"general system implementing consistency tests needs consistency . especially true basic mapper functions, functions line rely mapper’s output specific properties. level detail requirements might seem pedantic. still encourage follow every step handwriting new mapping function. ’s easier looks first, many aspects indispensable. interplay mapper higher-level functions follows carefully concerted system. mapper misses one ingredient, functions may fail. () requirements basic mapping function : name ends _map instead _scalar otherwise name respective _scalar function. first argument, data, data frame contains key columns respective consistency test. columns permitted. mapper’s user never needs include helper columns can always replace specifying arguments names columns. user specifies argument input data frame contains column name, function throws error. column input data frame named \"consistency\". return value tibble data frame contains key input columns. types columns input data frame. first (.e., leftmost) columns output, even input isn’t ordered way. columns modified within mapping function, output include modified columns, original ones. Examples can effects helper columns, also change displayed \"x\" column output grim_map(percent = TRUE). output must test TRUE is_map_df() is_map_basic_df(), FALSE two is_map_*() functions. Helper columns included output unless transform one key columns. case, representing output confusing effects already played via transformed key column(s). every helper column performs transformations, mapper Boolean argument, TRUE default, determines whether helper column transforms key column(s). TRUE, helper column included output . FALSE, helper column included transformation takes place. name Boolean argument start merge_, followed name helper column question. example optional items column grim_map()’s input data frame, together function’s items merge_items arguments. work helper columns, call manage_helper_col() within mapper. output data frame also includes Boolean column named \"consistency\". contains results consistency test, determined respective *_scalar() function. row, \"consistency\" TRUE values left mutually consistent, FALSE aren’t. column placed immediately right group key (, potentially, helper) columns. underlying single-case function performs rounding unrounding, internally call reround() /unround(), respectively. output data frame mapper function inherit S3 class (see section S3 classes ) \"scr_rounding_up_or_down\": consists \"scr_rounding_\" followed rounding specification, e.g., \"up_or_down\". latter also default rounding unrounding specification. specification can supplied user via argument called rounding, passed single-case function. reround() called within mapper, arguments need passed mapper, arguments, defaults. applies unround(). output data frame inherits S3 class starts \"scr_\" (short scrutiny), followed name mapper function. example, output grim_map() inherits \"scr_grim_map\" class. \"scr_\" prefix necessary follow-computations introduced , used even within functions part scrutiny. classes added output data frame also start \"scr_\". None end \"_map\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"implications","dir":"Articles","previous_headings":"3. Basic mapper > Writing mappers manually","what":"Implications","title":"Implementing consistency tests","text":"implications requirements, fact design space mapper functions restricted ways: Anything factors consistency test tested columns needs conveyed mapper function via arguments. example rounding argument grim_map(). Mapper functions don’t need allow helper columns. input data frame necessarily tibble, output data frame . input data frame never contains column named \"consistency\", output data frame always . Key columns may may modified helper columns /arguments. number key columns doesn’t change input output data frames. output data frame may may contain non-tested columns input. may may contain non-tested columns created within mapper function . (can useful, \"ratio\" grim_map()’s output.) non-tested, non-\"consistency\" columns go right \"consistency\". number key columns plus number helper columns output \\(k\\), index \"consistency\" \\(k+1\\). Besides \"scr_*_map\" class, output data frame may inherit number classes added within mapper, long start \"scr_\" don’t end \"_map\". can’t inherit \"grouped_df\" \"rowwise_df\" classes added dplyr::group_by() dplyr::rowwise(), respectively. either functions called within mapper, needs followed dplyr::ungroup() point. columns input data frame organized like :  contrast, columns output data frame organized like :","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"practical-steps","dir":"Articles","previous_headings":"3. Basic mapper > Writing mappers manually","what":"Practical steps","title":"Implementing consistency tests","text":"actually write mapper functions? , recommend function_map(). functions created conceptually similar. Apply *_scalar() function input data frame using purrr::pmap_lgl(): Alternatively, call dplyr::rowwise() directly mutate \"consistency\": call check_mapper_input_colnames() required adds safety function. Also, see manage_key_colnames() grants user flexibility naming key columns. approaches lead results:","code":"schlim_map_alt1 <- function(data, ...) {   scrutiny::check_mapper_input_colnames(data, c(\"y\", \"n\"), \"SCHLIM\")   consistency <- purrr::pmap_lgl(data, schlim_scalar, ...)   out <- tibble::tibble(y = data$y, n = data$n, consistency)   out <- add_class(out, \"scr_schlim_map\")  # See section \"S3 classes\" below   out } schlim_map_alt2 <- function(data, ...) {   scrutiny::check_mapper_input_colnames(data, c(\"y\", \"n\"), \"SCHLIM\")   data %>%      dplyr::rowwise() %>%      dplyr::mutate(consistency = schlim_scalar(y, n, ...)) %>%      dplyr::ungroup() %>%      dplyr::relocate(y, n, consistency) %>%      add_class(\"scr_schlim_map\")  # See section \"S3 classes\" below } schlim_map_alt1(df1) #> # A tibble: 10 × 3 #>        y     n consistency #>    <int> <int> <lgl>       #>  1    16     3 TRUE        #>  2    17     4 TRUE        #>  3    18     5 TRUE        #>  4    19     6 TRUE        #>  5    20     7 FALSE       #>  6    21     8 FALSE       #>  7    22     9 FALSE       #>  8    23    10 FALSE       #>  9    24    11 FALSE       #> 10    25    12 FALSE  schlim_map_alt2(df1) #> # A tibble: 10 × 3 #>        y     n consistency #>    <int> <int> <lgl>       #>  1    16     3 TRUE        #>  2    17     4 TRUE        #>  3    18     5 TRUE        #>  4    19     6 TRUE        #>  5    20     7 FALSE       #>  6    21     8 FALSE       #>  7    22     9 FALSE       #>  8    23    10 FALSE       #>  9    24    11 FALSE       #> 10    25    12 FALSE"},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"testing","dir":"Articles","previous_headings":"3. Basic mapper > Writing mappers manually","what":"Testing","title":"Implementing consistency tests","text":"let function_map() produce equivalent function make sure returns output handwritten one. compare two output data frames, don’t just eyeball . Use waldo::compare() , already run tests testthat, expect_equal(). handwritten mapper creates new columns beyond \"consistency\", ’ll remove output first. Don’t use helper columns testing function_map() can’t handle .","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"s3-classes","dir":"Articles","previous_headings":"3. Basic mapper > Writing mappers manually","what":"S3 classes","title":"Implementing consistency tests","text":"don’t know S3 classes , don’t worry. Just copy paste function , call end mapper function. x output data frame, new_class string vector. new_class consists one “classes” added existing classes x. can access classes object carries — “inherits” — calling class():","code":"add_class <- function(x, new_class) {   class(x) <- c(new_class, class(x))   x } some_object <- tibble::tibble(x = 5) some_object <- add_class(some_object, \"dummy class\") class(some_object) #> [1] \"dummy class\" \"tbl_df\"      \"tbl\"         \"data.frame\""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"internal-helpers","dir":"Articles","previous_headings":"3. Basic mapper > Writing mappers manually","what":"Internal helpers","title":"Implementing consistency tests","text":"Within scrutiny, many functions exported users internally call helper functions , add_class(). might writing function following design exported scrutiny function, suddenly can’t access unknown function seem need! ’d like employ internal helper , specify namespace three colons, like scrutiny:::add_class. However, use trick copy paste helper’s source code source code. (’s left parentheses — return function .) Never rely calling function :::, internals actually meant users. can easily shift vanish without notice. develop package, see blogpost Thomas Lin Pedersen information using internal code packages. particular, package developers mind licenses copying code scrutiny scrutiny GPL-3 licensed. directly looking internal helpers scrutiny’s source code, start utils.R file. helpers can found , every helper utils.R documented.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"introduction-3","dir":"Articles","previous_headings":"4. audit() method","what":"Introduction","title":"Implementing consistency tests","text":"audit() S3 generic summarizing scrutiny’s test result data frames, especially mapper functions grim_map(). always return descriptive statistics nothing else. Every mapper function corresponding audit() method. aspect object-oriented programming (OOP), scrutiny’s use OOP simple even low standards R. mapper function’s output already inherits specific class, \"scr_grim_map\", \"scr_grimmer_map\", \"scr_debit_map\". schlim_map(), added \"scr_schlim_map\" class addition existing classes:","code":"df1_tested <- schlim_map(df1) class(df1_tested) #> [1] \"scr_schlim_map\" \"tbl_df\"         \"tbl\"            \"data.frame\""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"basics","dir":"Articles","previous_headings":"4. audit() method > Introduction","what":"Basics","title":"Implementing consistency tests","text":"Every audit() method consistency test results insofar consistency tests . single argument named data. return value tibble least columns: incons_cases counts inconsistent cases, .e., number rows mapper’s output \"consistency\" FALSE. all_cases total number rows mapper’s output. incons_rate ratio incons_cases all_cases. Apart , see descriptive statistics audit() method compute. Means variables *_map() function’s output ratios might sensible choices. existing audit() methods consistency tests return tibbles single row . makes sense obvious grouping variable input data frame, lead multiple rows audit()’s output. However, might good reasons multiple rows summarizing results tests, requirement.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"practical-steps-1","dir":"Articles","previous_headings":"4. audit() method > Introduction","what":"Practical steps","title":"Implementing consistency tests","text":"audit() method simply function named audit plus dot specific class. Call audit_cols_minimal() within method create tibble three required columns. don’t use audit_cols_minimal(), call check_audit_special() method. can still add summary columns tibble returned audit_cols_minimal(). Use dplyr::mutate() similar.","code":"# The `name_test` argument is only for the alert # that might be issued by `check_audit_special()`: audit.scr_schlim_map <- function(data) {   audit_cols_minimal(data, name_test = \"SCHLIM\") }  # This calls our new method: audit(df1_tested) #> # A tibble: 1 × 3 #>   incons_cases all_cases incons_rate #>          <int>     <int>       <dbl> #> 1            6        10         0.6  # This doesn't work because no method was defined: audit(iris) #> Error in UseMethod(\"audit\"): no applicable method for 'audit' applied to an object of class \"data.frame\""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"documentation-template","dir":"Articles","previous_headings":"4. audit() method","what":"Documentation template","title":"Implementing consistency tests","text":"audit() method documented page respective mapper function. section called Summaries audit(). Create write_doc_audit(): function prepares roxygen2 block section. fills three standard columns , leaves space describe columns might . Also, internal checks write_doc_audit() make sure programmed correct audit() method, represented value sample_output argument. Copy output console paste roxygen2 block *_map() function. preserve numbered list structure indenting roxygen2 comments Ctrl+Shift+/, leave empty lines pasted output rest block.","code":"audit_grim    <- audit(grim_map(pigs1)) audit_grimmer <- audit(grimmer_map(pigs5))  write_doc_audit(sample_output = audit_grim,  name_test = \"GRIM\") #> #' @section Summaries with `audit()`: There is an S3 method for `audit()`, so  #> #'   you can call `audit()` following `grim_map()` to get a summary of  #> #'   `grim_map()`'s results. It is a tibble with a single row and these  #> #'   columns --  #> #'  #> #' 1. `incons_cases`: number of GRIM-inconsistent value sets. #> #' 2. `all_cases`: total number of value sets. #> #' 3. `incons_rate`: proportion of GRIM-inconsistent value sets. #> #' 4. `mean_grim_ratio`:  #> #' 5. `incons_to_ratio`:  #> #' 6. `testable_cases`:  #> #' 7. `testable_rate`:  write_doc_audit(sample_output = audit_grimmer, name_test = \"GRIMMER\") #> #' @section Summaries with `audit()`: There is an S3 method for `audit()`, so  #> #'   you can call `audit()` following `grimmer_map()` to get a summary of  #> #'   `grimmer_map()`'s results. It is a tibble with a single row and these  #> #'   columns --  #> #'  #> #' 1. `incons_cases`: number of GRIMMER-inconsistent value sets. #> #' 2. `all_cases`: total number of value sets. #> #' 3. `incons_rate`: proportion of GRIMMER-inconsistent value sets. #> #' 4. `fail_grim`:  #> #' 5. `fail_test1`:  #> #' 6. `fail_test2`:  #> #' 7. `fail_test3`:"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"introduction-4","dir":"Articles","previous_headings":"5. Visualization function","what":"Introduction","title":"Implementing consistency tests","text":"hard give general advice implement visualization functions results consistency tests. *_scalar() function, best way plot results greatly depends idiosyncratic nature consistency test . comparing looks grim_plot() debit_plot(), becomes clear two different things going . (mainly granularity crucial GRIM DEBIT.)","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"requirements-1","dir":"Articles","previous_headings":"5. Visualization function","what":"Requirements","title":"Implementing consistency tests","text":"Nevertheless, general requirements apply scrutiny-style visualization functions. much like arbitrary conventions requirements mapper functions, often meet precise technical needs. Visualization functions, however, basis computations apart modifications additional ggplot2 layers. result, rules admittedly somewhat less important. violate , nobody sad . visualization functions based ggplot2. follow developers’ general advice using ggplot2 packages. Visualization functions don’t need implement newly created layers, geoms themes. Indeed, neither two existing visualization functions relies new layers. visualization function’s name test (lowercase), followed _plot. Naturally, doesn’t apply methods generic functions like plot() ggplot2::autoplot(). first argument, data, data frame result call respective mapper function, grim_map() debit_map(). visualization function makes sure true checking data inherits special class added within mapper, \"scr_grim_map\" \"scr_debit_map\". data fails check, function throws error. function display consistent inconsistent value sets. color defaults \"royalblue1\" consistent value sets \"red\" inconsistent ones. user can override defaults via two arguments named color_cons consistent value sets color_incons inconsistent ones. certain layers optional rather essential plot, display can controlled via Boolean arguments start show_. Examples show_data grim_plot() show_outer_boxes debit_plot(). arguments kind start show_. defaults (usually TRUE, requirement).","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"introduction-5","dir":"Articles","previous_headings":"6. Sequence mapper","what":"Introduction","title":"Implementing consistency tests","text":"reported values inconsistent, ’s never obvious . Consistency tests provide mathematical certainty results, trade-: don’t suggest clear causal story summary statistics. (Contrast reconstruction technique SPRITE, aim mathematical proof point towards major issues origins data.) One possible reason inconsistencies lies small mistakes computing /reporting original researchers. Indeed, Brown Heathers (2017) reanalyzed data sets behind GRIM inconsistencies, often found “straightforward explanation, minor error reported sample sizes, failure report exclusion participant” (p. 368). may therefore useful test numeric neighborhood inconsistent reported values. nearby values consistent statistics? , many ? problem might due simple oversight. However, cumbersome test candidate value manually, even test sequences manually created functions seq_distance(). Fortunately, scrutiny semi-automates process. grim_map_seq(), grimmer_map_seq() debit_map_seq() provide instant assessment whether inconsistent reported values close consistent numbers. also allow user specify many steps away reported value permitted looking consistent ones, well options.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"practical-steps-2","dir":"Articles","previous_headings":"6. Sequence mapper","what":"Practical steps","title":"Implementing consistency tests","text":"Although code underlies fairly complex, functions written simple way. ones GRIM, GRIMMER, DEBIT: consistency test already implemented basic mapper function like grim_map(), grimmer_map(), debit_map() can receive *_map_seq() function just easily using function_map_seq(). due scrutiny’s streamlined design conventions — specifically, requirements mapper functions laid section 3. Let’s write sequence mapper SCHLIM: default, *_map_seq() function creates sequences around inconsistent input values. ’s primary purpose shed light inconsistencies reported statistics. Override default include_consistent = TRUE: function_map(), want export function produced function_map_seq(), follow purrr FAQ.","code":"grim_map_seq <- function_map_seq(   .fun = grim_map,   .reported = c(\"x\", \"n\"),   .name_test = \"GRIM\", )  grimmer_map_seq <- function_map_seq(   .fun = grimmer_map,   .reported = c(\"x\", \"sd\", \"n\"),   .name_test = \"GRIMMER\" )  debit_map_seq <- function_map_seq(   .fun = debit_map,   .reported = c(\"x\", \"sd\", \"n\"),   .name_test = \"DEBIT\", ) schlim_map_seq <- function_map_seq(   .fun = schlim_map,   .reported = c(\"y\", \"n\"),   .name_test = \"SCHLIM\" )  # Test dispersed sequences: out_seq <- schlim_map_seq(df1) out_seq #> # A tibble: 120 × 5 #>        y     n consistency  case var   #>    <int> <int> <lgl>       <int> <chr> #>  1    15     7 FALSE           1 y     #>  2    16     7 FALSE           1 y     #>  3    17     7 FALSE           1 y     #>  4    18     7 FALSE           1 y     #>  5    19     7 FALSE           1 y     #>  6    21     7 FALSE           1 y     #>  7    22     7 TRUE            1 y     #>  8    23     7 TRUE            1 y     #>  9    24     7 TRUE            1 y     #> 10    25     7 TRUE            1 y     #> # … with 110 more rows  # Summarize: audit_seq(out_seq) #> # A tibble: 6 × 12 #>       y     n consistency hits_total hits_y hits_n diff_y diff_…¹ diff_…² diff_n #>   <int> <int> <lgl>            <int>  <int>  <int>  <dbl>   <dbl>   <dbl>  <dbl> #> 1    20     7 FALSE                9      4      5      2       2      NA      1 #> 2    21     8 FALSE                6      2      4      4       4      NA      2 #> 3    22     9 FALSE                4      0      4     NA      NA      NA      2 #> 4    23    10 FALSE                3      0      3     NA      NA      NA      3 #> 5    24    11 FALSE                2      0      2     NA      NA      NA      4 #> 6    25    12 FALSE                2      0      2     NA      NA      NA      4 #> # … with 2 more variables: diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated #> #   variable names ¹​diff_y_up, ²​diff_y_down df1 %>%    schlim_map_seq(include_consistent = TRUE) %>%    audit_seq() #> # A tibble: 10 × 12 #>        y     n consistency hits_to…¹ hits_y hits_n diff_y diff_…² diff_…³ diff_n #>    <int> <int> <lgl>           <int>  <int>  <int>  <dbl>   <dbl>   <dbl>  <dbl> #>  1    16     3 TRUE               14     10      4      1       1      -1      0 #>  2    17     4 TRUE               13      9      4      1       1      -1      1 #>  3    18     5 TRUE               11      7      4      1       1      -1      0 #>  4    19     6 TRUE               10      5      5      1       1      NA      1 #>  5    20     7 FALSE               9      4      5      2       2      NA      1 #>  6    21     8 FALSE               6      2      4      4       4      NA      2 #>  7    22     9 FALSE               4      0      4     NA      NA      NA      2 #>  8    23    10 FALSE               3      0      3     NA      NA      NA      3 #>  9    24    11 FALSE               2      0      2     NA      NA      NA      4 #> 10    25    12 FALSE               2      0      2     NA      NA      NA      4 #> # … with 2 more variables: diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated #> #   variable names ¹​hits_total, ²​diff_y_up, ³​diff_y_down  # Compare with the original values: df1 #> # A tibble: 10 × 2 #>        y     n #>    <int> <int> #>  1    16     3 #>  2    17     4 #>  3    18     5 #>  4    19     6 #>  5    20     7 #>  6    21     8 #>  7    22     9 #>  8    23    10 #>  9    24    11 #> 10    25    12"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"introduction-6","dir":"Articles","previous_headings":"7. Total-n mapper","what":"Introduction","title":"Implementing consistency tests","text":"reporting summary statistics often insufficient — certainly error detection point view. particular, values means standard deviations always accompanied respective group sizes, total sample size. presents problem consistency tests rely reported group sizes, GRIM. requires splitting reported total groups creating multiple plausible scenarios group sizes add total. Although definitive test results can gained way, help see whether reported values consistent least plausible group sizes (Bauer Francis 2021).","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"practical-steps-3","dir":"Articles","previous_headings":"7. Total-n mapper","what":"Practical steps","title":"Implementing consistency tests","text":"function_map_total_n() creates new functions follow scheme applying given consistency test multiple combinations reported hypothetical summary statistics. powerhouse behind grim_map_total_n(), grimmer_map_total_n(), debit_map_total_n(), just function_map_seq() powerhouse behind grim_map_seq(), grimmer_map_seq(), debit_map_seq(). See case study vignette(\"grim\") , section Handling unknown group sizes grim_map_total_n(), example grim_map_total_n() works practice. function_map_seq(), creating manufactured *_total_n() function easy. Just let function factory work : drive point home, let’s SCHLIM: pattern can applied basic mapper function fulfills requirements section 3. One columns, n, values dispersed half, internally using disperse_total(). See advice exporting manufactured functions end section 6.","code":"grim_map_total_n <- function_map_total_n(   .fun = grim_map,   .reported = \"x\",  # don't include `n` here   .name_test = \"GRIM\" )  grimmer_map_total_n <- function_map_total_n(   .fun = grimmer_map,   .reported = c(\"x\", \"sd\"),  # don't include `n` here   .name_test = \"GRIMMER\" )  debit_map_total_n <- function_map_total_n(   .fun = debit_map,   .reported = c(\"x\", \"sd\"),  # don't include `n` here   .name_test = \"DEBIT\" ) schlim_map_total_n <- function_map_total_n(   .fun = schlim_map,   .reported = \"y\",   .name_test = \"SCHLIM\" )  # Example data: df_groups_schlim <- tibble::tribble(   ~y1, ~y2, ~n,    84,  37,  29,    61,  55,  26 )  # Test dispersed sequences: out_total_n <- schlim_map_total_n(df_groups_schlim) out_total_n #> # A tibble: 48 × 7 #>        y     n n_change consistency both_consistent  case dir   #>    <dbl> <dbl>    <dbl> <lgl>       <lgl>           <int> <chr> #>  1    84    14        0 TRUE        FALSE               1 forth #>  2    37    15        0 FALSE       FALSE               1 forth #>  3    84    13       -1 TRUE        FALSE               1 forth #>  4    37    16        1 FALSE       FALSE               1 forth #>  5    84    12       -2 TRUE        FALSE               1 forth #>  6    37    17        2 FALSE       FALSE               1 forth #>  7    84    11       -3 TRUE        FALSE               1 forth #>  8    37    18        3 FALSE       FALSE               1 forth #>  9    84    10       -4 TRUE        FALSE               1 forth #> 10    37    19        4 FALSE       FALSE               1 forth #> # … with 38 more rows  # Summarize: audit_total_n(out_total_n) #> # A tibble: 2 × 8 #>      y1    y2     n hits_total hits_forth hits_back scenarios_total hit_rate #>   <dbl> <dbl> <dbl>      <dbl>      <dbl>     <dbl>           <dbl>    <dbl> #> 1    84    37    29          4          0         4              12    0.333 #> 2    61    55    26         12          6         6              12    1"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"introduction-7","dir":"Articles","previous_headings":"8. Documenting audit_seq() and audit_total_n()","what":"Introduction","title":"Implementing consistency tests","text":"output sequence mappers total-n mappers comprehensive. makes somewhat unwieldy creates need summaries. first step, user can always call audit() tibbles returned manufactured functions like grim_map_seq(). go \"*_map\" class added within basic mapper function, grim_map(), return regular output respective audit() method. However, scrutiny features two specialized functions summarizing results manufactured *_seq() *_total_n() functions: audit_seq() audit_total_n(). two generic like audit(), accept output functions produced function_map_seq() function_map_total_n(), respectively. notice spoken two existing functions, rather — sections — kind function writing. Indeed, nothing left audit_seq() audit_total_n() , unless find bug ! , however, document behavior regard specific test implemented.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"documentation-templates","dir":"Articles","previous_headings":"8. Documenting audit_seq() and audit_total_n()","what":"Documentation templates","title":"Implementing consistency tests","text":"audit_seq() audit_total_n() rely uniform design manufactured functions, allows compute essentially summaries: behavior varies names numbers key columns, turn follow straightforwardly nature consistency test. ’re developing package, therefore document behavior audit_seq() audit_total_n() pages manufactured *_map_seq() *_map_total_n() functions. specialized helpers creating respective documentation sections, write_doc_audit_seq() write_doc_audit_total_n(), analogy write_doc_audit(). used first one grim_map_seq(), grimmer_map_seq(), debit_map_seq(); output omitted save space: key_args string vector names respective test’s key arguments. (see function sensitive length key_args, just values.) name_test short, plain-text name consistency test . Copy output console paste roxygen2 block _map_seq function. preserve bullet-point structure indenting roxygen2 comments Ctrl+Shift+/, leave empty lines pasted output rest block. Likewise, documenting audit_total_n() grim_map_total_n(), grimmer_map_total_n(), debit_map_total_n(): develop, export, strange functions? Documenting one’s package glossed , value standardization, well. write_doc_audit_seq() write_doc_audit_total_n() deliver quality documentation little effort also establishing firm conventions .","code":"write_doc_audit_seq(key_args = c(\"x\", \"n\"), name_test = \"GRIM\") write_doc_audit_seq(key_args = c(\"x\", \"sd\", \"n\"), name_test = \"GRIMMER\") write_doc_audit_seq(key_args = c(\"x\", \"sd\", \"n\"), name_test = \"DEBIT\") write_doc_audit_total_n(key_args = c(\"x\", \"n\"), name_test = \"GRIM\") write_doc_audit_total_n(key_args = c(\"x\", \"sd\", \"n\"), name_test = \"GRIMMER\") write_doc_audit_total_n(key_args = c(\"x\", \"sd\", \"n\"), name_test = \"DEBIT\")"},{"path":"https://lhdjung.github.io/scrutiny/articles/consistency-tests.html","id":"wrap-up","dir":"Articles","previous_headings":"","what":"Wrap-up","title":"Implementing consistency tests","text":"key part consistency tests compelling mathematical insight relationship summary statistics. rest implementation application. software package can generate new consistency tests yet, can make implementation application scale easy possible. scrutiny hopes . vignette generated five example functions (counting audit() method), four via function factories. Three factories part scrutiny’s infrastructure. Starting simple mock test, entire family functions sprang apply test special cases, unified API, scale — just lines easy write code. function family tree. Fields bold margins function factories. Arrows passing indicate new function generated basis earlier one.  overview scrutiny’s function factories: Predicate functions return TRUE data frames returned factory-made functions. general is_map_df() returns TRUE data frames. explained section 3, grim_map() written “hand” rather produced function_map(), factory-made function equivalent except additional columns output.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/debit.html","id":"debit-basics","dir":"Articles","previous_headings":"","what":"DEBIT basics","title":"DEBIT","text":"Consider summary data binary distribution: mean 0.35, SD 0.18, sample size 20. test consistency, run : grim(), mean needs string. (true SD.) strings preserve trailing zeros, can crucial DEBIT. Numeric values don’t, even converting strings won’t help. workaround larger numbers values, restore_zeros(), discussed Data wrangling vignette. debit() arguments, can used within debit_map(). Since debit_map() useful function practice, arguments discussed context.","code":"debit(x = \"0.35\", sd = \"0.18\", n = 20) #>  0.35  #> FALSE"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/debit.html","id":"working-with-debit_map","dir":"Articles","previous_headings":"Testing multiple cases","what":"Working with debit_map()","title":"DEBIT","text":"want test handful cases, recommended way enter data frame run debit_map() data frame. example data Heathers Brown’s (2019) Table 1. useful way enter data copy PDF file paste tibble::tribble(), available via scrutiny: Now, simply run debit_map() data frame: x, sd, n columns input. main result, consistency, DEBIT consistency former three columns. DEBIT makes sense binary means SDs. debit() debit_map() check inputs data, fail : Compared grim_map(), debit_map() straightforward. percentage conversion accounting multiple scale items. true comparing basic grim() debit() functions. However, implementations tap scrutiny’s arsenal rounding procedures, discussed next.","code":"flying_pigs <- tibble(     x  = runif(5, 0.2, 1) %>% round(2) %>% restore_zeros(),     sd = runif(5, 0, 0.3) %>% round(2) %>% restore_zeros(),     n = 1000 )   flying_pigs #> # A tibble: 5 × 3 #>   x     sd        n #>   <chr> <chr> <dbl> #> 1 0.53  0.24   1000 #> 2 0.80  0.07   1000 #> 3 0.97  0.05   1000 #> 4 0.58  0.07   1000 #> 5 0.21  0.15   1000 flying_pigs %>%    debit_map() #> # A tibble: 5 × 11 #>   x     sd        n consistency rounding sd_lo…¹ sd_in…² sd_up…³ sd_in…⁴ x_lower #>   <chr> <chr> <int> <lgl>       <chr>      <dbl> <lgl>     <dbl> <lgl>     <dbl> #> 1 0.53  0.24   1000 FALSE       up_or_d…   0.235 TRUE      0.245 TRUE      0.525 #> 2 0.80  0.07   1000 FALSE       up_or_d…   0.065 TRUE      0.075 TRUE      0.795 #> 3 0.97  0.05   1000 FALSE       up_or_d…   0.045 TRUE      0.055 TRUE      0.965 #> 4 0.58  0.07   1000 FALSE       up_or_d…   0.065 TRUE      0.075 TRUE      0.575 #> 5 0.21  0.15   1000 FALSE       up_or_d…   0.145 TRUE      0.155 TRUE      0.205 #> # … with 1 more variable: x_upper <dbl>, and abbreviated variable names #> #   ¹​sd_lower, ²​sd_incl_lower, ³​sd_upper, ⁴​sd_incl_upper pigs3  # data saved within the package #> # A tibble: 7 × 3 #>   x     sd        n #>   <chr> <chr> <dbl> #> 1 0.53  0.50   1683 #> 2 0.44  0.50   1683 #> 3 0.77  0.42   1683 #> 4 0.19  0.35   1683 #> 5 0.34  0.47   1683 #> 6 0.93  0.25   1683 #> 7 0.12  0.33   1683  pigs3 %>%    debit_map() #> # A tibble: 7 × 11 #>   x     sd        n consistency rounding sd_lo…¹ sd_in…² sd_up…³ sd_in…⁴ x_lower #>   <chr> <chr> <int> <lgl>       <chr>      <dbl> <lgl>     <dbl> <lgl>     <dbl> #> 1 0.53  0.50   1683 TRUE        up_or_d…   0.495 TRUE      0.505 TRUE      0.525 #> 2 0.44  0.50   1683 TRUE        up_or_d…   0.495 TRUE      0.505 TRUE      0.435 #> 3 0.77  0.42   1683 TRUE        up_or_d…   0.415 TRUE      0.425 TRUE      0.765 #> 4 0.19  0.35   1683 FALSE       up_or_d…   0.345 TRUE      0.355 TRUE      0.185 #> 5 0.34  0.47   1683 TRUE        up_or_d…   0.465 TRUE      0.475 TRUE      0.335 #> 6 0.93  0.25   1683 TRUE        up_or_d…   0.245 TRUE      0.255 TRUE      0.925 #> 7 0.12  0.33   1683 TRUE        up_or_d…   0.325 TRUE      0.335 TRUE      0.115 #> # … with 1 more variable: x_upper <dbl>, and abbreviated variable names #> #   ¹​sd_lower, ²​sd_incl_lower, ³​sd_upper, ⁴​sd_incl_upper pigs5  # no binary means / SDs! #> # A tibble: 12 × 3 #>    x     sd        n #>    <chr> <chr> <dbl> #>  1 7.22  5.30     38 #>  2 4.74  6.55     31 #>  3 5.23  2.55     35 #>  4 2.57  2.57     30 #>  5 6.77  2.18     33 #>  6 2.68  2.59     34 #>  7 7.01  6.68     35 #>  8 7.38  3.65     32 #>  9 3.14  5.32     33 #> 10 6.89  4.18     37 #> 11 5.00  2.18     31 #> 12 0.24  6.43     34  pigs5 %>%    debit_map() #> Error in `check_debit_inputs()` at scrutiny/R/debit-table.R:48:2: #> ! DEBIT only works with binary summary data. #> ! Binary mean (`x`) values must range from 0 to 1. #> ✖ 11 out of 12 `x` values are not in that range, starting with 7.22, 4.74, and #>   5.23."},{"path":"https://lhdjung.github.io/scrutiny/articles/debit.html","id":"rounding","dir":"Articles","previous_headings":"Testing multiple cases","what":"Rounding","title":"DEBIT","text":"scrutiny package provides infrastructure reconstructing rounded numbers. can commanded within debit() debit_map(). Several arguments allow stating precise way original numbers supposedly rounded. First foremost rounding argument. takes string rounding procedure’s name, leads number rounded either ways: Rounded \"\" \"\" 5. Note SAS, SPSS, Stata, Matlab, Excel round \"\" 5, whereas Python rounds \"\" 5. Rounded \"even\" using base R’s round(). Rounded \"up_from\" \"down_from\" number, needs specified via threshold argument. Given \"ceiling\" \"floor\" respective decimal place. Rounded towards zero \"trunc\" away zero \"anti_trunc\". default, \"up_or_down\", allows numbers rounded either \"\" \"\" 5 using DEBIT; likewise \"up_from_or_down_from\" \"ceiling_or_floor\". procedures, see documentation round(), round_up(), round_ceiling(). include ways rounding. Points 3 5 list quite obscure options included cover wide spectrum possible rounding procedures. true threshold symmetric arguments, aren’t discussed . default, debit() debit_map() accept values rounded either 5. reason impose stricter assumptions way x rounded, specify rounding accordingly: Although changing rounding procedure didn’t make difference DEBIT consistency , important account different ways numbers might rounded, demonstrate given results robust variable decisions. err side caution, default rounding permissive \"up_or_down\".","code":"pigs3 %>%    debit_map(rounding = \"up\") #> # A tibble: 7 × 11 #>   x     sd        n consistency rounding sd_lo…¹ sd_in…² sd_up…³ sd_in…⁴ x_lower #>   <chr> <chr> <int> <lgl>       <chr>      <dbl> <lgl>     <dbl> <lgl>     <dbl> #> 1 0.53  0.50   1683 TRUE        up         0.495 TRUE      0.505 FALSE     0.525 #> 2 0.44  0.50   1683 TRUE        up         0.495 TRUE      0.505 FALSE     0.435 #> 3 0.77  0.42   1683 TRUE        up         0.415 TRUE      0.425 FALSE     0.765 #> 4 0.19  0.35   1683 FALSE       up         0.345 TRUE      0.355 FALSE     0.185 #> 5 0.34  0.47   1683 TRUE        up         0.465 TRUE      0.475 FALSE     0.335 #> 6 0.93  0.25   1683 TRUE        up         0.245 TRUE      0.255 FALSE     0.925 #> 7 0.12  0.33   1683 TRUE        up         0.325 TRUE      0.335 FALSE     0.115 #> # … with 1 more variable: x_upper <dbl>, and abbreviated variable names #> #   ¹​sd_lower, ²​sd_incl_lower, ³​sd_upper, ⁴​sd_incl_upper  pigs3 %>%    debit_map(rounding = \"even\") #> # A tibble: 7 × 11 #>   x     sd        n consistency rounding sd_lo…¹ sd_in…² sd_up…³ sd_in…⁴ x_lower #>   <chr> <chr> <int> <lgl>       <chr>      <dbl> <lgl>     <dbl> <lgl>     <dbl> #> 1 0.53  0.50   1683 TRUE        even       0.495 FALSE     0.505 FALSE     0.525 #> 2 0.44  0.50   1683 TRUE        even       0.495 FALSE     0.505 FALSE     0.435 #> 3 0.77  0.42   1683 TRUE        even       0.415 FALSE     0.425 FALSE     0.765 #> 4 0.19  0.35   1683 FALSE       even       0.345 FALSE     0.355 FALSE     0.185 #> 5 0.34  0.47   1683 TRUE        even       0.465 FALSE     0.475 FALSE     0.335 #> 6 0.93  0.25   1683 TRUE        even       0.245 FALSE     0.255 FALSE     0.925 #> 7 0.12  0.33   1683 TRUE        even       0.325 FALSE     0.335 FALSE     0.115 #> # … with 1 more variable: x_upper <dbl>, and abbreviated variable names #> #   ¹​sd_lower, ²​sd_incl_lower, ³​sd_upper, ⁴​sd_incl_upper"},{"path":"https://lhdjung.github.io/scrutiny/articles/debit.html","id":"summarizing-results-with-audit","dir":"Articles","previous_headings":"","what":"Summarizing results with audit()","title":"DEBIT","text":"Following call debit_map(), generic function audit() summarizes test results: columns — incons_cases: number inconsistent value sets. all_cases: total number value sets. incons_rate: proportion DEBIT-inconsistent value sets. mean_x: average binary distribution means. mean_sd: average binary distribution standard deviations. distinct_n: number different sample sizes.","code":"pigs3 %>%    debit_map() %>%    audit() #> # A tibble: 1 × 6 #>   incons_cases all_cases incons_rate mean_x mean_sd distinct_n #>          <int>     <int>       <dbl>  <dbl>   <dbl>      <int> #> 1            1         7       0.143  0.474   0.403          1"},{"path":"https://lhdjung.github.io/scrutiny/articles/debit.html","id":"visualizing-results-with-debit_plot","dir":"Articles","previous_headings":"","what":"Visualizing results with debit_plot()","title":"DEBIT","text":"specialized visualization function DEBIT results, debit_plot(). run debit_map()’s output. fail otherwise.  DEBIT-consistent value pairs blue, inconsistent ones red. black arc DEBIT line: Given sample size, pairs mean SD values DEBIT-consistent cross line. precisely, inner boxes must cross line — outer boxes just pointers inner ones, case poorly visible. inherent meaning. Except colors, inner boxes must look exactly like : sizes shapes completely determined mean SD values. Since inner boxes enlarged , outer boxes might helpful spot first glance. However, outer boxes desired, can turned like :  Color settings ggplot2-typical options available via arguments, settings handed ggrepel::geom_text_repel(), creates labels. , see debit_plot()’s documentation.","code":"# Determine plot theme for the remaining session: ggplot2::theme_minimal(base_size = 12) %>%    ggplot2::theme_set()  pigs3 %>%    debit_map() %>%    debit_plot() pigs3 %>%    debit_map() %>%    debit_plot(show_outer_boxes = FALSE)"},{"path":"https://lhdjung.github.io/scrutiny/articles/debit.html","id":"testing-numeric-sequences-with-debit_map_seq","dir":"Articles","previous_headings":"","what":"Testing numeric sequences with debit_map_seq()","title":"DEBIT","text":"DEBIT analysts might interested mean percentage value’s numeric neighborhood. Suppose found DEBIT inconsistencies, example pigs3 data. might wonder whether due small reporting computing errors. Use debit_map_seq() use DEBIT values surrounding reported means, SDs, sample sizes:","code":"out_seq1 <- debit_map_seq(pigs3) out_seq1 #> # A tibble: 30 × 13 #>    x     sd        n consistency round…¹ sd_lo…² sd_in…³ sd_up…⁴ sd_in…⁵ x_lower #>    <chr> <chr> <int> <lgl>       <chr>     <dbl> <lgl>     <dbl> <lgl>     <dbl> #>  1 0.14  0.35   1683 TRUE        up_or_…   0.345 TRUE      0.355 TRUE      0.135 #>  2 0.15  0.35   1683 TRUE        up_or_…   0.345 TRUE      0.355 TRUE      0.145 #>  3 0.16  0.35   1683 FALSE       up_or_…   0.345 TRUE      0.355 TRUE      0.155 #>  4 0.17  0.35   1683 FALSE       up_or_…   0.345 TRUE      0.355 TRUE      0.165 #>  5 0.18  0.35   1683 FALSE       up_or_…   0.345 TRUE      0.355 TRUE      0.175 #>  6 0.20  0.35   1683 FALSE       up_or_…   0.345 TRUE      0.355 TRUE      0.195 #>  7 0.21  0.35   1683 FALSE       up_or_…   0.345 TRUE      0.355 TRUE      0.205 #>  8 0.22  0.35   1683 FALSE       up_or_…   0.345 TRUE      0.355 TRUE      0.215 #>  9 0.23  0.35   1683 FALSE       up_or_…   0.345 TRUE      0.355 TRUE      0.225 #> 10 0.24  0.35   1683 FALSE       up_or_…   0.345 TRUE      0.355 TRUE      0.235 #> # … with 20 more rows, 3 more variables: x_upper <dbl>, case <int>, var <chr>, #> #   and abbreviated variable names ¹​rounding, ²​sd_lower, ³​sd_incl_lower, #> #   ⁴​sd_upper, ⁵​sd_incl_upper"},{"path":"https://lhdjung.github.io/scrutiny/articles/debit.html","id":"summaries-with-audit_seq","dir":"Articles","previous_headings":"Testing numeric sequences with debit_map_seq()","what":"Summaries with audit_seq()","title":"DEBIT","text":"output little unwieldy, run audit_seq() results: output columns mean: x, sd, n original inputs, reconstructed tested consistency . hits_* columns display number DEBIT-consistent value combinations found within specified dispersion range; either total varying individual parameters. diff_x reports absolute difference x next consistent dispersed value (dispersion steps, actual numeric difference). diff_x_up diff_x_down report difference next higher lower consistent value, respectively. Accordingly diff_sd* diff_n* columns. default dispersion 1:5, five steps . dispersion sequence gets longer, number hits tends increase:","code":"audit_seq(out_seq1) #> # A tibble: 1 × 17 #>   x     sd        n consi…¹ hits_…² hits_x hits_sd hits_n diff_x diff_…³ diff_…⁴ #>   <chr> <chr> <int> <lgl>     <int>  <int>   <int>  <int>  <dbl>   <dbl>   <dbl> #> 1 0.19  0.35   1683 FALSE         4      2       2      1      4      NA      -4 #> # … with 6 more variables: diff_sd <dbl>, diff_sd_up <dbl>, diff_sd_down <dbl>, #> #   diff_n <dbl>, diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated variable #> #   names ¹​consistency, ²​hits_total, ³​diff_x_up, ⁴​diff_x_down out_seq2 <- debit_map_seq(pigs3, dispersion = 1:7, include_consistent = TRUE) audit_seq(out_seq2) #> # A tibble: 7 × 17 #>   x     sd        n consi…¹ hits_…² hits_x hits_sd hits_n diff_x diff_…³ diff_…⁴ #>   <chr> <chr> <int> <lgl>     <int>  <int>   <int>  <int>  <dbl>   <dbl>   <dbl> #> 1 0.53  0.50   1683 TRUE         25     11       0     14      1       1      -1 #> 2 0.44  0.50   1683 TRUE         22      8       0     14      1       1      -1 #> 3 0.77  0.42   1683 TRUE         16      2       0     14      1       1      -1 #> 4 0.19  0.35   1683 FALSE         4      2       2      0      4      NA      -4 #> 5 0.34  0.47   1683 TRUE         17      2       1     14      1      NA      -1 #> 6 0.93  0.25   1683 TRUE         16      2       1     14     NA      NA      NA #> 7 0.12  0.33   1683 TRUE         16      1       1     14      1       1      NA #> # … with 6 more variables: diff_sd <dbl>, diff_sd_up <dbl>, diff_sd_down <dbl>, #> #   diff_n <dbl>, diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated variable #> #   names ¹​consistency, ²​hits_total, ³​diff_x_up, ⁴​diff_x_down"},{"path":"https://lhdjung.github.io/scrutiny/articles/debit.html","id":"visualizing-debit-checked-sequences","dir":"Articles","previous_headings":"Testing numeric sequences with debit_map_seq()","what":"Visualizing DEBIT-checked sequences","title":"DEBIT","text":"Although possible principle visualize results debit_map_seq() using debit_plot(), ’s recommended results don’t currently look great. issue might fixed future version debit_plot().","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/debit.html","id":"problems-from-underreporting","dir":"Articles","previous_headings":"Handling unknown group sizes with debit_map_total_n()","what":"Problems from underreporting","title":"DEBIT","text":"Unfortunately, studies report group averages don’t report corresponding group sizes — total sample size. makes direct use DEBIT impossible x sd values known, n values. feasible terms DEBIT take number around half total sample size, go , check hypothetical group sizes consistent reported group means SDs. debit_map_total_n() semi-automates process, motivated recent GRIM analysis (Bauer Francis 2021). example: See GRIM vignette, section Handling unknown group sizes grim_map_total_n(), comprehensive case study. uses grim_map_total_n(), debit_map_total_n() GRIM.","code":"out_total_n <- tibble::tribble(   ~x1,     ~x2,   ~sd1,   ~sd2,  ~n,   \"0.30\", \"0.28\", \"0.17\", \"0.10\", 70,   \"0.41\", \"0.39\", \"0.09\", \"0.15\", 65 )  out_total_n <- debit_map_total_n(out_total_n) out_total_n #> # A tibble: 48 × 15 #>    x     sd        n n_change consiste…¹ both_…² round…³ sd_lo…⁴ sd_in…⁵ sd_up…⁶ #>    <chr> <chr> <int>    <dbl> <lgl>      <lgl>   <chr>     <dbl> <lgl>     <dbl> #>  1 0.30  0.17     35        0 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #>  2 0.28  0.10     35        0 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #>  3 0.30  0.17     34       -1 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #>  4 0.28  0.10     36        1 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #>  5 0.30  0.17     33       -2 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #>  6 0.28  0.10     37        2 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #>  7 0.30  0.17     32       -3 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #>  8 0.28  0.10     38        3 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #>  9 0.30  0.17     31       -4 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #> 10 0.28  0.10     39        4 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #> # … with 38 more rows, 5 more variables: sd_incl_upper <lgl>, x_lower <dbl>, #> #   x_upper <dbl>, case <int>, dir <chr>, and abbreviated variable names #> #   ¹​consistency, ²​both_consistent, ³​rounding, ⁴​sd_lower, ⁵​sd_incl_lower, #> #   ⁶​sd_upper  audit_total_n(out_total_n) #> # A tibble: 2 × 10 #>   x1    x2    sd1   sd2       n hits_total hits_forth hits_back scenar…¹ hit_r…² #>   <chr> <chr> <chr> <chr> <dbl>      <dbl>      <dbl>     <dbl>    <dbl>   <dbl> #> 1 0.30  0.28  0.17  0.10     70          0          0         0       12       0 #> 2 0.41  0.39  0.09  0.15     65          0          0         0       12       0 #> # … with abbreviated variable names ¹​scenarios_total, ²​hit_rate"},{"path":[]},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"few-cases-grim","dir":"Articles","previous_headings":"Basic GRIM testing","what":"Few cases: grim()","title":"GRIM","text":"test reported mean 5.27 granular scale GRIM-consistent sample size 43, run : Note x, reported mean, needs string. reason strings preserve trailing zeros, can crucial GRIM-testing. Numeric values don’t, even converting strings won’t help. workaround larger numbers values, restore_zeros(), discussed vignette(\"wrangling\"). grim() parameters, can used within grim_map(). parameters discussed context grim_map() often useful function practice. Furthermore, although grim() vectorized, grim_map() safe convenient testing multiple combinations means/proportions sample sizes.","code":"grim(x = \"5.27\", n = 43) #>  5.27  #> FALSE"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"many-cases-grim_map","dir":"Articles","previous_headings":"Basic GRIM testing","what":"Many cases: grim_map()","title":"GRIM","text":"want GRIM-test handful cases, recommended way enter data frame run grim_map() data frame. Two different ways discussed vignette(\"wrangling\"), , describe easily accessible solution single table. Copy summary data PDF file paste tibble::tribble(), available via scrutiny: Use RStudio’s multiple cursors draw quotation marks around x values, set commas end. See vignette(\"wrangling\"), section copy paste, sure . Now, simply run grim_map() data frame: x n columns input. default, number items composing mean assumed 1. main result, consistency, GRIM consistency former three columns. ratio column, see section GRIM ratio.","code":"flying_pigs1 <- tribble(   ~x, \"8.97\", \"2.61\", \"7.26\", \"3.64\", \"9.26\", \"10.46\", \"7.39\" ) %>%    mutate(n = 28) grim_map(flying_pigs1) #> # A tibble: 7 × 4 #>   x         n consistency ratio #>   <chr> <dbl> <lgl>       <dbl> #> 1 8.97     28 FALSE        0.72 #> 2 2.61     28 TRUE         0.72 #> 3 7.26     28 FALSE        0.72 #> 4 3.64     28 TRUE         0.72 #> 5 9.26     28 FALSE        0.72 #> 6 10.46    28 TRUE         0.72 #> 7 7.39     28 TRUE         0.72"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"scale-items","dir":"Articles","previous_headings":"Basic GRIM testing","what":"Scale items","title":"GRIM","text":"mean composed multiple items, set items parameter number. hypothetical means three-items scale. single-item default, half wrongly flagged inconsistent: Yet, consistent correct number items stated: also possible include items column data frame instead:","code":"jpap_1 <- tribble(    ~x,   \"5.90\",   \"5.71\",   \"3.50\",   \"3.82\",   \"4.61\",   \"5.24\", ) %>%    mutate(n = 40)  jpap_1 %>%    grim_map()  # default is wrong here! #> # A tibble: 6 × 4 #>   x         n consistency ratio #>   <chr> <dbl> <lgl>       <dbl> #> 1 5.90     40 TRUE          0.6 #> 2 5.71     40 FALSE         0.6 #> 3 3.50     40 TRUE          0.6 #> 4 3.82     40 TRUE          0.6 #> 5 4.61     40 FALSE         0.6 #> 6 5.24     40 FALSE         0.6 jpap_1 %>%    grim_map(items = 3) #> # A tibble: 6 × 4 #>   x         n consistency ratio #>   <chr> <dbl> <lgl>       <dbl> #> 1 5.90    120 TRUE         -0.2 #> 2 5.71    120 TRUE         -0.2 #> 3 3.50    120 TRUE         -0.2 #> 4 3.82    120 TRUE         -0.2 #> 5 4.61    120 TRUE         -0.2 #> 6 5.24    120 TRUE         -0.2 jpap_2 <- tribble(    ~x,    ~items,   \"6.92\",  1,   \"3.48\",  1,   \"1.59\",  2,   \"2.61\",  2,   \"4.04\",  3,   \"4.50\",  3, ) %>%    mutate(n = 30)  jpap_2 %>%    grim_map() #> # A tibble: 6 × 4 #>   x         n consistency ratio #>   <chr> <dbl> <lgl>       <dbl> #> 1 6.92     30 FALSE         0.7 #> 2 3.48     30 FALSE         0.7 #> 3 1.59     60 FALSE         0.4 #> 4 2.61     60 FALSE         0.4 #> 5 4.04     90 TRUE          0.1 #> 6 4.50     90 TRUE          0.1"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"percentage-conversion","dir":"Articles","previous_headings":"Basic GRIM testing","what":"Percentage conversion","title":"GRIM","text":"underappreciated strength GRIM testing percentages. Since actually decimal numbers inflated factor 100, percentages come two “free” decimal places. However, percentages often reported decimal places beyond two, increases probability GRIM-inconsistencies unless true values correctly reported. grim() grim_map() percent parameter , set TRUE, divides x values 100 increases decimal count two, percentages can tested just like means:","code":"jpap_3 <- tribble(   ~x,     ~n,   \"32.5\",  438,   \"35.6\",  455,   \"21.7\",  501,   \"39.3\",  516, )  jpap_3 %>%    grim_map(percent = TRUE) #> ℹ `x` converted from percentage #> # A tibble: 4 × 4 #>   x         n consistency ratio #>   <chr> <dbl> <lgl>       <dbl> #> 1 0.325   438 FALSE       0.562 #> 2 0.356   455 TRUE        0.545 #> 3 0.217   501 FALSE       0.499 #> 4 0.393   516 TRUE        0.484"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"reconstructed-values","dir":"Articles","previous_headings":"Basic GRIM testing","what":"Reconstructed values","title":"GRIM","text":"Set show_rec TRUE want values reconstructed GRIM-testing displayed output. columns prefixed rec_: additional columns — rec_sum: sum total mean proportion ostensibly derived. rec_x_upper: upper reconstructed x value. rec_x_lower: lower reconstructed x value. rec_x_upper_rounded_up: rec_x_upper value rounded . rec_x_upper_rounded_down: rec_x_upper value rounded . rec_x_lower_rounded_up: rec_x_lower value rounded . rec_x_lower_rounded_down: rec_x_lower value rounded . last four columns depend rounding. , follow default \"up_or_down\", leading two columns rec_x_upper rec_x_lower. singular rounding procedure, \"\", one column , thus, two total. difference numbers greatly important, however, rounding mostly delivers results. Internally, GRIM-consistency determined whether stated x value near-identical either rec_x_upper_rounded rec_x_lower_rounded. algorithm follows charitable conservative protocol outlined Brown Heathers (2017). rec_* columns inspired Bauer Francis (2021)’s Table 1 present values slightly different ways.","code":"pigs1 %>%    grim_map(show_rec = TRUE) %>%    dplyr::select(4:8)   # output cut down for printing #> # A tibble: 12 × 5 #>    rec_sum rec_x_upper rec_x_lower rec_x_upper_rounded_up rec_x_upper_rounded_…¹ #>      <dbl>       <dbl>       <dbl>                  <dbl>                  <dbl> #>  1  231.         7.25        7.22                    7.25                   7.25 #>  2  118.         4.76        4.72                    4.76                   4.76 #>  3  152.         5.24        5.21                    5.24                   5.24 #>  4   61.7        2.58        2.54                    2.58                   2.58 #>  5  183.         6.78        6.74                    6.78                   6.78 #>  6   75.0        2.71        2.68                    2.71                   2.71 #>  7  203.         7.03        7.00                    7.03                   7.03 #>  8  192.         7.38        7.35                    7.38                   7.38 #>  9   84.8        3.15        3.11                    3.15                   3.15 #> 10  214.         6.90        6.87                    6.9                    6.9  #> 11  125          5.00        5.00                    5                      5    #> 12    6.72       0.250       0.214                   0.25                   0.25 #> # … with abbreviated variable name ¹​rec_x_upper_rounded_down"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"rounding","dir":"Articles","previous_headings":"Basic GRIM testing","what":"Rounding","title":"GRIM","text":"scrutiny package provides infrastructure reconstructing rounded numbers. can commanded within grim() grim_map(). Several parameters allow stating precise way original numbers supposedly rounded. First foremost rounding. takes string rounding procedure’s name, leads number rounded either ways: Rounded \"\" \"\" 5. Note SAS, SPSS, Stata, Matlab, Excel round \"\" 5, whereas Python used round \"\" 5. Rounded \"even\" using base R’s round(). Rounded \"up_from\" \"down_from\" number, needs specified via threshold parameter. Given \"ceiling\" \"floor\" respective decimal place. Rounded towards zero \"trunc\" away zero \"anti_trunc\". default, \"up_or_down\", allows numbers rounded either \"\" \"\" 5 GRIM-testing; likewise \"up_from_or_down_from\" \"ceiling_or_floor\". procedures, see documentation round(), round_up(), round_ceiling(). include ways rounding. Points 3 5 list quite obscure options included cover wide spectrum possible rounding procedures. true threshold symmetric parameters, aren’t discussed . Learn scrutiny’s infrastructure rounding vignette(\"rounding\"). default, grim() grim_map() accept values rounded either 5. reason impose stricter assumptions way x rounded, specify rounding accordingly: Rounding leads precisely opposite results first two cases, although agrees latter two. Even example cherry-picked: Sample sizes 80 highly unusual , n values, two rounding procedures agree vast majority cases. See section Visualizing results grim_plot() issue. might still important account different ways numbers can rounded, demonstrate given results robust variable decisions. err side caution, default rounding permissive \"up_or_down\".","code":"jpap_4 <- tibble::tribble(     ~x,     ~n,     \"2.02\",  80,     \"2.03\",  80,     \"2.04\",  80,     \"2.05\",  80, )  jpap_4 %>%    grim_map(rounding = \"up\") #> # A tibble: 4 × 4 #>   x         n consistency ratio #>   <chr> <dbl> <lgl>       <dbl> #> 1 2.02     80 TRUE          0.2 #> 2 2.03     80 TRUE          0.2 #> 3 2.04     80 TRUE          0.2 #> 4 2.05     80 TRUE          0.2  jpap_4 %>%    grim_map(rounding = \"down\") #> # A tibble: 4 × 4 #>   x         n consistency ratio #>   <chr> <dbl> <lgl>       <dbl> #> 1 2.02     80 TRUE          0.2 #> 2 2.03     80 TRUE          0.2 #> 3 2.04     80 TRUE          0.2 #> 4 2.05     80 TRUE          0.2"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"summarizing-results-with-audit","dir":"Articles","previous_headings":"","what":"Summarizing results with audit()","title":"GRIM","text":"Following call grim_map(), generic function audit() summarizes GRIM test results: columns — incons_cases: number GRIM-inconsistent value sets. all_cases: total number value sets. incons_rate: proportion GRIM-inconsistent value sets. mean_grim_ratio: average GRIM ratios. incons_to_ratio: ratio incons_rate mean_ratio. testable_cases: number GRIM-testable value sets (.e., positive ratio). testable_rate: proportion GRIM-testable value sets.","code":"flying_pigs1 %>%    grim_map() %>%    audit() %>%    dplyr::select(1:5)   # output cut down for printing #> # A tibble: 1 × 5 #>   incons_cases all_cases incons_rate mean_grim_ratio incons_to_ratio #>          <int>     <int>       <dbl>           <dbl>           <dbl> #> 1            3         7       0.429            0.72           0.595"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"visualizing-results-with-grim_plot","dir":"Articles","previous_headings":"","what":"Visualizing results with grim_plot()","title":"GRIM","text":"specialized visualization function GRIM test results, grim_plot():  grim_plot() can called grim_map()’s output. fail otherwise: unusual optics, plot probably fit everyone’s taste. results grim_plot() like error detection general: pretty, put unvarnished truth display. plot strictly based laws governing GRIM. background raster shows consistent (light) inconsistent (dark) value pairs two decimal places. Empirical values shown blue consistent red inconsistent. Color settings ggplot2-typical options available via arguments. Read grim_plot()’s documentation. might notice light vertical lines \\(N = 40\\) \\(N = 80\\): values flagged inconsistent . reflects grim_map()’s charitable default accepting values rounded either 5. different rounding specification chosen grim_map() call, plot raster adjust automatically (although often ):  rounding values up_from, down_from, up_from_or_down_from supported. Speed much concern rasters based data already stored within package (R/sysdata.rda), don’t need generated spot every time function called. See R/data-gen.R way generated.","code":"jpap_5 <- tribble(   ~x,        ~n,   \"7.19\",    28,   \"4.56\",    34,   \"0.42\",    27,   \"1.31\",    25,   \"3.48\",    34,   \"4.27\",    29,   \"6.21\",    30,   \"3.11\",    18,   \"5.39\",    36,   \"5.66\",    18, )   jpap_5 %>%    grim_map() %>%    grim_plot() grim_plot(mtcars) #> Error in `grim_plot()`: #> ! `grim_plot()` needs GRIM or GRIMMER test results. #> ✖ `data` is not `grim_map()` or `grimmer_map()` output. #> ℹ The only exception is an \"empty\" plot that shows the background raster but no #>   empirical test results. Create such a plot by setting `show_data` to `FALSE`. jpap_5 %>%    grim_map(rounding = \"ceiling\") %>%    grim_plot()"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"testing-numeric-sequences-with-grim_map_seq","dir":"Articles","previous_headings":"","what":"Testing numeric sequences with grim_map_seq()","title":"GRIM","text":"GRIM analysts might interested mean percentage value’s numeric neighborhood. Suppose found multiple GRIM inconsistencies example pigs1 data. might wonder whether due small reporting computing errors. Use grim_map_seq() GRIM-test values surrounding reported means sample sizes:","code":"out_seq1 <- grim_map_seq(pigs1) out_seq1 #> # A tibble: 160 × 6 #>    x         n consistency ratio  case var   #>    <chr> <dbl> <lgl>       <dbl> <int> <chr> #>  1 4.69     25 FALSE        0.75     1 x     #>  2 4.70     25 FALSE        0.75     1 x     #>  3 4.71     25 FALSE        0.75     1 x     #>  4 4.72     25 TRUE         0.75     1 x     #>  5 4.73     25 FALSE        0.75     1 x     #>  6 4.75     25 FALSE        0.75     1 x     #>  7 4.76     25 TRUE         0.75     1 x     #>  8 4.77     25 FALSE        0.75     1 x     #>  9 4.78     25 FALSE        0.75     1 x     #> 10 4.79     25 FALSE        0.75     1 x     #> # … with 150 more rows"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"summaries-with-audit_seq","dir":"Articles","previous_headings":"Testing numeric sequences with grim_map_seq()","what":"Summaries with audit_seq()","title":"GRIM","text":"output little unwieldy, run audit_seq() results: output columns mean: x n original inputs, reconstructed tested consistency . hits number GRIM-consistent value combinations found within specified dispersion range. diff_x reports absolute difference x next consistent dispersed value (dispersion steps, actual numeric difference). diff_x_up diff_x_down report difference next higher lower consistent value, respectively. diff_n, diff_n_up, diff_n_down n. default dispersion 1:5, five steps . dispersion sequence gets longer, number hits tends increase:","code":"audit_seq(out_seq1) #> # A tibble: 8 × 12 #>   x         n consistency hits_total hits_x hits_n diff_x diff_…¹ diff_…² diff_n #>   <chr> <dbl> <lgl>            <int>  <int>  <int>  <dbl>   <dbl>   <dbl>  <dbl> #> 1 4.74     25 FALSE                4      2      2      2       2      -2      2 #> 2 5.23     29 FALSE                6      3      3      1       1      -2      1 #> 3 2.57     24 FALSE                6      3      3      1       1      -3      1 #> 4 6.77     27 FALSE                7      3      4      1       1      -3      1 #> 5 7.01     29 FALSE                3      3      0      1       2      -1     NA #> 6 3.14     27 FALSE                6      3      3      1       1      -3      1 #> 7 6.89     31 FALSE                8      4      4      1       1      -2      3 #> 8 0.24     28 FALSE                6      3      3      1       1      -3      1 #> # … with 2 more variables: diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated #> #   variable names ¹​diff_x_up, ²​diff_x_down out_seq2 <- grim_map_seq(pigs1, dispersion = 1:10) audit_seq(out_seq2) #> # A tibble: 8 × 12 #>   x         n consistency hits_total hits_x hits_n diff_x diff_…¹ diff_…² diff_n #>   <chr> <dbl> <lgl>            <int>  <int>  <int>  <dbl>   <dbl>   <dbl>  <dbl> #> 1 4.74     25 FALSE               12      6      6      2       2      -2      2 #> 2 5.23     29 FALSE               12      6      6      1       1      -2      1 #> 3 2.57     24 FALSE               11      6      5      1       1      -3      1 #> 4 6.77     27 FALSE               11      6      5      1       1      -3      1 #> 5 7.01     29 FALSE                6      6      0      1       2      -1     NA #> 6 3.14     27 FALSE               13      6      7      1       1      -3      1 #> 7 6.89     31 FALSE               12      6      6      1       1      -2      3 #> 8 0.24     28 FALSE               13      6      7      1       1      -3      1 #> # … with 2 more variables: diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated #> #   variable names ¹​diff_x_up, ²​diff_x_down"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"visualizing-grim-tested-sequences","dir":"Articles","previous_headings":"Testing numeric sequences with grim_map_seq()","what":"Visualizing GRIM-tested sequences","title":"GRIM","text":"’s curious happens plot output grim_map_seq(). Like regular GRIM plots, however, give us sense many tested values consistent:  crosses appear grim_map_seq() creates sequences around x n. Restrict process one var argument:","code":"grim_plot(out_seq1) out_seq1_only_x <- grim_map_seq(pigs1, var = \"x\") out_seq1_only_n <- grim_map_seq(pigs1, var = \"n\")  grim_plot(out_seq1_only_x) grim_plot(out_seq1_only_n)"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"problems-from-underreporting","dir":"Articles","previous_headings":"Handling unknown group sizes with grim_map_total_n()","what":"Problems from underreporting","title":"GRIM","text":"Unfortunately, studies report group averages don’t report corresponding group sizes — total sample size. makes direct GRIM-testing impossible x values known, n values. feasible terms GRIM take number around half total sample size, go , check hypothetical group sizes consistent reported group means. grim_map_total_n() semi-automates process, motivated recent GRIM analysis (Bauer Francis 2021). study examined Bauer Francis (2021) reported means 5.3 4.71 total sample size 40. equal group sizes (.e., 20 group), 5.3 GRIM-consistent, 4.71. However, Bauer Francis looked plausible scenario means consistent. checked scenarios came 40 participants distributed across two groups slightly different ways. precisely, went 20/20 group split 19/21 split, 18/22 split, finally 17/23 split. latter scenario, means consistent 17 paired 4.71 23 5.3.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"semi-automated-solution","dir":"Articles","previous_headings":"Handling unknown group sizes with grim_map_total_n()","what":"Semi-automated solution","title":"GRIM","text":"Instead going manually, call grim_map_total_n(), followed audit_total_n() summarizing results. find two plausible scenarios means consistent; . “hit” scenario x1 x2 GRIM-consistent one two hypothetical group sizes. default (dispersion = 0:5), function goes five steps n.","code":"df <- tibble(x1 = \"4.71\", x2 = \"5.3\", n = 40)  # Detailed results: df_tested <- grim_map_total_n(df) df_tested #> # A tibble: 24 × 8 #>    x         n n_change consistency both_consistent ratio  case dir   #>    <chr> <dbl>    <dbl> <lgl>       <lgl>           <dbl> <int> <chr> #>  1 4.71     20        0 FALSE       FALSE            0.8      1 forth #>  2 5.3      20        0 TRUE        FALSE           -1        1 forth #>  3 4.71     19       -1 FALSE       FALSE            0.81     1 forth #>  4 5.3      21        1 TRUE        FALSE           -1.1      1 forth #>  5 4.71     18       -2 FALSE       FALSE            0.82     1 forth #>  6 5.3      22        2 TRUE        FALSE           -1.2      1 forth #>  7 4.71     17       -3 TRUE        TRUE             0.83     1 forth #>  8 5.3      23        3 TRUE        TRUE            -1.3      1 forth #>  9 4.71     16       -4 FALSE       FALSE            0.84     1 forth #> 10 5.3      24        4 TRUE        FALSE           -1.4      1 forth #> # … with 14 more rows  # Summary: audit_total_n(df_tested) #> # A tibble: 1 × 8 #>   x1    x2        n hits_total hits_forth hits_back scenarios_total hit_rate #>   <chr> <chr> <dbl>      <dbl>      <dbl>     <dbl>           <dbl>    <dbl> #> 1 4.71  5.3      40          3          1         2              12     0.25"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"testing-both-ways","dir":"Articles","previous_headings":"Handling unknown group sizes with grim_map_total_n()","what":"Testing both ways","title":"GRIM","text":"Bauer Francis (2021) took scenarios account 4.71 combined respective smaller group 5.3 larger one, 17/23 “hit” found (term). However, converse way assigning hypothetical group sizes reported means equally justified. grim_map_total_n(), therefore, conducts two sets GRIM tests: one way pairing means group sizes. thus finds group sizes 19/21 16/24 GRIM-consistent 5.3 combined smaller group 4.71 larger one (.e., pairing reversed Bauer Francis’ analysis). audit_total_n() summary function’s output, results original pairing named hits_forth, reversed pairing named hits_back, sum named hits_total. example features one case — df tibble just single row. number rows, though; grim_map_total_n() determine count “hits” . See Examples section grim_map_total_n()’s documentation.","code":""},{"path":[]},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"formula","dir":"Articles","previous_headings":"GRIM statistics > The GRIM ratio","what":"Formula","title":"GRIM","text":"ratio column tibble returned grim_map() “GRIM ratio”, .e.: \\[ \\frac{10^D - NL}{10^D} \\] \\(D\\) number decimal places x (mean proportion), \\(N\\) sample size, \\(L\\) number scale items. \\(N, L \\geq 1\\), GRIM ratio ranges \\(-\\infty\\) \\(1 - \\frac{1}{10^D}\\), asymptotically approaching 1. upper bound 0.9 \\(D = 1\\) 0.99 \\(D = 2\\), etc.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"functions","dir":"Articles","previous_headings":"GRIM statistics > The GRIM ratio","what":"Functions","title":"GRIM","text":"grim_ratio() takes arguments x, n, items, percent grim() grim_map(): addition, grim_total() takes arguments returns numerator formula: grim_map()’s prob argument set TRUE, adds prob column shows probability GRIM inconsistency. prob derived left-censoring ratio column 0, equal ratio \\(0 \\leq ratio\\). \\(ratio < 0\\), \\(prob = 0\\). (GRIM ratio 1 greater.)","code":"grim_ratio(x = 1.42, n = 72) #> [1] 0.28  grim_ratio(x = 5.93, n = 80, items = 3) #> [1] -1.4  # Enter `x` as a string to preserve trailing zeros: grim_ratio(x = \"84.20\", n = 40, percent = TRUE) #> [1] 0.996  # Upper bounds: grim_ratio_upper(x = 1.42) #> [1] 0.99 grim_ratio_upper(x = \"84.20\", percent = TRUE) #> [1] 0.9999 grim_total(x = 1.42, n = 72) #> [1] 28  grim_total(x = 5.93, n = 80, items = 3) #> [1] -140  grim_total(x = \"84.20\", n = 40, percent = TRUE)  # Enter `x` as string to preserve trailing zero #> [1] 9960"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"interpretation","dir":"Articles","previous_headings":"GRIM statistics > The GRIM ratio","what":"Interpretation","title":"GRIM","text":"GRIM ratio non-negative, can interpreted proportion inconsistent value sets corresponding given set parameters. also probability randomly chosen mean GRIM-inconsistent. ratio negative, probability 0. Similarly, grim_total() value non-negative, can interpreted total number GRIM inconsistencies corresponding given set parameters. negative, total 0.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"origins","dir":"Articles","previous_headings":"GRIM statistics > The GRIM ratio","what":"Origins","title":"GRIM","text":"Although term “GRIM ratio” new, formula arguably implicit Brown Heathers’ (2017) paper GRIM. numerator transformation formula presented p. 364, authors discuss common special case ratio (interpreted proportion) p. 367: reporting two decimal places, sample size \\(N < 100\\) [single item], random mean value consistent approximately \\(N\\)% cases. Assuming \\(N = 70\\) inserting values formula returns \\[ \\frac{10^2-70×1}{10^2} = 0.3 \\] random mean inconsistent 30% cases , conversely, consistent 70%. code (assuming arbitrary mean two decimal places): Thus, regarding GRIM ratio make general formula explicit give name. Researchers may judge useful analyses.","code":"grim_ratio(x = 0.99, n = 70) #> [1] 0.3"},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"granularity-and-scale-items","dir":"Articles","previous_headings":"GRIM statistics","what":"Granularity and scale items","title":"GRIM","text":"granularity non-continuous distribution minimal amount two means proportions distribution can differ. derived sample size number scale items. number items, turn, naturally follows distribution’s sample size granularity.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"formulas","dir":"Articles","previous_headings":"GRIM statistics > Granularity and scale items","what":"Formulas","title":"GRIM","text":"granularity (\\(G\\)) formula \\[ G = \\frac{1}{NL} \\] \\(N\\) sample size \\(L\\) number items. scale items formula converse: \\[ L = \\frac{1}{NG} \\]","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/grim.html","id":"functions-1","dir":"Articles","previous_headings":"GRIM statistics > Granularity and scale items","what":"Functions","title":"GRIM","text":"Suppose ordinal distribution 80 observations five items. get granularity, run : Now, imagine distribution 50 observations granularity 0.01. get number items (actual effective), use code: number items granularity 1, call grim_items() doesn’t return whole numbers indicates problem earlier computations. warning effect displayed:","code":"grim_granularity(n = 80, items = 4) #> [1] 0.003125 grim_items(n = 50, gran = 0.01) #> [1] 2 grim_items(n = c(50, 65, 93), gran = 0.02) #> Warning: 2 out of 3 item counts aren't whole numbers. #> → This concerns `0.769` and `0.538`. #> ! Item counts have a granularity of 1, so they should be whole numbers. Are you #>   sure about the `n` and `gran` values? #> [1] 1.0000000 0.7692308 0.5376344"},{"path":[]},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"few-cases-grimmer","dir":"Articles","previous_headings":"Basic GRIMMER testing","what":"Few cases: grimmer()","title":"GRIMMER","text":"test reported mean 7.3 granular scale GRIMMER-consistent SD 2.51 sample size 12, run : Note x, reported mean, needs string. reason strings preserve trailing zeros, can crucial GRIMMER-testing. Numeric values don’t, even converting strings won’t help. workaround larger numbers values, restore_zeros(), discussed vignette(\"wrangling\"). grimmer() parameters, can used within grimmer_map(). parameters discussed context grimmer_map() often useful function practice. Furthermore, although grimmer() vectorized, grimmer_map() safer convenient testing multiple combinations means, SDs, sample sizes.","code":"grimmer(x = \"7.3\", sd = \"2.51\", n = 12) #>   7.3  #> FALSE"},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"many-cases-grimmer_map","dir":"Articles","previous_headings":"Basic GRIMMER testing","what":"Many cases: grimmer_map()","title":"GRIMMER","text":"want GRIMMER-test handful cases, recommended way enter data frame run grimmer_map() data frame. Two different ways discussed vignette(\"wrangling\"), , describe easily accessible solution single table. Copy summary data PDF file paste tibble::tribble(), available via scrutiny: Use RStudio’s multiple cursors draw quotation marks around x sd values, set commas end. See vignette(\"wrangling\"), section copy paste, sure . Now, simply run grimmer_map() data frame: x n columns input. default, number items composing mean assumed 1. main result, consistency, GRIMMER consistency former three columns. reason column says set values inconsistent. GRIMMER-consistent, value set needs pass four separate tests: three GRIMMER tests Allard (2018) basic GRIM test. , two inconsistent values passed GRIM well first two GRIMMER tests, failed third one. consistent value sets marked \"Passed \" \"reason\" column.","code":"flying_pigs1 <- tribble(   ~x,   ~sd, \"8.9\",  \"2.81\", \"2.6\",  \"2.05\", \"7.2\",  \"2.89\", \"3.6\",  \"3.11\", \"9.2\",  \"7.13\", \"10.4\", \"2.53\", \"7.3\",  \"3.14\" ) %>%    mutate(n = 25) grimmer_map(flying_pigs1) #> # A tibble: 7 × 5 #>   x     sd        n consistency reason                        #>   <chr> <chr> <dbl> <lgl>       <chr>                         #> 1 8.9   2.81     25 FALSE       GRIMMER inconsistent (test 3) #> 2 2.6   2.05     25 TRUE        Passed all                    #> 3 7.2   2.89     25 TRUE        Passed all                    #> 4 3.6   3.11     25 FALSE       GRIMMER inconsistent (test 3) #> 5 9.2   7.13     25 TRUE        Passed all                    #> 6 10.4  2.53     25 TRUE        Passed all                    #> 7 7.3   3.14     25 TRUE        Passed all"},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"scale-items","dir":"Articles","previous_headings":"Basic GRIMMER testing","what":"Scale items","title":"GRIMMER","text":"NOTE: Don’t use items argument. currently contains bug fixed scrutiny’s next CRAN release. mean composed multiple items, set items parameter number. hypothetical means three-items scale. single-item default, half wrongly flagged inconsistent: Yet, consistent correct number items stated: also possible include items column data frame instead:","code":"jpap_1 <- tribble(    ~x,    ~sd,   \"5.90\", \"2.19\",   \"5.71\", \"1.42\",   \"3.50\", \"1.81\",   \"3.82\", \"2.43\",   \"4.61\", \"1.92\",   \"5.24\", \"2.51\", ) %>%    mutate(n = 40)  jpap_1 %>%    grimmer_map()  # default is wrong here! #> # A tibble: 6 × 5 #>   x     sd        n consistency reason            #>   <chr> <chr> <dbl> <lgl>       <chr>             #> 1 5.90  2.19     40 TRUE        Passed all        #> 2 5.71  1.42     40 FALSE       GRIM inconsistent #> 3 3.50  1.81     40 TRUE        Passed all        #> 4 3.82  2.43     40 TRUE        Passed all        #> 5 4.61  1.92     40 FALSE       GRIM inconsistent #> 6 5.24  2.51     40 FALSE       GRIM inconsistent jpap_1 %>%    grimmer_map(items = 3) #> # A tibble: 6 × 5 #>   x     sd        n consistency reason     #>   <chr> <chr> <dbl> <lgl>       <chr>      #> 1 5.90  2.19    120 TRUE        Passed all #> 2 5.71  1.42    120 TRUE        Passed all #> 3 3.50  1.81    120 TRUE        Passed all #> 4 3.82  2.43    120 TRUE        Passed all #> 5 4.61  1.92    120 TRUE        Passed all #> 6 5.24  2.51    120 TRUE        Passed all jpap_2 <- tribble(    ~x,     ~sd,    ~items,   \"6.92\",  \"2.19\",  1,   \"3.48\",  \"1.42\",  1,   \"1.59\",  \"1.81\",  2,   \"2.61\",  \"2.43\",  2,   \"4.04\",  \"1.92\",  3,   \"4.50\",  \"2.51\",  3, ) %>%    mutate(n = 30)  jpap_2 %>%    grimmer_map() #> # A tibble: 6 × 5 #>   x     sd        n consistency reason            #>   <chr> <chr> <dbl> <lgl>       <chr>             #> 1 6.92  2.19     30 FALSE       GRIM inconsistent #> 2 3.48  1.42     30 FALSE       GRIM inconsistent #> 3 1.59  1.81     60 FALSE       GRIM inconsistent #> 4 2.61  2.43     60 FALSE       GRIM inconsistent #> 5 4.04  1.92     90 TRUE        Passed all        #> 6 4.50  2.51     90 TRUE        Passed all"},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"rounding","dir":"Articles","previous_headings":"Basic GRIMMER testing","what":"Rounding","title":"GRIMMER","text":"scrutiny package provides infrastructure reconstructing rounded numbers. can commanded within grimmer() grimmer_map(). Several parameters allow stating precise way original numbers supposedly rounded. First foremost rounding. takes string rounding procedure’s name, leads number rounded either ways: Rounded \"\" \"\" 5. Note SAS, SPSS, Stata, Matlab, Excel round \"\" 5, whereas Python used round \"\" 5. Rounded \"even\" using base R’s round(). Rounded \"up_from\" \"down_from\" number, needs specified via threshold parameter. Given \"ceiling\" \"floor\" respective decimal place. Rounded towards zero \"trunc\" away zero \"anti_trunc\". default, \"up_or_down\", allows numbers rounded either \"\" \"\" 5 GRIMMER-testing; likewise \"up_from_or_down_from\" \"ceiling_or_floor\". procedures, see documentation round(), round_up(), round_ceiling(). include ways rounding. Points 3 5 list quite obscure options included cover wide spectrum possible rounding procedures. true threshold symmetric parameters, aren’t discussed . Learn scrutiny’s infrastructure rounding vignette(\"rounding\"). default, grimmer() grimmer_map() accept values rounded either 5. reason impose stricter assumptions way x sd rounded, specify rounding accordingly. might still important account different ways numbers can rounded, demonstrate given results robust variable decisions. err side caution, default rounding permissive \"up_or_down\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"summarizing-results-with-audit","dir":"Articles","previous_headings":"","what":"Summarizing results with audit()","title":"GRIMMER","text":"Following call grimmer_map(), generic function audit() summarizes GRIMMER test results: columns — incons_cases: number GRIMMER-inconsistent value sets. all_cases: total number value sets. incons_rate: proportion GRIMMER-inconsistent value sets. fail_grim, fail_test1, fail_test2, fail_test3: number value sets failing GRIM test one three GRIMMER tests, respectively.","code":"flying_pigs1 %>%    grimmer_map() %>%    audit() #> # A tibble: 1 × 7 #>   incons_cases all_cases incons_rate fail_grim fail_test1 fail_test2 fail_test3 #>          <int>     <int>       <dbl>     <int>      <int>      <int>      <int> #> 1            2         7       0.286         0          0          0          2"},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"visualizing-results-with-grim_plot","dir":"Articles","previous_headings":"","what":"Visualizing results with grim_plot()","title":"GRIMMER","text":"GRIMMER currently dedicated visualization function scrutiny. However, grim_plot() accept output grimmer_map() just well grim_map():  However, grim_plot() fail object returned either two functions: See GRIM vignette section grim_plot() information.","code":"jpap_5 <- tribble(   ~x,      ~sd,    ~n,   \"7.19\",  \"1.19\",  54,   \"4.56\",  \"2.56\",  66,   \"0.42\",  \"1.29\",  59,   \"1.31\",  \"3.50\",  57,   \"3.48\",  \"3.65\",  66,   \"4.27\",  \"2.86\",  61,   \"6.21\",  \"2.15\",  62,   \"3.11\",  \"3.17\",  50,   \"5.39\",  \"2.37\",  68,   \"5.66\",  \"1.11\",  44, )   jpap_5 %>%    grimmer_map() %>%    grim_plot() #> → Also visualizing 3 GRIMMER inconsistencies. grim_plot(mtcars) #> Error in `grim_plot()`: #> ! `grim_plot()` needs GRIM or GRIMMER test results. #> ✖ `data` is not `grim_map()` or `grimmer_map()` output. #> ℹ The only exception is an \"empty\" plot that shows the background raster but no #>   empirical test results. Create such a plot by setting `show_data` to `FALSE`."},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"testing-numeric-sequences-with-grimmer_map_seq","dir":"Articles","previous_headings":"","what":"Testing numeric sequences with grimmer_map_seq()","title":"GRIMMER","text":"GRIMMER analysts might interested mean percentage value’s numeric neighborhood. Suppose found multiple GRIMMER inconsistencies example pigs5 data. might wonder whether due small reporting computing errors. Use grimmer_map_seq() GRIMMER-test values surrounding reported means sample sizes:","code":"out_seq1 <- grimmer_map_seq(pigs5) out_seq1 #> # A tibble: 180 × 7 #>    x     sd        n consistency reason             case var   #>    <chr> <chr> <dbl> <lgl>       <chr>             <int> <chr> #>  1 7.17  5.30     38 FALSE       GRIM inconsistent     1 x     #>  2 7.18  5.30     38 TRUE        Passed all            1 x     #>  3 7.19  5.30     38 FALSE       GRIM inconsistent     1 x     #>  4 7.20  5.30     38 FALSE       GRIM inconsistent     1 x     #>  5 7.21  5.30     38 TRUE        Passed all            1 x     #>  6 7.23  5.30     38 FALSE       GRIM inconsistent     1 x     #>  7 7.24  5.30     38 TRUE        Passed all            1 x     #>  8 7.25  5.30     38 FALSE       GRIM inconsistent     1 x     #>  9 7.26  5.30     38 TRUE        Passed all            1 x     #> 10 7.27  5.30     38 FALSE       GRIM inconsistent     1 x     #> # … with 170 more rows"},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"summaries-with-audit_seq","dir":"Articles","previous_headings":"Testing numeric sequences with grimmer_map_seq()","what":"Summaries with audit_seq()","title":"GRIMMER","text":"output little unwieldy, run audit_seq() results: output columns mean: x n original inputs, reconstructed tested consistency . hits number GRIMMER-consistent value combinations found within specified dispersion range. diff_x reports absolute difference x next consistent dispersed value (dispersion steps, actual numeric difference). diff_x_up diff_x_down report difference next higher lower consistent value, respectively. diff_n, diff_n_up, diff_n_down n. default dispersion 1:5, five steps . dispersion sequence gets longer, number hits tends increase:","code":"audit_seq(out_seq1) #> # A tibble: 6 × 17 #>   x     sd        n consi…¹ hits_…² hits_x hits_sd hits_n diff_x diff_…³ diff_…⁴ #>   <chr> <chr> <dbl> <lgl>     <int>  <int>   <int>  <int>  <dbl>   <dbl>   <dbl> #> 1 7.22  5.30     38 FALSE         8      4       0      4      1       2      -1 #> 2 5.23  2.55     35 FALSE        16      2      10      4      3       3      -3 #> 3 2.57  2.57     30 FALSE        11      1       8      2      3       3      NA #> 4 6.77  2.18     33 FALSE         6      4       0      2      1       2      -1 #> 5 7.01  6.68     35 FALSE         4      4       0      0      1       2      -1 #> 6 3.14  5.32     33 FALSE         9      4       0      5      1       1      -2 #> # … with 6 more variables: diff_sd <dbl>, diff_sd_up <dbl>, diff_sd_down <dbl>, #> #   diff_n <dbl>, diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated variable #> #   names ¹​consistency, ²​hits_total, ³​diff_x_up, ⁴​diff_x_down out_seq2 <- grimmer_map_seq(pigs5, dispersion = 1:10) audit_seq(out_seq2) #> # A tibble: 6 × 17 #>   x     sd        n consi…¹ hits_…² hits_x hits_sd hits_n diff_x diff_…³ diff_…⁴ #>   <chr> <chr> <dbl> <lgl>     <int>  <int>   <int>  <int>  <dbl>   <dbl>   <dbl> #> 1 7.22  5.30     38 FALSE        15      8       0      7      1       2      -1 #> 2 5.23  2.55     35 FALSE        32      6      19      7      3       3      -3 #> 3 2.57  2.57     30 FALSE        24      3      16      5      3       3      NA #> 4 6.77  2.18     33 FALSE        11      7       0      4      1       2      -1 #> 5 7.01  6.68     35 FALSE         8      8       0      0      1       2      -1 #> 6 3.14  5.32     33 FALSE        14      7       0      7      1       1      -2 #> # … with 6 more variables: diff_sd <dbl>, diff_sd_up <dbl>, diff_sd_down <dbl>, #> #   diff_n <dbl>, diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated variable #> #   names ¹​consistency, ²​hits_total, ³​diff_x_up, ⁴​diff_x_down"},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"visualizing-grimmer-tested-sequences","dir":"Articles","previous_headings":"Testing numeric sequences with grimmer_map_seq()","what":"Visualizing GRIMMER-tested sequences","title":"GRIMMER","text":"’s curious happens plot output grimmer_map_seq(). Like regular GRIM GRIMMER plots, however, give us sense many tested values consistent:  crosses appear grimmer_map_seq() creates sequences around x n. Restrict process one var argument:","code":"grim_plot(out_seq1) #> → Also visualizing 4 GRIMMER inconsistencies. out_seq1_only_x <- grimmer_map_seq(pigs5, var = \"x\") out_seq1_only_n <- grimmer_map_seq(pigs5, var = \"n\")  grim_plot(out_seq1_only_x) #> → Also visualizing 1 GRIMMER inconsistency. grim_plot(out_seq1_only_n) #> → Also visualizing 1 GRIMMER inconsistency."},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/grimmer.html","id":"problems-from-underreporting","dir":"Articles","previous_headings":"Handling unknown group sizes with grimmer_map_total_n()","what":"Problems from underreporting","title":"GRIMMER","text":"Unfortunately, studies report group averages don’t report corresponding group sizes — total sample size. makes direct GRIMMER-testing impossible x values known, n values. feasible terms GRIMMER take number around half total sample size, go , check hypothetical group sizes consistent reported group means. grimmer_map_total_n() semi-automates process, motivated recent GRIM analysis (Bauer Francis 2021). example: See GRIM vignette, section Handling unknown group sizes grim_map_total_n(), comprehensive case study. uses grim_map_total_n(), grimmer_map_total_n() GRIM.","code":"jpap_6 <- tibble::tribble(     ~x1,    ~x2,    ~sd1,   ~sd2,   ~n,     \"3.43\", \"5.28\", \"1.09\", \"2.12\", 70,     \"2.97\", \"4.42\", \"0.43\", \"1.65\", 65 )  out_total_n <- grimmer_map_total_n(jpap_6) out_total_n #> # A tibble: 48 × 9 #>    x     sd        n n_change consistency both_consistent reason      case dir   #>    <chr> <chr> <dbl>    <dbl> <lgl>       <lgl>           <chr>      <int> <chr> #>  1 3.43  1.09     35        0 FALSE       FALSE           GRIMMER i…     1 forth #>  2 5.28  2.12     35        0 FALSE       FALSE           GRIM inco…     1 forth #>  3 3.43  1.09     34       -1 FALSE       FALSE           GRIM inco…     1 forth #>  4 5.28  2.12     36        1 FALSE       FALSE           GRIMMER i…     1 forth #>  5 3.43  1.09     33       -2 FALSE       FALSE           GRIM inco…     1 forth #>  6 5.28  2.12     37        2 FALSE       FALSE           GRIM inco…     1 forth #>  7 3.43  1.09     32       -3 FALSE       FALSE           GRIM inco…     1 forth #>  8 5.28  2.12     38        3 FALSE       FALSE           GRIM inco…     1 forth #>  9 3.43  1.09     31       -4 FALSE       FALSE           GRIM inco…     1 forth #> 10 5.28  2.12     39        4 FALSE       FALSE           GRIMMER i…     1 forth #> # … with 38 more rows  audit_total_n(out_total_n) #> # A tibble: 2 × 10 #>   x1    x2    sd1   sd2       n hits_total hits_forth hits_back scenar…¹ hit_r…² #>   <chr> <chr> <chr> <chr> <dbl>      <dbl>      <dbl>     <dbl>    <dbl>   <dbl> #> 1 3.43  5.28  1.09  2.12     70          1          1         0       12  0.0833 #> 2 2.97  4.42  0.43  1.65     65          1          0         1       12  0.0833 #> # … with abbreviated variable names ¹​scenarios_total, ²​hit_rate"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/infrastructure.html","id":"count-decimal-places","dir":"Articles","previous_headings":"","what":"Count decimal places","title":"General infrastructure","text":"Large parts package ultimately rest either two functions simply count decimal places. digits number’s decimal point separator. functions also take strings. decimal_places() vectorized: Using strings (coercible numeric) recommended error detection context trailing zeros can crucial . Numeric values drop trailing zeros, whereas strings preserve : decimal_places_scalar() faster decimal_places() takes single number string. makes suitable helper within single-case functions.","code":"decimal_places(\"2.80\") #> [1] 2  decimal_places(c(55.1, 6.493, 8)) #> [1] 1 3 0  vec1 <- iris %>%    dplyr::slice(1:10) %>%    dplyr::pull(Sepal.Length)  vec1 #>  [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9  vec1 %>%    decimal_places() #>  [1] 1 1 1 1 0 1 1 0 1 1 decimal_places(7.200) #> [1] 1  decimal_places(\"7.200\") #> [1] 3"},{"path":"https://lhdjung.github.io/scrutiny/articles/infrastructure.html","id":"restore-trailing-zeros","dir":"Articles","previous_headings":"","what":"Restore trailing zeros","title":"General infrastructure","text":"dealing numbers used trailing zeros lost registered numeric, call restore_zeros() format correctly. can relevant within functions create vectors trailing zeros matter, seq_*() functions presented next section. Suppose following numbers originally one decimal place, longer : Now, get back restore_zeros(): uses default going longest mantissa padding strings decimal zeros many decimal places. However, just heuristic: longest mantissa might lost decimal places. Specify width argument explicitly state desired mantissa length:","code":"vec2 <- c(4, 6.9, 5, 4.2, 4.8, 7, 4)  vec2 %>%    decimal_places() #> [1] 0 1 0 1 1 0 0 vec2 %>%    restore_zeros() #> [1] \"4.0\" \"6.9\" \"5.0\" \"4.2\" \"4.8\" \"7.0\" \"4.0\"  vec2 %>%    restore_zeros() %>%    decimal_places() #> [1] 1 1 1 1 1 1 1 vec2 %>%    restore_zeros(width = 2) #> [1] \"4.00\" \"6.90\" \"5.00\" \"4.20\" \"4.80\" \"7.00\" \"4.00\"  vec2 %>%    restore_zeros(width = 2) %>%    decimal_places() #> [1] 2 2 2 2 2 2 2"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/infrastructure.html","id":"introduction","dir":"Articles","previous_headings":"Sequence generation","what":"Introduction","title":"General infrastructure","text":"base::seq() offers flexible way generate sequences, cut working decimal numbers. argument allows manual specifications step size, .e., difference two consecutive output values. error detection context, also problem trailing zeros numeric values. Use scrutiny’s seq_*() functions automatically determine step size input numbers , default, supply missing trailing zeros via restore_zeros(). Output naturally string. multiple functions? first two disentangle two different ways seq() can used. third function adds way generating sequences directly covered seq(). seq_endpoint() takes two main arguments, . creates sequence two, inferring step size greater number decimal places among . corresponds seq() call specified. seq_distance() takes argument, uses infer step size, creates sequence length specified length_out argument (default 10). corresponds seq() call length.specified. Finally, seq_disperse() creates sequence centered around . functions *_df() variant embeds sequence tibble column.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/infrastructure.html","id":"examples","dir":"Articles","previous_headings":"Sequence generation","what":"Examples","title":"General infrastructure","text":"seq_*() functions features, offsets direction reversal, ’ll focus basics . Call seq_endpoint() bridge two numbers correct decimal level: Call seq_distance() get sequence desired length: Finally, call seq_disperse() construct sequence around : seq_disperse() hybrid two seq() wrappers explained disperse*() functions introduced next.","code":"seq_endpoint(from = 4.1, to = 6) #>  [1] \"4.1\" \"4.2\" \"4.3\" \"4.4\" \"4.5\" \"4.6\" \"4.7\" \"4.8\" \"4.9\" \"5.0\" \"5.1\" \"5.2\" #> [13] \"5.3\" \"5.4\" \"5.5\" \"5.6\" \"5.7\" \"5.8\" \"5.9\" \"6.0\"  seq_endpoint(from = 4.1, to = 4.15) #> [1] \"4.10\" \"4.11\" \"4.12\" \"4.13\" \"4.14\" \"4.15\" seq_distance(from = 4.1, length_out = 3) #> [1] \"4.1\" \"4.2\" \"4.3\"  # Default for `length_out` is `10`: seq_distance(from = 4.1) #>  [1] \"4.1\" \"4.2\" \"4.3\" \"4.4\" \"4.5\" \"4.6\" \"4.7\" \"4.8\" \"4.9\" \"5.0\" seq_disperse(from = 4.1, dispersion = 1:3) #> [1] \"3.8\" \"3.9\" \"4.0\" \"4.1\" \"4.2\" \"4.3\" \"4.4\"  # Default for `dispersion` if `1:5`: seq_disperse(from = 4.1) #>  [1] \"3.6\" \"3.7\" \"3.8\" \"3.9\" \"4.0\" \"4.1\" \"4.2\" \"4.3\" \"4.4\" \"4.5\" \"4.6\""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/infrastructure.html","id":"general-points","dir":"Articles","previous_headings":"Sequence testing","what":"General points","title":"General infrastructure","text":"Four predicate functions test whether vector x represents particular kinds sequences. testing functions can used helpers, also analytic tools right. is_seq_linear() returns TRUE difference neighboring values : is_seq_ascending() tests whether difference always positive… …whereas is_seq_descending() tests whether always negative: is_seq_dispersed() tests whether vector grouped around argument:","code":"is_seq_linear(x = 8:15) #> [1] TRUE is_seq_linear(x = c(8:15, 16)) #> [1] TRUE is_seq_linear(x = c(8:15, 17)) #> [1] FALSE is_seq_ascending(x = 8:15) #> [1] TRUE is_seq_ascending(x = 15:8) #> [1] FALSE  # Default also tests for linearity: is_seq_ascending(x = c(8:15, 17)) #> [1] FALSE is_seq_ascending(x = c(8:15, 17), test_linear = FALSE) #> [1] TRUE is_seq_descending(x = 8:15) #> [1] FALSE is_seq_descending(x = 15:8) #> [1] TRUE  # Default also tests for linearity: is_seq_descending(x = c(15:8, 2)) #> [1] FALSE is_seq_descending(x = c(15:8, 2), test_linear = FALSE) #> [1] TRUE is_seq_dispersed(x = 3:7, from = 2) #> [1] FALSE  # Direction doesn't matter here: is_seq_dispersed(x = 3:7, from = 5) #> [1] TRUE is_seq_dispersed(x = 7:3, from = 5) #> [1] TRUE  # Dispersed from `50`, but not linear: x_nonlinear <- c(49, 42, 47, 44, 50, 56, 53, 58, 51)  # Default also tests for linearity: is_seq_dispersed(x = x_nonlinear, from = 50) #> [1] FALSE is_seq_dispersed(x = x_nonlinear, from = 50, test_linear = FALSE) #> [1] TRUE"},{"path":"https://lhdjung.github.io/scrutiny/articles/infrastructure.html","id":"na-handling","dir":"Articles","previous_headings":"Sequence testing","what":"NA handling","title":"General infrastructure","text":"is_seq_*() functions take special care missing values. one elements x NA, doesn’t necessarily mean ’s unknown whether x might possibly represent kind sequence question. examples, genuinely unclear whether x linear: Linearity thus depends unknown, missing value behind NA: Sometimes, however, x possibly represent tested kind sequence, independently hypothetical numbers substituted NA elements. cases, scrutiny’s is_seq_*() functions always return FALSE: much spirit consistency testing. Even certain data unknown, still makes sense check whether data possibly fill gaps. is_seq_*() functions effectively ask: numbers left right NAs consistent , given index positions? worth emphasizing behavior exotic, specific scrutiny. simply asserts fundamental ideas NA propagation R. example, is_seq_ascending(x = c(1, 2, NA, 1)) FALSE reason NA & FALSE FALSE: outcome possible values NA (Wickham 2019, ch. 3.2.3). Leading trailing NAs mostly ignored determining whether x might kind sequence question: exception, is_seq_dispersed(), particularly sensitive NA values:","code":"is_seq_linear(x = c(1, 2, NA, 4)) #> [1] NA is_seq_linear(x = c(1, 2, NA, NA, NA, 6)) #> [1] NA is_seq_linear(x = c(1, 2, 3, 4)) #> [1] TRUE is_seq_linear(x = c(1, 2, 7, 4)) #> [1] FALSE  is_seq_linear(x = c(1, 2, 3, 4, 5, 6)) #> [1] TRUE is_seq_linear(x = c(1, 2, 17, 29, 32, 6)) #> [1] FALSE is_seq_linear(x = c(1, 2, NA, 10)) #> [1] FALSE is_seq_linear(x = c(1, 2, NA, NA, NA, 10)) #> [1] FALSE is_seq_linear(x = c(NA, NA, 1, 2, 3, 4, NA)) #> [1] NA is_seq_linear(x = c(NA, NA, 1, 2, NA, 4, NA)) #> [1] NA # `TRUE` because `x` is symmetrically dispersed # from 5 and contains no `NA` values: is_seq_dispersed(x = c(3:7), from = 5) #> [1] TRUE  # `NA` because it might be dispersed from 5, # depending on the values hidden behind the `NA`s: is_seq_dispersed(x = c(NA, 3:7, NA), from = 5) #> [1] NA is_seq_dispersed(x = c(NA, NA, 3:7, NA, NA), from = 5) #> [1] NA  # `FALSE` because it's not symmetrically dispersed # around 5, no matter what the `NA`s stand in for: is_seq_dispersed(x = c(NA, 3:7), from = 5) #> [1] FALSE is_seq_dispersed(x = c(3:7, NA), from = 5) #> [1] FALSE is_seq_dispersed(x = c(3:7, NA, NA), from = 5) #> [1] FALSE is_seq_dispersed(x = c(NA, NA, 3:7), from = 5) #> [1] FALSE"},{"path":"https://lhdjung.github.io/scrutiny/articles/infrastructure.html","id":"disperse-from-around-half-with-disperse_total","dir":"Articles","previous_headings":"","what":"Disperse from (around) half with disperse_total()","title":"General infrastructure","text":"Briefly, disperse_total() checks input total even odd, cuts half, creates “dispersed” group sizes going , pair group sizes adding input total. works naturally even totals. odd totals, starts two integers closest half. function internally calls either disperse() disperse2(), recommend simply using higher-level disperse_total(). two basic examples:","code":"# With an even total... disperse_total(n = 70) #> # A tibble: 12 × 2 #>        n n_change #>    <dbl>    <dbl> #>  1    35        0 #>  2    35        0 #>  3    34       -1 #>  4    36        1 #>  5    33       -2 #>  6    37        2 #>  7    32       -3 #>  8    38        3 #>  9    31       -4 #> 10    39        4 #> 11    30       -5 #> 12    40        5  # ...and with an odd total: disperse_total(n = 83) #> # A tibble: 12 × 2 #>        n n_change #>    <dbl>    <dbl> #>  1    41        0 #>  2    42        0 #>  3    40       -1 #>  4    43        1 #>  5    39       -2 #>  6    44        2 #>  7    38       -3 #>  8    45        3 #>  9    37       -4 #> 10    46        4 #> 11    36       -5 #> 12    47        5"},{"path":"https://lhdjung.github.io/scrutiny/articles/infrastructure.html","id":"test-for-subsets-supersets-and-equal-sets","dir":"Articles","previous_headings":"","what":"Test for subsets, supersets, and equal sets","title":"General infrastructure","text":"Starting is_subset_of(), scrutiny features distinctive family predicate functions test whether one vector x subset another vector y, whether x superset y (.e. reverse subset), whether x y equal sets. teaser: functions divided three subgroups based way second vector, y, constituted. example, might test x subset multiple vectors taken together, superset vector y consists multiple values entered along x. Functions family currently used helpers inside scrutiny functions, may well change. Use elsewhere also conceivable.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/rounding.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Rounding","text":"Base R’s round() function surprisingly sophisticated, distinguishes simple ways decimal numbers normally rounded — time, rounding 5. reason, however, can’t used reconstruct rounding procedures software programs. job scrutiny’s rounding functions. First, present reround(), general interface reconstructing rounded numbers, going individual rounding functions. add comments . also discuss unround(), works reverse way: takes rounded number reconstructs bounds original number, taking details assumed rounding procedure account. Finally, take closer look bias rounding raw numbers.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/rounding.html","id":"reconstruct-rounded-numbers-with-reround","dir":"Articles","previous_headings":"","what":"Reconstruct rounded numbers with reround()","title":"Rounding","text":"None error detection techniques scrutiny calls individual rounding functions directly. Instead, call reround(), mediates two levels. reround() takes vector “raw” reconstructed numbers yet rounded way ’s assumed original rounding procedure. next argument digits, number decimal places round . remaining three arguments rounding procedure. time, rounding interest. takes string name one rounding procedures discussed . example reround() call: two remaining arguments mostly forgettable: concern obscure cases rounding threshold 5 (threshold) rounding absolute values positive negative numbers (symmetric). Ignore otherwise.","code":"reround(x = c(5.812, 7.249), digits = 2, rounding = \"up\") #> [1] 5.81 7.25"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/rounding.html","id":"up-and-down","dir":"Articles","previous_headings":"Rounding procedures in detail","what":"Up and down","title":"Rounding","text":"round_up() people think rounding. decimal portion cut rounding 5 greater, rounds . Otherwise, rounds . SAS, SPSS, Stata, Matlab, Excel use procedure. Rounding 5 actually special case round_up_from(), can take numeric threshold, just 5: two functions mirror images round_down() round_down_from(). arguments round_up(): round_down_from(), , just reverse round_up_from():","code":"round_up(x = 1.24, digits = 1) #> [1] 1.2  round_up(x = 1.25, digits = 1) #> [1] 1.3  round_up(x = 1.25)  # default for `digits` is 0 #> [1] 1 round_up_from(x = 4.28, digits = 1, threshold = 9) #> [1] 4.2  round_up_from(x = 4.28, digits = 1, threshold = 1) #> [1] 4.3 round_down(x = 1.24, digits = 1) #> [1] 1.2  round_down(x = 1.25, digits = 1) #> [1] 1.2  round_down(x = 1.25)  # default for `digits` is 0 #> [1] 1 round_down_from(x = 4.28, digits = 1, threshold = 9) #> [1] 4.3  round_down_from(x = 4.28, digits = 1, threshold = 1) #> [1] 4.2"},{"path":"https://lhdjung.github.io/scrutiny/articles/rounding.html","id":"to-even-base-r","dir":"Articles","previous_headings":"Rounding procedures in detail","what":"To even (base R)","title":"Rounding","text":"Like Python’s round() function, R’s base::round() doesn’t round , use procedure based solely truncated part number. Instead, round() strives round next even number. also called “banker’s rounding”, follows technical standard, IEEE 754. Realizing round() works highly unintuitive way sometimes leads consternation. can’t just round like learned school, , 5? reason seems bias. 5 right two whole numbers, procedure rounds 5 predetermined direction introduces bias toward direction. Rounding 5 therefore biased upward, rounding 5 biased downward. shown Rounding bias section , unlikely major issue rounding raw numbers originally many decimal places. might serious, however, initial number decimal places low (whatever reason) need precision high. least theory, “rounding even” biased either direction, preserves mean original distribution. round() aims operate. case works , whereas bias rounding fully apparent: However, noble goal unbiased rounding runs reality floating point arithmetic. might therefore get results round() first seem bizarre, least unpredictable. Consider: Sometimes round() behaves just , times, results can hard explain. Martin Mächler, wrote present version round(), describes issue follows: reason behavior decimal fractions can’t, fact, represented double precision numbers. Even seemingly “clean” numbers decimal places come long invisible mantissa, therefore closer one side . usually think rounding rules breaking tie occurs 5. floating-point numbers, however, just somewhat less greater 5. tie! Consequently, Mächler says, rounding functions need “measure, guess two possible decimals closer x” — therefore, way round. seems better going mathematical intuitions may always correspond way computers actually deal issues. R using present solution since version 4.0.0. base::round() can seem like black box, seems unbiased long run. recommend using round() original work, even though quite different rounding procedures — therefore unsuitable reconstructing . Instead, need something like scrutiny’s round_*() functions.","code":"vec1 <- seq(from = 0.5, to = 9.5) up1 <- round_up(vec1) down1 <- round_down(vec1) even1 <- round(vec1)  vec1 #>  [1] 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 up1 #>  [1]  1  2  3  4  5  6  7  8  9 10 down1 #>  [1] 0 1 2 3 4 5 6 7 8 9 even1 #>  [1]  0  2  2  4  4  6  6  8  8 10  # Original mean mean(vec1) #> [1] 5  # Means when rounding up or down: bias! mean(up1) #> [1] 5.5 mean(down1) #> [1] 4.5  # Mean when rounding to even: no bias mean(even1) #> [1] 5 vec2 <- seq(from = 4.5, to = 10.5)  up2 <- round_up(vec2) down2 <- round_down(vec2) even2 <- round(vec2)  vec1 #>  [1] 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 up2 #> [1]  5  6  7  8  9 10 11 down2 #> [1]  4  5  6  7  8  9 10 even2  # No symmetry here... #> [1]  4  6  6  8  8 10 10  mean(vec2) #> [1] 7.5 mean(up2) #> [1] 8 mean(down2) #> [1] 7 mean(even2)  # ... and the mean is slightly biased downward! #> [1] 7.428571   vec3 <- c(   1.05, 1.15, 1.25, 1.35, 1.45,   1.55, 1.65, 1.75, 1.85, 1.95 )  # No bias here, though: round(vec3, 1) #>  [1] 1.0 1.1 1.2 1.4 1.4 1.6 1.6 1.8 1.9 2.0 mean(vec3) #> [1] 1.5 mean(round(vec3, 1)) #> [1] 1.5"},{"path":"https://lhdjung.github.io/scrutiny/articles/rounding.html","id":"reconstruct-rounding-bounds-with-unround","dir":"Articles","previous_headings":"","what":"Reconstruct rounding bounds with unround()","title":"Rounding","text":"Rounding leads loss information. mantissa cut part full, resulting number underdetermined respect original number: latter can’t inferred former. might interest, however, compute range original number given rounded number (especially number decimal places rounded) presumed rounding method. ’s often easy infer range, better computer . Enter unround(). returns lower upper bounds, says whether bounds inclusive — something varies greatly rounding procedure. Currently, unround() used helper within scrutiny’s DEBIT implementation; see vignette(\"debit\"). default rounding procedure unround() \"up_or_down\": complete list featured rounding procedures, see documentation unround(), section Rounding. left, range column displays pithy graphical overview columns (except rounding) order: lower lower bound original number. incl_lower TRUE lower bound inclusive FALSE otherwise. x input value. incl_upper TRUE upper bound inclusive FALSE otherwise. upper upper bound original number. default, decimal places counted internally function always operates appropriate decimal level. creates need take trailing zeros account, x needs string: Alternatively, function uses unround() helper might count decimal places (.e., internally calling decimal_places()). pass numbers unround() via decimals argument instead letting redundantly count decimal places second time. case, x can numeric trailing zeros longer needed. (, turn, responsibility count decimal places number-strings rather numeric values shifts unround() higher-level function.) following call returns exact tibble : Since x vectorized, might test several reported numbers :","code":"unround(x = \"8.0\") #> # A tibble: 1 × 7 #>   range                  rounding   lower incl_lower x     incl_upper upper #>   <chr>                  <chr>      <dbl> <lgl>      <chr> <lgl>      <dbl> #> 1 7.95 <= x(8.0) <= 8.05 up_or_down  7.95 TRUE       8.0   TRUE        8.05 unround(x = \"3.50\", rounding = \"up\") #> # A tibble: 1 × 7 #>   range                    rounding lower incl_lower x     incl_upper upper #>   <chr>                    <chr>    <dbl> <lgl>      <chr> <lgl>      <dbl> #> 1 3.495 <= x(3.50) < 3.505 up        3.50 TRUE       3.50  FALSE       3.50 unround(x = 3.5, digits = 2, rounding = \"up\") #> # A tibble: 1 × 7 #>   range                   rounding lower incl_lower     x incl_upper upper #>   <chr>                   <chr>    <dbl> <lgl>      <dbl> <lgl>      <dbl> #> 1 3.495 <= x(3.5) < 3.505 up        3.50 TRUE         3.5 FALSE       3.50 vec2 <- c(2, 3.1, 3.5) %>%    restore_zeros()  vec2   # `restore_zeros()` returns \"2.0\" for 2 #> [1] \"2.0\" \"3.1\" \"3.5\"  vec2 %>%    unround(rounding = \"even\") #> # A tibble: 3 × 7 #>   range                rounding lower incl_lower x     incl_upper upper #>   <chr>                <chr>    <dbl> <lgl>      <chr> <lgl>      <dbl> #> 1 1.95 < x(2.0) < 2.05 even      1.95 FALSE      2.0   FALSE       2.05 #> 2 3.05 < x(3.1) < 3.15 even      3.05 FALSE      3.1   FALSE       3.15 #> 3 3.45 < x(3.5) < 3.55 even      3.45 FALSE      3.5   FALSE       3.55"},{"path":"https://lhdjung.github.io/scrutiny/articles/rounding.html","id":"fractional-rounding","dir":"Articles","previous_headings":"","what":"Fractional rounding","title":"Rounding","text":"want round numbers fraction instead integer? Check reround_to_fraction() reround_to_fraction_level(): function rounds 0.4 0.5 ’s closest fraction 2. inspired janitor::round_to_fraction(), credit core implementation goes . reround_to_fraction() blends janitor’s fractional rounding flexibility precision reround() provides. ’s , reround_to_fraction_level() rounds nearest fraction decimal level specified via digits argument: two functions currently part error detection workflow.","code":"reround_to_fraction(x = 0.4, denominator = 2, rounding = \"up\") #> [1] 0.5 reround_to_fraction_level(   x = 0.777, denominator = 5, digits = 0, rounding = \"down\" ) #> [1] 0.8 reround_to_fraction_level(   x = 0.777, denominator = 5, digits = 1, rounding = \"down\" ) #> [1] 0.78 reround_to_fraction_level(   x = 0.777, denominator = 5, digits = 2, rounding = \"down\" ) #> [1] 0.776"},{"path":"https://lhdjung.github.io/scrutiny/articles/rounding.html","id":"rounding-bias","dir":"Articles","previous_headings":"","what":"Rounding bias","title":"Rounding","text":"wrote rounding 5 biased. However, points wider problem: true rounding procedure doesn’t take active precautions bias. base::round() , recommend original work (opposed reconstruction). might useful general flexible way quantify far rounding biases distribution, compared looked like rounding. function rounding_bias() fulfills role. wrapper around reround(), can access rounding procedure reround() can, takes arguments. However, default rounding \"\" instead \"up_or_down\" rounding_bias() makes sense single rounding procedures. general, bias due rounding computed subtracting original distribution rounded one: \\[ bias = x_{rounded} - x \\] default, mean computed reduce bias single data point: Set mean FALSE return whole vector individual biases instead: Admittedly, example somewhat overdramatic. rather harmless one: responsible difference? seems (1) sample size (2) number decimal places vector rounded. rounding method doesn’t appear matter numbers many decimal places rounded:  However, raw values preliminarily rounded 2 decimal places rounding proceeds , picture different:  sum, function allows users quantify degree rounding biases distribution, can assess relative merits different rounding procedures. partly sensitize readers potential bias edge cases, also enable make informed rounding decisions .","code":"vec3 <- seq(from = 0.6, to = 0.7, by = 0.01)  vec3 #>  [1] 0.60 0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69 0.70  # The mean before rounding... mean(vec3) #> [1] 0.65  # ...is not the same as afterwards... mean(round_up(vec3)) #> [1] 1  # ...and the difference is bias: rounding_bias(x = vec3, digits = 0, rounding = \"up\") #> [1] 0.35 rounding_bias(x = vec3, digits = 0, rounding = \"up\", mean = FALSE) #>  [1] 0.40 0.39 0.38 0.37 0.36 0.35 0.34 0.33 0.32 0.31 0.30 vec4 <- rnorm(50000, 100, 15)  rounding_bias(vec4, digits = 2) #> [1] 1.574561e-05 #> # A tibble: 10 × 3 #>             bias decimal_digits rounding #>            <dbl> <chr>          <chr>    #>  1 0.000168      1 up           up       #>  2 0.0000157     2 up           up       #>  3 0.0000000744  3 up           up       #>  4 0.0000000184  4 up           up       #>  5 0.00000000999 5 up           up       #>  6 0.000168      1 even         even     #>  7 0.0000157     2 even         even     #>  8 0.0000000744  3 even         even     #>  9 0.0000000184  4 even         even     #> 10 0.00000000999 5 even         even #> # A tibble: 10 × 3 #>        bias decimal_digits rounding #>       <dbl> <chr>          <chr>    #>  1 0.00515  1 up           up       #>  2 0        2 up           up       #>  3 0        3 up           up       #>  4 0        4 up           up       #>  5 0        5 up           up       #>  6 0.000244 1 even         even     #>  7 0        2 even         even     #>  8 0        3 even         even     #>  9 0        4 even         even     #> 10 0        5 even         even"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/wrangling.html","id":"motivation","dir":"Articles","previous_headings":"Trailing zeros","what":"Motivation","title":"Data wrangling","text":"One particular challenge looking numeric irregularities using R numbers often treated strings. reason numeric values don’t preserve trailing zeros. major problem trailing zeros important , e.g., GRIM DEBIT trailing digits . solution know work strings — namely, strings can converted non-NA numeric values. discuss two ways work : (1) directly entering importing numbers strings, (2) restoring trailing zeros.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/wrangling.html","id":"automated","dir":"Articles","previous_headings":"Trailing zeros > Enter numbers as strings","what":"Automated","title":"Data wrangling","text":"Several R packages help extract tables PDF. recommend tabulizer (currently CRAN; see installation notes). also pdftables pdftools packages. Using tabulizer requires Java installed. works well, tabulizer great tool importing tables quickly efficiently. automatically captures values strings, trailing zeros treated just like digits. However, tabulizer might sometimes struggle, especially older PDF files. likely fault PDF format inbuilt support tables, effort extract faces serious ambiguities. (See , Replace column names row values, solution one issue.) many tables multiple files formatted way, can useful check tabulizer reliably accurately captures . doesn’t, might use copy paste.","code":""},{"path":"https://lhdjung.github.io/scrutiny/articles/wrangling.html","id":"with-copy-and-paste","dir":"Articles","previous_headings":"Trailing zeros > Enter numbers as strings","what":"With copy and paste","title":"Data wrangling","text":"Perhaps R users know RStudio features option multiple cursors. especially useful conjunction tibble::tribble(), available via scrutiny. ’s use multiple cursors present context: Copy column numbers PDF, pressing holding Alt Windows option Mac. (works least Adobe Acrobat.) Paste tribble() call . Pressing holding Alt/option, select copied numbers. Enter quotation marks , tribble()’s syntax, comma. get something like : ’s missing sample size. Add either via another tribble() column via dplyr::mutate(), also comes scrutiny:","code":"flights1 <- tribble(   ~x, \"8.97\", \"2.61\", \"7.26\", \"3.64\", \"9.26\", \"10.46\", \"7.39\", ) flights1 <- flights1 %>%    mutate(n = 28)  flights1 #> # A tibble: 7 × 2 #>   x         n #>   <chr> <dbl> #> 1 8.97     28 #> 2 2.61     28 #> 3 7.26     28 #> 4 3.64     28 #> 5 9.26     28 #> 6 10.46    28 #> 7 7.39     28"},{"path":"https://lhdjung.github.io/scrutiny/articles/wrangling.html","id":"restore-trailing-zeros","dir":"Articles","previous_headings":"Trailing zeros","what":"Restore trailing zeros","title":"Data wrangling","text":"dealing numbers used trailing zeros lost registered numeric, call restore_zeros() format correctly. Suppose following numbers originally one decimal place, longer : Now, get back restore_zeros(): uses default going longest mantissa padding strings decimal zeros many decimal places. However, just heuristic: longest mantissa might lost decimal places. Specify width argument explicitly state desired mantissa length: convenient way restore trailing zeros data frame restore_zeros_df(). default, operates columns coercible numeric (factors don’t count): Specify columns mostly like dplyr::select():","code":"vec <- c(4, 6.9, 5, 4.2, 4.8, 7, 4)  vec %>%    decimal_places() #> [1] 0 1 0 1 1 0 0 vec %>%    restore_zeros() #> [1] \"4.0\" \"6.9\" \"5.0\" \"4.2\" \"4.8\" \"7.0\" \"4.0\"  vec %>%    restore_zeros() %>%    decimal_places() #> [1] 1 1 1 1 1 1 1 vec %>%    restore_zeros(width = 2) #> [1] \"4.00\" \"6.90\" \"5.00\" \"4.20\" \"4.80\" \"7.00\" \"4.00\"  vec %>%    restore_zeros(width = 2) %>%    decimal_places() #> [1] 2 2 2 2 2 2 2 iris <- as_tibble(iris) iris %>%    restore_zeros_df(width = 3) #> # A tibble: 150 × 5 #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>    <chr>        <chr>       <chr>        <chr>       <fct>   #>  1 5.100        3.500       1.400        0.200       setosa  #>  2 4.900        3.000       1.400        0.200       setosa  #>  3 4.700        3.200       1.300        0.200       setosa  #>  4 4.600        3.100       1.500        0.200       setosa  #>  5 5.000        3.600       1.400        0.200       setosa  #>  6 5.400        3.900       1.700        0.400       setosa  #>  7 4.600        3.400       1.400        0.300       setosa  #>  8 5.000        3.400       1.500        0.200       setosa  #>  9 4.400        2.900       1.400        0.200       setosa  #> 10 4.900        3.100       1.500        0.100       setosa  #> # … with 140 more rows iris %>%    restore_zeros_df(starts_with(\"Sepal\"), width = 3) #> # A tibble: 150 × 5 #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>    <chr>        <chr>              <dbl>       <dbl> <fct>   #>  1 5.100        3.500                1.4         0.2 setosa  #>  2 4.900        3.000                1.4         0.2 setosa  #>  3 4.700        3.200                1.3         0.2 setosa  #>  4 4.600        3.100                1.5         0.2 setosa  #>  5 5.000        3.600                1.4         0.2 setosa  #>  6 5.400        3.900                1.7         0.4 setosa  #>  7 4.600        3.400                1.4         0.3 setosa  #>  8 5.000        3.400                1.5         0.2 setosa  #>  9 4.400        2.900                1.4         0.2 setosa  #> 10 4.900        3.100                1.5         0.1 setosa  #> # … with 140 more rows"},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/articles/wrangling.html","id":"basic-usage","dir":"Articles","previous_headings":"Split strings by parentheses","what":"Basic usage","title":"Data wrangling","text":"summary data copied extracted PDF (see ), might encounter values presented like 5.22 (0.73). Instead manually teasing apart, call split_by_parens(): Optionally, transform values useful format: , can call debit_map() almost right away (supposing deal binary distributions’ means standard deviations): strings look like \"2.65 [0.27]\", specify .sep argument \"brackets\". Likewise \"2.65 {0.27}\" .sep = \"braces\". separators, \"2.65 <0.27>\"? Specify .sep two substrings, like .sep = c(\"<\", \">\"). cases, output default strings like \"2.65 (0.27)\".","code":"flights2 <- tribble(   ~drone,           ~selfpilot,   \"0.09 (0.21)\",    \"0.19 (0.13)\",   \"0.19 (0.28)\",    \"0.53 (0.10)\",   \"0.62 (0.16)\",    \"0.50 (0.11)\",   \"0.15 (0.35)\",    \"0.57 (0.16)\", )  flights2 %>%    split_by_parens() #> # A tibble: 4 × 4 #>   drone_x drone_sd selfpilot_x selfpilot_sd #>   <chr>   <chr>    <chr>       <chr>        #> 1 0.09    0.21     0.19        0.13         #> 2 0.19    0.28     0.53        0.10         #> 3 0.62    0.16     0.50        0.11         #> 4 0.15    0.35     0.57        0.16 flights2 %>%    split_by_parens(transform = TRUE) #> # A tibble: 8 × 3 #>   .origin   x     sd    #>   <chr>     <chr> <chr> #> 1 drone     0.09  0.21  #> 2 drone     0.19  0.28  #> 3 drone     0.62  0.16  #> 4 drone     0.15  0.35  #> 5 selfpilot 0.19  0.13  #> 6 selfpilot 0.53  0.10  #> 7 selfpilot 0.50  0.11  #> 8 selfpilot 0.57  0.16 flights2 %>%    split_by_parens(transform = TRUE) %>%    dplyr::mutate(n = 80) %>%    debit_map() #> # A tibble: 8 × 12 #>   x     sd        n consistency rounding sd_lo…¹ sd_in…² sd_up…³ sd_in…⁴ x_lower #>   <chr> <chr> <int> <lgl>       <chr>      <dbl> <lgl>     <dbl> <lgl>     <dbl> #> 1 0.09  0.21     80 FALSE       up_or_d…   0.205 TRUE      0.215 TRUE      0.085 #> 2 0.19  0.28     80 FALSE       up_or_d…   0.275 TRUE      0.285 TRUE      0.185 #> 3 0.62  0.16     80 FALSE       up_or_d…   0.155 TRUE      0.165 TRUE      0.615 #> 4 0.15  0.35     80 TRUE        up_or_d…   0.345 TRUE      0.355 TRUE      0.145 #> 5 0.19  0.13     80 FALSE       up_or_d…   0.125 TRUE      0.135 TRUE      0.185 #> 6 0.53  0.10     80 FALSE       up_or_d…   0.095 TRUE      0.105 TRUE      0.525 #> 7 0.50  0.11     80 FALSE       up_or_d…   0.105 TRUE      0.115 TRUE      0.495 #> 8 0.57  0.16     80 FALSE       up_or_d…   0.155 TRUE      0.165 TRUE      0.565 #> # … with 2 more variables: x_upper <dbl>, .origin <chr>, and abbreviated #> #   variable names ¹​sd_lower, ²​sd_incl_lower, ³​sd_upper, ⁴​sd_incl_upper"},{"path":"https://lhdjung.github.io/scrutiny/articles/wrangling.html","id":"column-name-suffixes","dir":"Articles","previous_headings":"Split strings by parentheses","what":"Column name suffixes","title":"Data wrangling","text":"defaults column name suffixes (1) \"x\" part parentheses (2) \"sd\" part inside . However, won’t fit data presented like 5.22 (0.73). Override defaults specifying .col1 /.col2: suffixes become column names .transform set TRUE:","code":"flights2 %>%    split_by_parens(end1 = \"beta\", end2 = \"se\") #> # A tibble: 4 × 4 #>   drone_beta drone_se selfpilot_beta selfpilot_se #>   <chr>      <chr>    <chr>          <chr>        #> 1 0.09       0.21     0.19           0.13         #> 2 0.19       0.28     0.53           0.10         #> 3 0.62       0.16     0.50           0.11         #> 4 0.15       0.35     0.57           0.16 flights2 %>%    split_by_parens(end1 = \"beta\", end2 = \"se\", transform = TRUE) #> # A tibble: 8 × 3 #>   .origin   beta  se    #>   <chr>     <chr> <chr> #> 1 drone     0.09  0.21  #> 2 drone     0.19  0.28  #> 3 drone     0.62  0.16  #> 4 drone     0.15  0.35  #> 5 selfpilot 0.19  0.13  #> 6 selfpilot 0.53  0.10  #> 7 selfpilot 0.50  0.11  #> 8 selfpilot 0.57  0.16"},{"path":"https://lhdjung.github.io/scrutiny/articles/wrangling.html","id":"extract-substrings-from-before_parens-and-inside_parens","dir":"Articles","previous_headings":"Split strings by parentheses","what":"Extract substrings from before_parens() and inside_parens()","title":"Data wrangling","text":"also specific functions extracting parts individual string vectors inside parentheses:","code":"flights3 <- flights2 %>%    dplyr::pull(selfpilot)  flights3 #> [1] \"0.19 (0.13)\" \"0.53 (0.10)\" \"0.50 (0.11)\" \"0.57 (0.16)\"  flights3 %>%    before_parens() #> [1] \"0.19\" \"0.53\" \"0.50\" \"0.57\"  flights3 %>%    inside_parens() #> [1] \"0.13\" \"0.10\" \"0.11\" \"0.16\""},{"path":"https://lhdjung.github.io/scrutiny/articles/wrangling.html","id":"replace-column-names-by-row-values","dir":"Articles","previous_headings":"","what":"Replace column names by row values","title":"Data wrangling","text":"extracting tables PDF tabulizer, might get data frames (converted matrices) wrong, nondescript column names, correct column names stored one rows within data frame . first simulate problem. x n column names, instead values first row: remedy issue, call row_to_colnames() data frame. replace column names values one rows. latter specified position numbers dplyr::slice(). numbers, default 1 column names often stored first row, . specified row rows dropped shouldn’t rows first place. example: Note n still string vector, true columns tables extracted tabulizer.","code":"flights1_with_issues <- flights1 %>%      dplyr::mutate(n = as.character(n)) %>%      tibble::add_row(x = \"x\", n = \"n\", .before = 1)  colnames(flights1_with_issues) <- c(\"Var1\", \"Var2\")  flights1_with_issues #> # A tibble: 8 × 2 #>   Var1  Var2  #>   <chr> <chr> #> 1 x     n     #> 2 8.97  28    #> 3 2.61  28    #> 4 7.26  28    #> 5 3.64  28    #> 6 9.26  28    #> 7 10.46 28    #> 8 7.39  28 flights1_with_issues %>%    row_to_colnames() #> # A tibble: 7 × 2 #>   x     n     #>   <chr> <chr> #> 1 8.97  28    #> 2 2.61  28    #> 3 7.26  28    #> 4 3.64  28    #> 5 9.26  28    #> 6 10.46 28    #> 7 7.39  28"},{"path":"https://lhdjung.github.io/scrutiny/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lukas Jung. Author, maintainer. Aurélien Allard. Contributor.","code":""},{"path":"https://lhdjung.github.io/scrutiny/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Jung L (2023). scrutiny: Error Detection Science. https://lhdjung.github.io/scrutiny/, https://github.com/lhdjung/scrutiny/.","code":"@Manual{,   title = {scrutiny: Error Detection in Science},   author = {Lukas Jung},   year = {2023},   note = {https://lhdjung.github.io/scrutiny/, https://github.com/lhdjung/scrutiny/}, }"},{"path":"https://lhdjung.github.io/scrutiny/index.html","id":"error-detection-in-science","dir":"","previous_headings":"","what":"Error detection in science","title":"Error detection in science","text":"goal scrutiny test published summary statistics consistency using techniques like GRIM check plausibility reconstructing processes behind . package makes methods easy use tidyverse-friendly way. hopes help new field error detection go mainstream. Besides ready-made tests, scrutiny features complete system implementing new consistency tests, general infrastructure implementing error detection techniques, well specialized data wrangling functions. See Articles tab vignettes. scrutiny work progress. welcome contribute pull requests. However, please open issue first. Install package CRAN: Alternatively, install development version GitHub:","code":"install.packages(\"scrutiny\") remotes::install_github(\"lhdjung/scrutiny\")"},{"path":"https://lhdjung.github.io/scrutiny/index.html","id":"get-started","dir":"","previous_headings":"","what":"Get started","title":"Error detection in science","text":"GRIM-test values data frame. using grim_map(), consistency column tells means (x), sample sizes (n), numbers scale items mutually consistent. Scale item numbers 1 default. Test percentages instead means: can choose means reconstructed testing — , rounded 5. visualizing results, plot adjust automatically. Blue dots consistent values, red dots inconsistent ones:  Similarly, use DEBIT test means standard deviations binary data:","code":"library(scrutiny)  # Example data: pigs1 #> # A tibble: 12 × 2 #>    x         n #>    <chr> <dbl> #>  1 7.22     32 #>  2 4.74     25 #>  3 5.23     29 #>  4 2.57     24 #>  5 6.77     27 #>  6 2.68     28 #>  7 7.01     29 #>  8 7.38     26 #>  9 3.14     27 #> 10 6.89     31 #> 11 5.00     25 #> 12 0.24     28  # GRIM-testing for data frames: grim_map(pigs1) #> # A tibble: 12 × 4 #>    x         n consistency ratio #>    <chr> <dbl> <lgl>       <dbl> #>  1 7.22     32 TRUE         0.68 #>  2 4.74     25 FALSE        0.75 #>  3 5.23     29 FALSE        0.71 #>  4 2.57     24 FALSE        0.76 #>  5 6.77     27 FALSE        0.73 #>  6 2.68     28 TRUE         0.72 #>  7 7.01     29 FALSE        0.71 #>  8 7.38     26 TRUE         0.74 #>  9 3.14     27 FALSE        0.73 #> 10 6.89     31 FALSE        0.69 #> 11 5.00     25 TRUE         0.75 #> 12 0.24     28 FALSE        0.72 pigs2 #> # A tibble: 6 × 2 #>   x         n #>   <chr> <dbl> #> 1 67.4    150 #> 2 54.2    150 #> 3 54.0    150 #> 4 69.8    150 #> 5 68.1    150 #> 6 55.4    150  grim_map(pigs2, percent = TRUE) #> ℹ `x` converted from percentage #> # A tibble: 6 × 4 #>   x         n consistency ratio #>   <chr> <dbl> <lgl>       <dbl> #> 1 0.674   150 FALSE        0.85 #> 2 0.542   150 FALSE        0.85 #> 3 0.540   150 TRUE         0.85 #> 4 0.698   150 FALSE        0.85 #> 5 0.681   150 FALSE        0.85 #> 6 0.554   150 FALSE        0.85 pigs1 %>%    grim_map(rounding = \"up\") %>%    grim_plot() pigs3 #> # A tibble: 7 × 3 #>   x     sd        n #>   <chr> <chr> <dbl> #> 1 0.53  0.50   1683 #> 2 0.44  0.50   1683 #> 3 0.77  0.42   1683 #> 4 0.19  0.35   1683 #> 5 0.34  0.47   1683 #> 6 0.93  0.25   1683 #> 7 0.12  0.33   1683  pigs3 %>%    debit_map() #> # A tibble: 7 × 11 #>   x     sd        n consistency rounding sd_lo…¹ sd_in…² sd_up…³ sd_in…⁴ x_lower #>   <chr> <chr> <int> <lgl>       <chr>      <dbl> <lgl>     <dbl> <lgl>     <dbl> #> 1 0.53  0.50   1683 TRUE        up_or_d…   0.495 TRUE      0.505 TRUE      0.525 #> 2 0.44  0.50   1683 TRUE        up_or_d…   0.495 TRUE      0.505 TRUE      0.435 #> 3 0.77  0.42   1683 TRUE        up_or_d…   0.415 TRUE      0.425 TRUE      0.765 #> 4 0.19  0.35   1683 FALSE       up_or_d…   0.345 TRUE      0.355 TRUE      0.185 #> 5 0.34  0.47   1683 TRUE        up_or_d…   0.465 TRUE      0.475 TRUE      0.335 #> 6 0.93  0.25   1683 TRUE        up_or_d…   0.245 TRUE      0.255 TRUE      0.925 #> 7 0.12  0.33   1683 TRUE        up_or_d…   0.325 TRUE      0.335 TRUE      0.115 #> # … with 1 more variable: x_upper <dbl>, and abbreviated variable names #> #   ¹​sd_lower, ²​sd_incl_lower, ³​sd_upper, ⁴​sd_incl_upper  pigs3 %>%    debit_map() %>%    debit_plot()"},{"path":"https://lhdjung.github.io/scrutiny/index.html","id":"guiding-ideas","dir":"","previous_headings":"","what":"Guiding ideas","title":"Error detection in science","text":"(…) critical inspection published literature mischaracterized hobby overly cynical, -called “methodological terrorism”. contrary, carefully evaluating presented data cornerstone scientific investigation, logical apply also published literature. willing critically assess published studies, also guarantee veracity. — van der Zee et al. (2017, pp. 8-9) (…) data thugs (…) demand data receive , contact editors universities threaten write blogs tweets errors uncovered. — Eric . Stewart (six retractions; quoted Pickett 2020, p. 178)","code":""},{"path":"https://lhdjung.github.io/scrutiny/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Error detection in science","text":"Pickett, J. T. (2020). Stewart Retractions: Quantitative Qualitative Analysis. Econ Journal Watch, 17(1), 152–190. https://econjwatch.org/articles/-stewart-retractions--quantitative--qualitative-analysis. van der Zee, T., Anaya, J., & Brown, N. J. L. (2017). Statistical heartburn: attempt digest four pizza publications Cornell Food Brand Lab. BMC Nutrition, 3(1), 54. https://doi.org/10.1186/s40795-017-0167-x.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/audit.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize scrutiny objects — audit","title":"Summarize scrutiny objects — audit","text":"audit() S3 generic follow scrutiny functions perform tests data frames. summarizes results tests presents summaries tibble. audit_list() variant returns named list instead. audit_seq() audit_total_n() summarize results functions end _seq _total_n, respectively. list functions return objects classes audit() methods. means can run audit() output returned functions. true audit_seq() audit_total_n(). Go documentation function named learn audit() method, way output processed audit_seq() audit_total_n().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/audit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize scrutiny objects — audit","text":"","code":"audit(data)  audit_list(data)  audit_seq(data)  audit_total_n(data)"},{"path":"https://lhdjung.github.io/scrutiny/reference/audit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize scrutiny objects — audit","text":"data data frame inherits one classes named .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/audit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize scrutiny objects — audit","text":"tibble (data frame) test summary statistics.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/audit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize scrutiny objects — audit","text":"","code":"# For basic GRIM-testing: pigs1 %>%   grim_map() %>%   audit() #> # A tibble: 1 × 7 #>   incons_cases all_cases incons_rate mean_grim_ratio incons_to…¹ testa…² testa…³ #>          <int>     <int>       <dbl>           <dbl>       <dbl>   <int>   <dbl> #> 1            8        12       0.667           0.724       0.921      12       1 #> # … with abbreviated variable names ¹​incons_to_ratio, ²​testable_cases, #> #   ³​testable_rate  # For GRIM-testing with # dispersed inputs: pigs1 %>%   grim_map_seq() %>%   audit_seq() #> # A tibble: 8 × 12 #>   x         n consistency hits_total hits_x hits_n diff_x diff_…¹ diff_…² diff_n #>   <chr> <dbl> <lgl>            <int>  <int>  <int>  <dbl>   <dbl>   <dbl>  <dbl> #> 1 4.74     25 FALSE                4      2      2      2       2      -2      2 #> 2 5.23     29 FALSE                6      3      3      1       1      -2      1 #> 3 2.57     24 FALSE                6      3      3      1       1      -3      1 #> 4 6.77     27 FALSE                7      3      4      1       1      -3      1 #> 5 7.01     29 FALSE                3      3      0      1       2      -1     NA #> 6 3.14     27 FALSE                6      3      3      1       1      -3      1 #> 7 6.89     31 FALSE                8      4      4      1       1      -2      3 #> 8 0.24     28 FALSE                6      3      3      1       1      -3      1 #> # … with 2 more variables: diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated #> #   variable names ¹​diff_x_up, ²​diff_x_down  # For detecting duplicates: pigs4 %>%   duplicate_detect() %>%   audit() #> # A tibble: 3 × 4 #>   variable n_duplicated n_total dup_rate #>   <chr>           <int>   <int>    <dbl> #> 1 snout               3       5      0.6 #> 2 tail                1       5      0.2 #> 3 .total              4      10      0.4"},{"path":"https://lhdjung.github.io/scrutiny/reference/audit_cols_minimal.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute minimal audit() summaries — audit_cols_minimal","title":"Compute minimal audit() summaries — audit_cols_minimal","text":"Call audit_cols_minimal() within audit() methods output consistency test mapper functions grim_map(). create tibble three minimal, required columns: incons_cases counts inconsistent cases, .e., number rows mapper's output \"consistency\" FALSE. all_cases total number rows mapper's output. incons_rate ratio incons_cases all_cases. can still add columns tibble. Either way, make sure name method correctly. See examples.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/audit_cols_minimal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute minimal audit() summaries — audit_cols_minimal","text":"","code":"audit_cols_minimal(data, name_test)"},{"path":"https://lhdjung.github.io/scrutiny/reference/audit_cols_minimal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute minimal audit() summaries — audit_cols_minimal","text":"data Data frame returned mapper function, asgrim_map(). name_test String (length 1). Short, plain-text name consistency test, \"GRIM\". needed potential alert.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/audit_cols_minimal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute minimal audit() summaries — audit_cols_minimal","text":"tibble (data frame) columns listed .","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/audit_cols_minimal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute minimal audit() summaries — audit_cols_minimal","text":"","code":"# For a mapper function called `schlim_map()` # that applies a test called SCHLIM and returns # a data frame with the `\"scr_schlim_map\"` class: audit.scr_schlim_map <- function(data) {   audit_cols_minimal(data, name_test = \"SCHLIM\") }  # If you like, add other summary columns # with `dplyr::mutate()` or similar."},{"path":"https://lhdjung.github.io/scrutiny/reference/check_audit_special.html","id":null,"dir":"Reference","previous_headings":"","what":"Alert user if more specific audit_*() summaries are available — check_audit_special","title":"Alert user if more specific audit_*() summaries are available — check_audit_special","text":"(Note: Ignore function audit() method calls audit_cols_minimal().) Call check_audit_special() within audit() method consistency test mapper function, audit.scr_grim_map(). checks input data frame product function produced function_map_seq() function_map_total_n(). , function issues gentle alert user points audit_seq() audit_total_n(), respectively.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/check_audit_special.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Alert user if more specific audit_*() summaries are available — check_audit_special","text":"","code":"check_audit_special(data, name_test)"},{"path":"https://lhdjung.github.io/scrutiny/reference/check_audit_special.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Alert user if more specific audit_*() summaries are available — check_audit_special","text":"data audit() method's input data frame. name_test String (length 1). Short, plain-text name consistency test, \"GRIM\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/check_audit_special.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Alert user if more specific audit_*() summaries are available — check_audit_special","text":"return value. Might print alert.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/check_mapper_input_colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that a mapper's input has correct column names — check_mapper_input_colnames","title":"Check that a mapper's input has correct column names — check_mapper_input_colnames","text":"called within consistency test mapper function, check_mapper_input_colnames() makes sure input data frame correct column names: include key columns corresponding test applied mapper. already include \"consistency\". either check fails, function throws informative error.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/check_mapper_input_colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that a mapper's input has correct column names — check_mapper_input_colnames","text":"","code":"check_mapper_input_colnames(data, reported, name_test)"},{"path":"https://lhdjung.github.io/scrutiny/reference/check_mapper_input_colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that a mapper's input has correct column names — check_mapper_input_colnames","text":"data Data frame. Input mapper function. reported String vector \"key\" column names data must , c(\"x\", \"n\") grim_map(). name_test String (length 1). Short, plain-text name consistency test mapper function applies, \"GRIM\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/check_mapper_input_colnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that a mapper's input has correct column names — check_mapper_input_colnames","text":"return value. Might throw error.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/data-frame-predicates.html","id":null,"dir":"Reference","previous_headings":"","what":"Is an object a consistency test output tibble? — data-frame-predicates","title":"Is an object a consistency test output tibble? — data-frame-predicates","text":"is_map_df() tests whether object output scrutiny-style mapper function consistency tests, like grim_map(). mapper functions also include produced function_map(), function_map_seq(), function_map_total_n(). is_map_basic_df() variant is_map_df() tests whether object output \"basic\" mapper function. includes functions like grim_map() produced function_map(), produced function_map_seq() function_map_total_n(). is_map_seq_df() tests whether object output function produced function_map_seq(). is_map_total_n_df() tests whether object output function produced function_map_total_n().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/data-frame-predicates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is an object a consistency test output tibble? — data-frame-predicates","text":"","code":"is_map_df(x)  is_map_basic_df(x)  is_map_seq_df(x)  is_map_total_n_df(x)"},{"path":"https://lhdjung.github.io/scrutiny/reference/data-frame-predicates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is an object a consistency test output tibble? — data-frame-predicates","text":"x Object tested.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/data-frame-predicates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is an object a consistency test output tibble? — data-frame-predicates","text":"Boolean (length 1).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/data-frame-predicates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Is an object a consistency test output tibble? — data-frame-predicates","text":"Sections 3, 6, 7 vignette(\"consistency-tests\") discuss function factories produce functions, new, factory-made functions return kinds tibbles. tibbles is_map_*() functions test . example, function_map_seq() produces grim_map_seq(), new function returns tibble. is_map_df() is_map_seq_df() return TRUE tibble, is_map_basic_df() is_map_total_n_df() return FALSE. overview, see table end vignette(\"consistency-tests\").","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/data-frame-predicates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Is an object a consistency test output tibble? — data-frame-predicates","text":"","code":"# Example test output: df1 <- grim_map(pigs1) df2 <- grim_map_seq(pigs1) df3 <- grim_map_total_n(tibble::tribble(   ~x1,    ~x2,   ~n,   \"3.43\", \"5.28\", 90,   \"2.97\", \"4.42\", 103 ))  # All three tibbles are mapper output: is_map_df(df1) #> [1] TRUE is_map_df(df2) #> [1] TRUE is_map_df(df3) #> [1] TRUE  # However, only `df1` is the output of a # basic mapper... is_map_basic_df(df1) #> [1] TRUE is_map_basic_df(df2) #> [1] FALSE is_map_basic_df(df3) #> [1] FALSE  # ...only `df2` is the output of a # sequence mapper... is_map_seq_df(df1) #> [1] FALSE is_map_seq_df(df2) #> [1] TRUE is_map_seq_df(df3) #> [1] FALSE  # ...and only `df3` is the output of a # total-n mapper: is_map_total_n_df(df1) #> [1] FALSE is_map_total_n_df(df2) #> [1] FALSE is_map_total_n_df(df3) #> [1] TRUE"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit.html","id":null,"dir":"Reference","previous_headings":"","what":"The DEBIT (descriptive binary) test — debit","title":"The DEBIT (descriptive binary) test — debit","text":"debit() tests summaries binary data consistency: mean standard deviation binary data given, consistent reported sample size? function vectorized, recommended use debit_map() testing multiple cases.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The DEBIT (descriptive binary) test — debit","text":"","code":"debit(   x,   sd,   n,   formula = \"mean_n\",   rounding = \"up_or_down\",   threshold = 5,   symmetric = FALSE )"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The DEBIT (descriptive binary) test — debit","text":"x String. Mean binary distribution. sd String. Sample standard deviation binary distribution. n Integer. Total sample size. formula String. Formula used compute SD binary distribution. Currently, default, \"mean_n\", supported. rounding String. Rounding method methods used reconstructing SD values sd compared. Default \"up_or_down\" (5). options, see documentation grim(), section Details. threshold Integer. rounding set \"up_from\", \"down_from\", \"up_from_or_down_from\", set threshold number reconstructed values rounded . Otherwise irrelevant. Default 5. symmetric Boolean. Set symmetric TRUE rounding negative numbers \"\", \"\", \"up_from\", \"down_from\" mirror positive numbers absolute values always equal. Default FALSE.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The DEBIT (descriptive binary) test — debit","text":"Boolean. TRUE x, sd, n mutually consistent, FALSE .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The DEBIT (descriptive binary) test — debit","text":"Heathers, James . J., Brown, Nicholas J. L. 2019. DEBIT: Simple Consistency Test Binary Data. https://osf.io/5vb3u/.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/debit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The DEBIT (descriptive binary) test — debit","text":"","code":"# Check single cases of binary # summary data: debit(x = \"0.36\", sd = \"0.11\", n = 20) #>  0.36  #> FALSE"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply DEBIT to many cases — debit_map","title":"Apply DEBIT to many cases — debit_map","text":"Call debit_map() use DEBIT multiple combinations mean, standard deviation, sample size binary distributions. Mapping function debit(). summary statistics, call audit() results.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply DEBIT to many cases — debit_map","text":"","code":"debit_map(   data,   x = NULL,   sd = NULL,   n = NULL,   rounding = \"up_or_down\",   threshold = 5,   symmetric = FALSE,   show_rec = TRUE,   extra = Inf )"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply DEBIT to many cases — debit_map","text":"data Data frame. x, sd, n Optionally, specify arguments column names data. rounding, threshold, symmetric Arguments passed debit(), defaults. show_rec set FALSE, resulting tibble includes columns x, sd, n, consistency. Default TRUE. extra currently used.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply DEBIT to many cases — debit_map","text":"tibble (least) columns -- x, sd, n: inputs. consistency: DEBIT consistency x, sd, n. default, tibble also includes rounding method, boundary values, Boolean information boundary values inclusive . tibble scr_debit_map class, recognized audit() generic.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map.html","id":"summaries-with-audit-","dir":"Reference","previous_headings":"","what":"Summaries with audit()","title":"Apply DEBIT to many cases — debit_map","text":"S3 method audit() generic, can call audit() following debit_map(). returns tibble columns --- incons_cases: number DEBIT-inconsistent cases. all_cases: total number cases. incons_rate: rate inconsistent cases. mean_x: mean x (mean) value. mean_sd: mean sd value. distinct_n: number distinct n values.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Apply DEBIT to many cases — debit_map","text":"Heathers, James . J., Brown, Nicholas J. L. 2019. DEBIT: Simple Consistency Test Binary Data. https://osf.io/5vb3u/.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply DEBIT to many cases — debit_map","text":"","code":"# Call `debit_map()` on binary summary # data such as these: pigs3 #> # A tibble: 7 × 3 #>   x     sd        n #>   <chr> <chr> <dbl> #> 1 0.53  0.50   1683 #> 2 0.44  0.50   1683 #> 3 0.77  0.42   1683 #> 4 0.19  0.35   1683 #> 5 0.34  0.47   1683 #> 6 0.93  0.25   1683 #> 7 0.12  0.33   1683  # The `consistency` column shows # whether the values to its left # are DEBIT-consistent: pigs3 %>%   debit_map() #> # A tibble: 7 × 11 #>   x     sd        n consistency rounding sd_lo…¹ sd_in…² sd_up…³ sd_in…⁴ x_lower #>   <chr> <chr> <int> <lgl>       <chr>      <dbl> <lgl>     <dbl> <lgl>     <dbl> #> 1 0.53  0.50   1683 TRUE        up_or_d…   0.495 TRUE      0.505 TRUE      0.525 #> 2 0.44  0.50   1683 TRUE        up_or_d…   0.495 TRUE      0.505 TRUE      0.435 #> 3 0.77  0.42   1683 TRUE        up_or_d…   0.415 TRUE      0.425 TRUE      0.765 #> 4 0.19  0.35   1683 FALSE       up_or_d…   0.345 TRUE      0.355 TRUE      0.185 #> 5 0.34  0.47   1683 TRUE        up_or_d…   0.465 TRUE      0.475 TRUE      0.335 #> 6 0.93  0.25   1683 TRUE        up_or_d…   0.245 TRUE      0.255 TRUE      0.925 #> 7 0.12  0.33   1683 TRUE        up_or_d…   0.325 TRUE      0.335 TRUE      0.115 #> # … with 1 more variable: x_upper <dbl>, and abbreviated variable names #> #   ¹​sd_lower, ²​sd_incl_lower, ³​sd_upper, ⁴​sd_incl_upper  # Get test summaries with `audit()`: pigs3 %>%   debit_map() %>%   audit() #> # A tibble: 1 × 6 #>   incons_cases all_cases incons_rate mean_x mean_sd distinct_n #>          <int>     <int>       <dbl>  <dbl>   <dbl>      <int> #> 1            1         7       0.143  0.474   0.403          1"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Using DEBIT with dispersed inputs — debit_map_seq","title":"Using DEBIT with dispersed inputs — debit_map_seq","text":"debit_map_seq() applies DEBIT values surrounding input values. provides easy powerful way assess whether small errors computing reporting may responsible DEBIT-inconsistencies published statistics.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Using DEBIT with dispersed inputs — debit_map_seq","text":"","code":"debit_map_seq(   data,   x = NULL,   sd = NULL,   n = NULL,   var = .var,   dispersion = .dispersion,   out_min = .out_min,   out_max = .out_max,   include_reported = .include_reported,   include_consistent = .include_consistent,   ... )"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using DEBIT with dispersed inputs — debit_map_seq","text":"data data frame debit_map() take. x, sd, n Optionally, specify column names data arguments. var String. Names columns dispersed. Default c(\"x\", \"sd\", \"n\"). dispersion Numeric. Sequence steps var inputs. adjusted values' decimal levels. example, reported 8.34, step size 0.01. Default 1:5, five steps . out_min, out_max specified, output restricted out_min out_max. Defaults \"auto\" out_min, .e., minimum one decimal unit zero; NULL out_max, .e., maximum. include_reported Boolean. reported values included sequences originating ? Default FALSE might redundant bias results. include_consistent Boolean. function also process consistent cases (among reported), just inconsistent ones? Default FALSE focus clarifying inconsistencies. ... Arguments passed debit_map().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Using DEBIT with dispersed inputs — debit_map_seq","text":"tibble (data frame) detailed test results.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_seq.html","id":"summaries-with-audit-seq-","dir":"Reference","previous_headings":"","what":"Summaries with audit_seq()","title":"Using DEBIT with dispersed inputs — debit_map_seq","text":"can call audit_seq() following debit_map_seq(). return data frame columns: x, sd, n original inputs, tested consistency . hits_total total number DEBIT-consistent value sets found within specified dispersion range. hits_x number DEBIT-consistent value sets found varying x. Accordingly sd hits_sd well n hits_n. (Note consistent reported cases counted hits_* columns include_reported include_consistent set TRUE.) diff_x reports absolute difference x next consistent dispersed value (dispersion steps, actual numeric difference). diff_x_up diff_x_down report difference next higher lower consistent value, respectively. diff_sd, diff_sd_up, diff_sd_down sd. Likewise diff_n, diff_n_up, diff_n_down.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Using DEBIT with dispersed inputs — debit_map_seq","text":"","code":"# `debit_map_seq()` can take any input # that `debit_map()` can take: pigs3 #> # A tibble: 7 × 3 #>   x     sd        n #>   <chr> <chr> <dbl> #> 1 0.53  0.50   1683 #> 2 0.44  0.50   1683 #> 3 0.77  0.42   1683 #> 4 0.19  0.35   1683 #> 5 0.34  0.47   1683 #> 6 0.93  0.25   1683 #> 7 0.12  0.33   1683  # Results from testing some few rows: out <- pigs3 %>%   dplyr::slice(3:4) %>%   debit_map_seq(include_consistent = TRUE)  out #> # A tibble: 60 × 13 #>    x     sd        n consistency round…¹ sd_lo…² sd_in…³ sd_up…⁴ sd_in…⁵ x_lower #>    <chr> <chr> <int> <lgl>       <chr>     <dbl> <lgl>     <dbl> <lgl>     <dbl> #>  1 0.72  0.42   1683 FALSE       up_or_…   0.415 TRUE      0.425 TRUE      0.715 #>  2 0.73  0.42   1683 FALSE       up_or_…   0.415 TRUE      0.425 TRUE      0.725 #>  3 0.74  0.42   1683 FALSE       up_or_…   0.415 TRUE      0.425 TRUE      0.735 #>  4 0.75  0.42   1683 FALSE       up_or_…   0.415 TRUE      0.425 TRUE      0.745 #>  5 0.76  0.42   1683 TRUE        up_or_…   0.415 TRUE      0.425 TRUE      0.755 #>  6 0.78  0.42   1683 TRUE        up_or_…   0.415 TRUE      0.425 TRUE      0.775 #>  7 0.79  0.42   1683 FALSE       up_or_…   0.415 TRUE      0.425 TRUE      0.785 #>  8 0.80  0.42   1683 FALSE       up_or_…   0.415 TRUE      0.425 TRUE      0.795 #>  9 0.81  0.42   1683 FALSE       up_or_…   0.415 TRUE      0.425 TRUE      0.805 #> 10 0.82  0.42   1683 FALSE       up_or_…   0.415 TRUE      0.425 TRUE      0.815 #> # … with 50 more rows, 3 more variables: x_upper <dbl>, case <int>, var <chr>, #> #   and abbreviated variable names ¹​rounding, ²​sd_lower, ³​sd_incl_lower, #> #   ⁴​sd_upper, ⁵​sd_incl_upper  # Case-wise summaries with `audit_seq()` # can be more important than the raw results: out %>%   audit_seq() #> # A tibble: 2 × 17 #>   x     sd        n consi…¹ hits_…² hits_x hits_sd hits_n diff_x diff_…³ diff_…⁴ #>   <chr> <chr> <int> <lgl>     <int>  <int>   <int>  <int>  <dbl>   <dbl>   <dbl> #> 1 0.77  0.42   1683 TRUE         12      2       0     10      1       1      -1 #> 2 0.19  0.35   1683 FALSE         4      2       2      0      4      NA      -4 #> # … with 6 more variables: diff_sd <dbl>, diff_sd_up <dbl>, diff_sd_down <dbl>, #> #   diff_n <dbl>, diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated variable #> #   names ¹​consistency, ²​hits_total, ³​diff_x_up, ⁴​diff_x_down"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_total_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Use DEBIT with hypothetical group sizes — debit_map_total_n","title":"Use DEBIT with hypothetical group sizes — debit_map_total_n","text":"debit_map_total_n() extends DEBIT cases group means standard deviations (SDs) reported, group sizes. function analogous grim_map_total_n() grimmer_map_total_n(), relying infrastructure.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_total_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use DEBIT with hypothetical group sizes — debit_map_total_n","text":"","code":"debit_map_total_n(   data,   x1 = NULL,   x2 = NULL,   sd1 = NULL,   sd2 = NULL,   dispersion = .dispersion,   n_min = .n_min,   n_max = .n_max,   constant = .constant,   constant_index = .constant_index,   ... )"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_total_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use DEBIT with hypothetical group sizes — debit_map_total_n","text":"data Data frame string columns x1, x2, sd1, sd2, well numeric column n. first two reported group means. sd1 sd2 reported group SDs. n reported total sample size. important whether value x1 x2 , first round tests, function switches roles x1 x2, reports outcomes ways. applies sd1 sd2. However, make sure x* sd* values paired accurately, reported. x1, x2, sd1, sd2 Optionally, specify arguments column names data. dispersion Numeric. Steps half n values. Default 0:5, .e., half n followed five steps . n_min Numeric. Minimal group size. Default 1. n_max Numeric. Maximal group size. Default NULL, .e., maximum. constant Optionally, add length-2 vector list length-2 vectors (data frame exactly two rows) accompany pairs dispersed values. Default NULL, .e., constant values. constant_index Integer (length 1). Index constant first constant column output tibble. NULL (default), constant go right n_change. ... Arguments passed debit_map().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_total_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use DEBIT with hypothetical group sizes — debit_map_total_n","text":"tibble columns: x sd, group-wise reported input statistics, repeated row pairs. n dispersed half input n, n_change tracking differences. both_consistent flags scenarios reported x sd values consistent hypothetical n values. case corresponds row numbers input data frame. dir \"forth\" first half rows \"back\" second half. \"forth\" means x2 sd2 input paired larger dispersed n, whereas \"back\" means x1 sd1 paired larger dispersed n. columns debit_map() preserved.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_total_n.html","id":"summaries-with-audit-total-n-","dir":"Reference","previous_headings":"","what":"Summaries with audit_total_n()","title":"Use DEBIT with hypothetical group sizes — debit_map_total_n","text":"can call audit_total_n() following debit_map_total_n() get tibble summary statistics. columns: x1, x2, sd1, sd2, n original inputs. hits_total number scenarios x1, x2, sd1, sd2 DEBIT-consistent. sum hits_forth hits_back . hits_forth number -consistent cases result pairing x2 sd2 larger dispersed n value. hits_back , except x1 sd1 paired larger dispersed n value. scenarios_total total number test scenarios, whether x1 sd1 well x2 sd2 DEBIT-consistent. hit_rate ratio hits_total scenarios_total. Call audit() following audit_total_n() summarize results even .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_total_n.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Use DEBIT with hypothetical group sizes — debit_map_total_n","text":"Bauer, P. J., & Francis, G. (2021). Expression Concern: Light Dark? Recalling Moral Behavior Changes Perception Brightness. Psychological Science, 32(12), 2042–2043. https://journals.sagepub.com/doi/10.1177/09567976211058727 Heathers, J. . J., & Brown, N. J. L. (2019). DEBIT: Simple Consistency Test Binary Data. https://osf.io/5vb3u/.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_map_total_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use DEBIT with hypothetical group sizes — debit_map_total_n","text":"","code":"# Run `debit_map_total_n()` on data like these: df <- tibble::tribble(   ~x1,  ~x2,  ~sd1,  ~sd2,  ~n,   \"0.30\", \"0.28\", \"0.17\", \"0.10\", 70,   \"0.41\", \"0.39\", \"0.09\", \"0.15\", 65 ) df #> # A tibble: 2 × 5 #>   x1    x2    sd1   sd2       n #>   <chr> <chr> <chr> <chr> <dbl> #> 1 0.30  0.28  0.17  0.10     70 #> 2 0.41  0.39  0.09  0.15     65  debit_map_total_n(df) #> # A tibble: 48 × 15 #>    x     sd        n n_change consiste…¹ both_…² round…³ sd_lo…⁴ sd_in…⁵ sd_up…⁶ #>    <chr> <chr> <int>    <dbl> <lgl>      <lgl>   <chr>     <dbl> <lgl>     <dbl> #>  1 0.30  0.17     35        0 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #>  2 0.28  0.10     35        0 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #>  3 0.30  0.17     34       -1 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #>  4 0.28  0.10     36        1 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #>  5 0.30  0.17     33       -2 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #>  6 0.28  0.10     37        2 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #>  7 0.30  0.17     32       -3 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #>  8 0.28  0.10     38        3 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #>  9 0.30  0.17     31       -4 FALSE      FALSE   up_or_…   0.165 TRUE      0.175 #> 10 0.28  0.10     39        4 FALSE      FALSE   up_or_…   0.095 TRUE      0.105 #> # … with 38 more rows, 5 more variables: sd_incl_upper <lgl>, x_lower <dbl>, #> #   x_upper <dbl>, case <int>, dir <chr>, and abbreviated variable names #> #   ¹​consistency, ²​both_consistent, ³​rounding, ⁴​sd_lower, ⁵​sd_incl_lower, #> #   ⁶​sd_upper  # `audit_total_n()` summaries can be more important than # the detailed results themselves. # The `hits_total` column shows all scenarios in # which both divergent `n` values are DEBIT-consistent # with the `x*` values when paired with them both ways: df %>%   debit_map_total_n(dispersion = 0:2) %>%   audit_total_n() #> # A tibble: 2 × 10 #>   x1    x2    sd1   sd2       n hits_total hits_forth hits_back scenar…¹ hit_r…² #>   <chr> <chr> <chr> <chr> <dbl>      <dbl>      <dbl>     <dbl>    <dbl>   <dbl> #> 1 0.30  0.28  0.17  0.10     70          0          0         0        6       0 #> 2 0.41  0.39  0.09  0.15     65          0          0         0        6       0 #> # … with abbreviated variable names ¹​scenarios_total, ²​hit_rate  # By default (`dispersion = 0:5`), the function goes # five steps up and down from `n`. The longer this # sequence, the larger the number of hits tends to be: df %>%   debit_map_total_n() %>%   audit_total_n() #> # A tibble: 2 × 10 #>   x1    x2    sd1   sd2       n hits_total hits_forth hits_back scenar…¹ hit_r…² #>   <chr> <chr> <chr> <chr> <dbl>      <dbl>      <dbl>     <dbl>    <dbl>   <dbl> #> 1 0.30  0.28  0.17  0.10     70          0          0         0       12       0 #> 2 0.41  0.39  0.09  0.15     65          0          0         0       12       0 #> # … with abbreviated variable names ¹​scenarios_total, ²​hit_rate"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize DEBIT results — debit_plot","title":"Visualize DEBIT results — debit_plot","text":"Plot distribution binary data mutual DEBIT consistency. Call function data frame resulted call debit_map(). Various parameters individual geoms can controlled via arguments.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize DEBIT results — debit_plot","text":"","code":"debit_plot(   data,   show_outer_boxes = TRUE,   show_labels = TRUE,   show_full_scale = TRUE,   show_theme_other = TRUE,   color_cons = \"royalblue1\",   color_incons = \"red\",   line_alpha = 1,   line_color = \"black\",   line_linetype = 1,   line_width = 0.5,   line_size = 0.5,   rect_alpha = 1,   tile_alpha = 0.15,   tile_height_offset = 0.025,   tile_width_offset = 0.025,   tile_height_min = 0.0375,   tile_width_min = 0.0385,   label_alpha = 0.5,   label_linetype = 3,   label_size = 3.5,   label_linesize = 0.75,   label_force = 175,   label_force_pull = 0.75,   label_padding = 0.5 )"},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize DEBIT results — debit_plot","text":"data Data frame. Result call debit_map(). show_outer_boxes Boolean. outer tiles surround actual data points, making easier spot assess overlap? Default TRUE. show_labels Boolean. data points labels (form \"mean; SD\")? Default TRUE. show_full_scale Boolean. plot fixed full scale, showing entire consistency line independently data? Default TRUE. show_theme_other Boolean. theme modified way fitting plot structure? Default TRUE. color_cons, color_incons Strings. Colors geoms representing consistent inconsistent values, respectively. line_alpha, line_color, line_linetype, line_width, line_size Parameters curved DEBIT line. rect_alpha Parameter DEBIT rectangles. (Due nature data mapping, can leeway regarding shape size particular geom.) tile_alpha, tile_height_offset, tile_width_offset, tile_height_min, tile_width_min Parameters outer tiles surrounding DEBIT rectangles. Offset refers distance rectangles within. label_alpha, label_linetype, label_size, label_linesize, label_force, label_force_pull, label_padding Parameters labels showing mean SD values. Passed ggrepel::geom_text_repel(); see information.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize DEBIT results — debit_plot","text":"ggplot object.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Visualize DEBIT results — debit_plot","text":"labels created via ggrepel::geom_text_repel(), algorithm designed minimize overlap tiles labels. Yet, take DEBIT line account, locations ultimately random. might therefore resize plot run function times labels localized satisfactory way. alternative present function S3 method ggplot2::autoplot(). However, standalone function allows customizing geom parameters might perhaps provide better accessibility overall.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_plot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Visualize DEBIT results — debit_plot","text":"Heathers, James . J., Brown, Nicholas J. L. 2019. DEBIT: Simple Consistency Test Binary Data. https://osf.io/5vb3u/.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/debit_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize DEBIT results — debit_plot","text":"","code":"# Run `debit_plot()` on the output # of `debit_map()`: pigs3 %>%   debit_map() %>%   debit_plot()"},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places.html","id":null,"dir":"Reference","previous_headings":"","what":"Count decimal places — decimal_places","title":"Count decimal places — decimal_places","text":"decimal_places() counts decimal places numeric vector, string vector can coerced numeric. decimal_places_scalar() much faster takes single input. useful helper within single-case functions.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count decimal places — decimal_places","text":"","code":"decimal_places(x, sep = \"\\\\.\")  decimal_places_scalar(x, sep = \"\\\\.\")"},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count decimal places — decimal_places","text":"x Numeric (string can coerced numeric). Object decimal places count. sep Substring separates mantissa integer part. Default \"\\\\.\", renders decimal point.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count decimal places — decimal_places","text":"Integer. Number decimal places x.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Count decimal places — decimal_places","text":"Decimal places numeric values counted accurately number 15 characters total, including integer part decimal point. possible solutions enter number string count digits. (Converting string sufficient -- numbers need entered quotes.) functions ignore whitespace end string, mistake spaces decimal places.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places.html","id":"trailing-zeros","dir":"Reference","previous_headings":"","what":"Trailing zeros","title":"Count decimal places — decimal_places","text":"trailing zeros matter, convert numeric values strings: numeric values, trailing zeros already dropped, information lost (e.g., 3.70 returns 3.7). Enter values strings instead, \"3.70\" instead 3.70. However, can restore lost trailing zeros restore_zeros() original number decimal places known. need enter many values strings, consider using tibble::tribble() drawing quotation marks around values tribble() column via RStudio's multiple cursors.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count decimal places — decimal_places","text":"","code":"# `decimal_places()` works on both numeric values # and strings... decimal_places(x = 2.851) #> [1] 3 decimal_places(x = \"2.851\") #> [1] 3  # ... but trailing zeros are only counted within # strings: decimal_places(x = c(7.3900, \"7.3900\")) #> [1] 2 4  # This doesn't apply to non-trailing zeros; these # behave just like any other digit would: decimal_places(x = c(4.08, \"4.08\")) #> [1] 2 2  # Whitespace at the end of a string is not counted: decimal_places(x = \"6.0     \") #> [1] 1  # `decimal_places_scalar()` is much faster, # but only works with a single number or string: decimal_places_scalar(x = 8.13) #> [1] 2 decimal_places_scalar(x = \"5.024\") #> [1] 3"},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Count decimal places in a data frame — decimal_places_df","title":"Count decimal places in a data frame — decimal_places_df","text":"every value column, decimal_places_df() counts decimal places. default, operates columns coercible numeric.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count decimal places in a data frame — decimal_places_df","text":"","code":"decimal_places_df(   data,   cols = everything(),   check_numeric_like = TRUE,   sep = \"\\\\.\" )"},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count decimal places in a data frame — decimal_places_df","text":"data Data frame. cols Select columns data using tidyselect. Default everything(), restricted check_numeric_like. check_numeric_like Boolean. TRUE (default), function operates numeric columns columns coercible numeric, determined is_numeric_like(). sep Substring separates mantissa integer part. Default \"\\\\.\", renders decimal point.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count decimal places in a data frame — decimal_places_df","text":"Data frame. values selected columns replaced numbers decimal places.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/decimal_places_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count decimal places in a data frame — decimal_places_df","text":"","code":"# Coerce all columns to string: iris <- iris %>%   tibble::as_tibble() %>%   dplyr::mutate(across(everything(), as.character))  # The function will operate on all # numeric-like columns but not on `\"Species\"`: iris %>%   decimal_places_df() #> Warning: ! 1 column was excluded: `Species`. #> ✖ It isn't numeric-like. #> # A tibble: 150 × 5 #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>           <int>       <int>        <int>       <int> <chr>   #>  1            1           1            1           1 setosa  #>  2            1           0            1           1 setosa  #>  3            1           1            1           1 setosa  #>  4            1           1            1           1 setosa  #>  5            0           1            1           1 setosa  #>  6            1           1            1           1 setosa  #>  7            1           1            1           1 setosa  #>  8            0           1            1           1 setosa  #>  9            1           1            1           1 setosa  #> 10            1           1            1           1 setosa  #> # … with 140 more rows  # Operate on some select columns only # (from among the numeric-like columns): iris %>%   decimal_places_df(cols = starts_with(\"Sepal\")) #> Warning: ! 1 column was excluded: `Species`. #> ✖ It isn't numeric-like. #> # A tibble: 150 × 5 #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>           <int>       <int> <chr>        <chr>       <chr>   #>  1            1           1 1.4          0.2         setosa  #>  2            1           0 1.4          0.2         setosa  #>  3            1           1 1.3          0.2         setosa  #>  4            1           1 1.5          0.2         setosa  #>  5            0           1 1.4          0.2         setosa  #>  6            1           1 1.7          0.4         setosa  #>  7            1           1 1.4          0.3         setosa  #>  8            0           1 1.5          0.2         setosa  #>  9            1           1 1.4          0.2         setosa  #> 10            1           1 1.5          0.1         setosa  #> # … with 140 more rows"},{"path":"https://lhdjung.github.io/scrutiny/reference/disperse.html","id":null,"dir":"Reference","previous_headings":"","what":"Vary hypothetical group sizes — disperse","title":"Vary hypothetical group sizes — disperse","text":"published studies report total sample size group sizes. However, group sizes crucial consistency tests GRIM. Call disperse() generate possible group sizes add total sample size, total even. disperse2() variant odd totals. takes two consecutive numbers generates decreasing values lower well increasing values upper. way, combinations still add total. disperse_total() directly takes total sample size, checks even odd, splits accordingly, applies disperse() disperse2(), respectively. functions primarily intended helpers. form backbone grim_map_total_n() functions created function_map_total_n().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/disperse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vary hypothetical group sizes — disperse","text":"","code":"disperse(   n,   dispersion = 0:5,   n_min = 1L,   n_max = NULL,   constant = NULL,   constant_index = NULL )  disperse2(   n,   dispersion = 0:5,   n_min = 1L,   n_max = NULL,   constant = NULL,   constant_index = NULL )  disperse_total(   n,   dispersion = 0:5,   n_min = 1L,   n_max = NULL,   constant = NULL,   constant_index = NULL )"},{"path":"https://lhdjung.github.io/scrutiny/reference/disperse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vary hypothetical group sizes — disperse","text":"n Numeric: disperse(), single number go . half even total sample size. disperse2(), two consecutive numbers closest half odd total sample size (e.g., c(25, 26) total 51). disperse_total(), total sample size. dispersion Numeric. Vector determines steps n (, disperse_total(), half n). Default 0:5. n_min Numeric. Minimal group size. Default 1L. n_max Numeric. Maximal group size. Default NULL, .e., maximum. constant Optionally, add length-2 vector list length-2 vectors (data frame exactly two rows) accompany pairs dispersed values. Default NULL, .e., constant values. constant_index Integer (length 1). Index constant first constant column output tibble. NULL (default), constant go right n_change.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/disperse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vary hypothetical group sizes — disperse","text":"tibble (data frame) columns: n includes dispersed n values. Every pair consecutive rows n values add total. n_change records input n transformed output n. disperse2(), n_change strings label lower input n values n1 higher one n2.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/disperse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Vary hypothetical group sizes — disperse","text":"group size less n_min greater n_max, removed. complementary size group also removed. constant values pairwise repeated. constant must length-2 atomic vector list vectors. constant data frame named list, resulting columns names list-element names. list named, new column names \"constant1\", \"constant2\", etc; just \"constant\", single pair.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/disperse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Vary hypothetical group sizes — disperse","text":"Bauer, P. J., & Francis, G. (2021). Expression Concern: Light Dark? Recalling Moral Behavior Changes Perception Brightness. Psychological Science, 32(12), 2042–2043. https://journals.sagepub.com/doi/10.1177/09567976211058727","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/disperse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vary hypothetical group sizes — disperse","text":"","code":"# For a total sample size of 40, # set `n` to `20`: disperse(n = 20) #> # A tibble: 12 × 2 #>        n n_change #>    <dbl>    <dbl> #>  1    20        0 #>  2    20        0 #>  3    19       -1 #>  4    21        1 #>  5    18       -2 #>  6    22        2 #>  7    17       -3 #>  8    23        3 #>  9    16       -4 #> 10    24        4 #> 11    15       -5 #> 12    25        5  # Specify `dispersion` to control # the steps up and down from `n`: disperse(n = 20, dispersion = c(3, 6, 10)) #> # A tibble: 6 × 2 #>       n n_change #>   <dbl>    <dbl> #> 1    17       -3 #> 2    23        3 #> 3    14       -6 #> 4    26        6 #> 5    10      -10 #> 6    30       10  # In `disperse2()`, specify `n` as two # consecutive numbers -- i.e., group sizes: disperse2(n = c(25, 26)) #> # A tibble: 12 × 2 #>        n n_change #>    <dbl>    <dbl> #>  1    25        0 #>  2    26        0 #>  3    24       -1 #>  4    27        1 #>  5    23       -2 #>  6    28        2 #>  7    22       -3 #>  8    29        3 #>  9    21       -4 #> 10    30        4 #> 11    20       -5 #> 12    31        5  # Use the total sample size directly # with `disperse_total()`. An even total # internally triggers `disperse()`... disperse_total(n = 40) #> # A tibble: 12 × 2 #>        n n_change #>    <dbl>    <dbl> #>  1    20        0 #>  2    20        0 #>  3    19       -1 #>  4    21        1 #>  5    18       -2 #>  6    22        2 #>  7    17       -3 #>  8    23        3 #>  9    16       -4 #> 10    24        4 #> 11    15       -5 #> 12    25        5  # ...whereas an odd total triggers `disperse2()`: disperse_total(n = 51) #> # A tibble: 12 × 2 #>        n n_change #>    <dbl>    <dbl> #>  1    25        0 #>  2    26        0 #>  3    24       -1 #>  4    27        1 #>  5    23       -2 #>  6    28        2 #>  7    22       -3 #>  8    29        3 #>  9    21       -4 #> 10    30        4 #> 11    20       -5 #> 12    31        5  # You may add values that repeat along with the # dispersed ones but remain constant themselves. # Such values can be stored in a length-2 vector # for a single column... disperse_total(37, constant = c(\"5.24\", \"3.80\")) #> # A tibble: 12 × 3 #>        n n_change constant #>    <dbl>    <dbl> <chr>    #>  1    18        0 5.24     #>  2    19        0 3.80     #>  3    17       -1 5.24     #>  4    20        1 3.80     #>  5    16       -2 5.24     #>  6    21        2 3.80     #>  7    15       -3 5.24     #>  8    22        3 3.80     #>  9    14       -4 5.24     #> 10    23        4 3.80     #> 11    13       -5 5.24     #> 12    24        5 3.80      # ... or a list of length-2 vectors for multiple # columns. This includes data frames with 2 rows: df_constant <- tibble::tibble(   name = c(\"Paul\", \"Mathilda\"), age = 27:28,   registered = c(TRUE, FALSE) ) disperse_total(37, constant = df_constant) #> # A tibble: 12 × 5 #>        n n_change name       age registered #>    <dbl>    <dbl> <chr>    <int> <lgl>      #>  1    18        0 Paul        27 TRUE       #>  2    19        0 Mathilda    28 FALSE      #>  3    17       -1 Paul        27 TRUE       #>  4    20        1 Mathilda    28 FALSE      #>  5    16       -2 Paul        27 TRUE       #>  6    21        2 Mathilda    28 FALSE      #>  7    15       -3 Paul        27 TRUE       #>  8    22        3 Mathilda    28 FALSE      #>  9    14       -4 Paul        27 TRUE       #> 10    23        4 Mathilda    28 FALSE      #> 11    13       -5 Paul        27 TRUE       #> 12    24        5 Mathilda    28 FALSE"},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Count duplicate values — duplicate_count","title":"Count duplicate values — duplicate_count","text":"duplicate_count() returns frequency table. searching data frame, includes values columns frequency count. function blunt tool designed initial data checking. put much weight results. summary statistics, call audit() results.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count duplicate values — duplicate_count","text":"","code":"duplicate_count(x, numeric_only = TRUE)"},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count duplicate values — duplicate_count","text":"x Vector data frame. numeric_only Boolean. TRUE (default), x data frame, function includes numeric columns string columns coercible numeric. Note: careful setting FALSE. can lead kinds coercion issues.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count duplicate values — duplicate_count","text":"tibble two columns — value includes values x. count frequency value x, descending order. tibble scr_dup_count class, recognized audit() generic.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Count duplicate values — duplicate_count","text":"duplicate_count() thin wrapper around janitor::get_dupes(). Use get_dupes() search duplicate rows. function informative values characters.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count.html","id":"summaries-with-audit-","dir":"Reference","previous_headings":"","what":"Summaries with audit()","title":"Count duplicate values — duplicate_count","text":"S3 method audit() generic, can call audit() following duplicate_count() get summary statistics. mostly self-explaining, count_max count_min directly apply count display respective value numbers, minimal maximal value numbers.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count duplicate values — duplicate_count","text":"","code":"# Count duplicate values... BJsales %>%   duplicate_count() #> # A tibble: 22 × 2 #>    value count #>    <dbl> <int> #>  1  209.     4 #>  2  219.     3 #>  3  257.     3 #>  4  258.     3 #>  5  202.     2 #>  6  210.     2 #>  7  211.     2 #>  8  212.     2 #>  9  215.     2 #> 10  216.     2 #> # … with 12 more rows  # ...and compute summaries: BJsales %>%   duplicate_count() %>%   audit() #> # A tibble: 2 × 7 #>   term  count_max count_min     n   mean     sd median #>   <chr>     <dbl>     <dbl> <int>  <dbl>  <dbl>  <dbl> #> 1 value      209.      260.    22 232.   21.3     221. #> 2 count        4         2     22   2.23  0.528     2"},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count_colpair.html","id":null,"dir":"Reference","previous_headings":"","what":"Count duplicate values by column — duplicate_count_colpair","title":"Count duplicate values by column — duplicate_count_colpair","text":"duplicate_count_colpair() takes data frame checks combination columns duplicates. Results presented tibble, ordered number duplicates.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count_colpair.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count duplicate values by column — duplicate_count_colpair","text":"","code":"duplicate_count_colpair(data, na.rm = TRUE, show_rates = TRUE)"},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count_colpair.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count duplicate values by column — duplicate_count_colpair","text":"data Data frame. na.rm Boolean. TRUE (default), NA values data's columns removed checking duplicates. makes sure NA values different columns counted duplicates . show_rates Boolean. TRUE (default), adds columns rate_x rate_y. See value section. Set show_rates FALSE higher performance.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count_colpair.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count duplicate values by column — duplicate_count_colpair","text":"tibble (data frame) columns --- x y: line contains unique combination data's columns, stored x y output columns. count: Number \"duplicates\", .e., values present x y. rate_x rate_y (added default): rate_x proportion x values duplicated y. Likewise, rate_y proportion y values duplicated x. two rate_* columns equal unless NA values present.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count_colpair.html","id":"summaries-with-audit-","dir":"Reference","previous_headings":"","what":"Summaries with audit()","title":"Count duplicate values by column — duplicate_count_colpair","text":"S3 method audit(), can call audit() following duplicate_count_colpair() get summary duplicate_count_colpair()'s results. tibble single row columns . tibble wide, call audit_list() instead. n: number column pairs tested (index 1). count_min, count_max, count_mean, count_sd, count_median: Summary statistics duplicate count column (index 2 6). rate_x_min, rate_x_max, rate_x_mean, rate_x_sd, rate_x_median: Summary statistics rate_x column (index 7 11). rate_y_min, rate_y_max, rate_y_mean, rate_y_sd, rate_y_median: Summary statistics rate_y column (index 12 16).","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_count_colpair.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count duplicate values by column — duplicate_count_colpair","text":"","code":"# Basic usage: mtcars %>%   duplicate_count_colpair() #> # A tibble: 55 × 5 #>    x     y     count rate_x rate_y #>    <chr> <chr> <int>  <dbl>  <dbl> #>  1 cyl   carb     32 1      1      #>  2 vs    am       32 1      1      #>  3 gear  carb     27 0.844  0.844  #>  4 vs    carb     14 0.438  0.438  #>  5 am    carb     13 0.406  0.406  #>  6 cyl   gear     11 0.344  0.344  #>  7 drat  wt        3 0.0938 0.0938 #>  8 mpg   qsec      2 0.0625 0.0625 #>  9 drat  gear      1 0.0312 0.0312 #> 10 drat  carb      1 0.0312 0.0312 #> # … with 45 more rows  # Summaries with `audit()`: mtcars %>%   duplicate_count_colpair() %>%   audit() #> # A tibble: 1 × 16 #>       n count_…¹ count…² count…³ count…⁴ count…⁵ rate_…⁶ rate_…⁷ rate_…⁸ rate_…⁹ #>   <int>    <int>   <int>   <dbl>   <dbl>   <int>   <dbl>   <dbl>   <dbl>   <dbl> #> 1    55        0      32    2.47    7.38       0       0       1  0.0773   0.231 #> # … with 6 more variables: rate_x_median <dbl>, rate_y_min <dbl>, #> #   rate_y_max <dbl>, rate_y_mean <dbl>, rate_y_sd <dbl>, rate_y_median <dbl>, #> #   and abbreviated variable names ¹​count_min, ²​count_max, ³​count_mean, #> #   ⁴​count_sd, ⁵​count_median, ⁶​rate_x_min, ⁷​rate_x_max, ⁸​rate_x_mean, #> #   ⁹​rate_x_sd"},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_detect.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect duplicate values — duplicate_detect","title":"Detect duplicate values — duplicate_detect","text":"every value vector data frame, duplicate_detect() tests whether least one identical value. Test results presented next every value. default, numeric columns string columns coercible numeric tested (x data frame). columns silently dropped. function blunt tool designed initial data checking. put much weight results. summary statistics, call audit() results.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_detect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect duplicate values — duplicate_detect","text":"","code":"duplicate_detect(x, numeric_only = TRUE, colname_end = \"dup\")"},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_detect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect duplicate values — duplicate_detect","text":"x Vector data frame. numeric_only Boolean. TRUE (default) x data frame, function test numeric columns string columns coercible numeric. Note: careful setting FALSE. can lead kinds coercion issues. colname_end String. Name ending Boolean test result columns. Default \"dup\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_detect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect duplicate values — duplicate_detect","text":"tibble (data frame) — x vector, two columns: input value Boolean has_duplicates. x data frame, output tibble () columns x, columns' right, corresponding Boolean column index value. tibble scr_dup_detect class, recognized audit() generic.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_detect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect duplicate values — duplicate_detect","text":"function informative many input values characters . Many may duplicates just chance. example, R's built-iris data set, 99% values duplicates. general, fewer values characters per value , significant duplicate_detect()'s results .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_detect.html","id":"summaries-with-audit-","dir":"Reference","previous_headings":"","what":"Summaries with audit()","title":"Detect duplicate values — duplicate_detect","text":"S3 method audit() generic, can call audit() following duplicate_detect(). returns tibble columns --- variable: original data frame's variables least one \"duplicated\" value: one least one duplicate anywhere else data frame. vector, x. n_duplicated: Number \"duplicated\" values variable: least one duplicate anywhere data frame. dup_rate: Rate \"duplicated\" values variable. final row, .total, summarizes across rows: adds n_duplicated n_total columns, calculates average dup_rate column.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/duplicate_detect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect duplicate values — duplicate_detect","text":"","code":"# Find duplicate values in a data frame... duplicate_detect(x = pigs4) #> # A tibble: 5 × 4 #>   snout snout_dup  tail tail_dup #>   <dbl> <lgl>     <dbl> <lgl>    #> 1  4.74 FALSE      6.89 FALSE    #> 2  8.13 TRUE       7.33 FALSE    #> 3  4.22 TRUE       6.10 FALSE    #> 4  4.22 TRUE       7.57 FALSE    #> 5  5.18 FALSE      8.13 TRUE      # ...or in a single vector: duplicate_detect(x = pigs4$snout) #> # A tibble: 5 × 2 #>   value has_duplicates #>   <dbl> <lgl>          #> 1  4.74 FALSE          #> 2  8.13 FALSE          #> 3  4.22 TRUE           #> 4  4.22 TRUE           #> 5  5.18 FALSE           # Summary statistics with `audit()`: pigs4 %>%   duplicate_detect() %>%   audit() #> # A tibble: 3 × 4 #>   variable n_duplicated n_total dup_rate #>   <chr>           <int>   <int>    <dbl> #> 1 snout               3       5      0.6 #> 2 tail                1       5      0.2 #> 3 .total              4      10      0.4  # If there are many values and/or few # characters per value, `duplicate_detect()` # can be misleading: iris %>%   duplicate_detect() #> # A tibble: 150 × 8 #>    Sepal.Length Sepal.Length_dup Sepal…¹ Sepal…² Petal…³ Petal…⁴ Petal…⁵ Petal…⁶ #>           <dbl> <lgl>              <dbl> <lgl>     <dbl> <lgl>     <dbl> <lgl>   #>  1          5.1 TRUE                 3.5 TRUE        1.4 TRUE        0.2 TRUE    #>  2          4.9 TRUE                 3   TRUE        1.4 TRUE        0.2 TRUE    #>  3          4.7 TRUE                 3.2 TRUE        1.3 TRUE        0.2 TRUE    #>  4          4.6 TRUE                 3.1 TRUE        1.5 TRUE        0.2 TRUE    #>  5          5   TRUE                 3.6 TRUE        1.4 TRUE        0.2 TRUE    #>  6          5.4 TRUE                 3.9 TRUE        1.7 TRUE        0.4 TRUE    #>  7          4.6 TRUE                 3.4 TRUE        1.4 TRUE        0.3 TRUE    #>  8          5   TRUE                 3.4 TRUE        1.5 TRUE        0.2 TRUE    #>  9          4.4 TRUE                 2.9 TRUE        1.4 TRUE        0.2 TRUE    #> 10          4.9 TRUE                 3.1 TRUE        1.5 TRUE        0.1 TRUE    #> # … with 140 more rows, and abbreviated variable names ¹​Sepal.Width, #> #   ²​Sepal.Width_dup, ³​Petal.Length, ⁴​Petal.Length_dup, ⁵​Petal.Width, #> #   ⁶​Petal.Width_dup  iris %>%   duplicate_detect() %>%   audit() #> # A tibble: 5 × 4 #>   variable     n_duplicated n_total dup_rate #>   <chr>               <int>   <int>    <dbl> #> 1 Petal.Length          150     150    1     #> 2 Petal.Width           148     150    0.987 #> 3 Sepal.Length          144     150    0.96  #> 4 Sepal.Width           150     150    1     #> 5 .total                592     600    0.987"},{"path":"https://lhdjung.github.io/scrutiny/reference/fractional-rounding.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized rounding to the nearest fraction of a specified denominator — fractional-rounding","title":"Generalized rounding to the nearest fraction of a specified denominator — fractional-rounding","text":"Two functions round numbers specific fractions, just next higher decimal level. inspired janitor::round_to_fraction() feature options reround(): reround_to_fraction() closely follows janitor::round_to_fraction() first rounding fractions whole number, optionally rounding result specific number digits usual way. reround_to_fraction_level() rounds nearest fraction number specific decimal level (.e., number digits), without subsequent rounding. closer conventional rounding functions.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/fractional-rounding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized rounding to the nearest fraction of a specified denominator — fractional-rounding","text":"","code":"reround_to_fraction(   x = NULL,   denominator = 1,   digits = Inf,   rounding = \"up_or_down\",   threshold = 5,   symmetric = FALSE )  reround_to_fraction_level(   x = NULL,   denominator = 1,   digits = 0L,   rounding = \"up_or_down\",   threshold = 5,   symmetric = FALSE )"},{"path":"https://lhdjung.github.io/scrutiny/reference/fractional-rounding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized rounding to the nearest fraction of a specified denominator — fractional-rounding","text":"x Numeric. Vector numbers rounded. denominator Numeric (>= 1) . x rounded nearest fraction denominator. Default 1. digits Numeric (whole numbers). reround_to_fraction(): digits specified, values resulting fractional rounding subsequently rounded many decimal places. set \"auto\", internally becomes ceiling(log10(denominator)) + 1, janitor::round_to_fraction(). Default Inf, case subsequent rounding. reround_to_fraction_level(): function round fraction number decimal level specified digits. Default 0. rounding, threshold, symmetric arguments passed reround().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/fractional-rounding.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized rounding to the nearest fraction of a specified denominator — fractional-rounding","text":"Numeric vector length x unless rounding either \"up_or_down\", \"up_from_or_down_from\", \"ceiling_or_floor\". cases, always length 2.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/fractional-rounding.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized rounding to the nearest fraction of a specified denominator — fractional-rounding","text":"","code":"#`reround_to_fraction()` rounds `0.4` # to `0` if `denominator` is `1`, which # is the usual integer rounding... reround_to_fraction(0.4, denominator = 1, rounding = \"even\") #> [1] 0  # ...but if `denominator` is `2`, it rounds to the nearest # fraction of 2, which is `0.5`: reround_to_fraction(0.4, denominator = 2, rounding = \"even\") #> [1] 0.5  # Likewise with fractions of 3: reround_to_fraction(0.25, denominator = 3, rounding = \"even\") #> [1] 0.3333333  # The default for `rounding` is to round # both up and down, as in `reround()`: reround_to_fraction(0.4, denominator = 2) #> [1] 0.5 0.5  # These two rounding procedures differ # at the tie points: reround_to_fraction(0.25, denominator = 2) #> [1] 0.5 0.0  # `reround_to_fraction_level()`, in contrast, # uses `digits` to determine some decimal level, # and then rounds to the closest fraction at # that level: reround_to_fraction_level(0.12345, denominator = 2, digits = 0) #> [1] 0 0 reround_to_fraction_level(0.12345, denominator = 2, digits = 1) #> [1] 0.1 0.1 reround_to_fraction_level(0.12345, denominator = 2, digits = 2) #> [1] 0.125 0.125"},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Create new *_map() functions — function_map","title":"Create new *_map() functions — function_map","text":"function_map() creates new basic mapper functions consistency tests, grim_map() debit_map(). context, see vignette(\"consistency-tests\"), section Creating mappers function_map().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create new *_map() functions — function_map","text":"","code":"function_map(   .fun,   .reported,   .name_test,   .name_class = NULL,   .args_disabled = NULL,   .col_names = NULL,   .col_control = NULL,   .col_filler = NULL )"},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create new *_map() functions — function_map","text":".fun Single-case consistency testing function applied row data frame, (non-exported) scrutiny functions grim_scalar() debit_scalar(). must return Boolean value length 1, .e., TRUE FALSE. .reported String. Names columns tested. .name_test String (length 1). Plain-text name consistency test, \"GRIM\". .name_class String. Optionally, one classes added output data frame. Default NULL, .e., extra class (see Details). .args_disabled Optionally, string vector names arguments *_scalar() function work factory-made function. user  tries specify arguments, informative error thrown. .col_names (Experimental) Optionally, string vector names additional columns derived *_scalar() function. Requires .col_control .col_filler specifications. .col_control (Experimental) Optionally, single string name *_scalar() function's Boolean argument controls columns named .col_names displayed. .col_filler (Experimental) Optionally, vector specifying values .col_names columns rows *_scalar() function returned consistency value.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create new *_map() functions — function_map","text":"factory-made function arguments: data: Data frame columns named .reported. must columns named key arguments .fun. columns permitted. Arguments named .reported values. can specified names data columns function rename column using .reported name. reported, fun, name_class: calling function_map() spelled without dots. can override defaults calling factory-made function. ...: Arguments passed .fun. include column-identifying arguments derived .reported.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create new *_map() functions — function_map","text":"output tibble returned factory-made function inherit one two classes independently .name_class argument: inherit class named \"scr_{tolower(.name_test)}_map\"; example, \"scr_grim_map\" .name_test \"GRIM\". rounding argument specified via ..., else .fun rounding argument default, output tibble inherit class named \"scr_rounding_{rounding}\"; example, \"scr_rounding_up_or_down\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map.html","id":"value-returned-by-the-factory-made-function","dir":"Reference","previous_headings":"","what":"Value returned by the factory-made function","title":"Create new *_map() functions — function_map","text":"tibble includes \"consistency\": Boolean column showing whether values left mutually consistent (TRUE) (FALSE).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create new *_map() functions — function_map","text":"","code":"# Basic test implementation for \"SCHLIM\", # a mock test with no real significance: schlim_scalar <- function(y, n) {   (y / 3) > n }  # Let the function factory produce # a mapper function for SCHLIM: schlim_map <- function_map(   .fun = schlim_scalar,   .reported = c(\"y\", \"n\"),   .name_test = \"SCHLIM\" )  # Example data: df1 <- tibble::tibble(y = 16:25, n = 3:12)  # Call the \"factory-made\" function: schlim_map(df1) #> # A tibble: 10 × 3 #>        y     n consistency #>    <int> <int> <lgl>       #>  1    16     3 TRUE        #>  2    17     4 TRUE        #>  3    18     5 TRUE        #>  4    19     6 TRUE        #>  5    20     7 FALSE       #>  6    21     8 FALSE       #>  7    22     9 FALSE       #>  8    23    10 FALSE       #>  9    24    11 FALSE       #> 10    25    12 FALSE"},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Create new *_map_seq() functions — function_map_seq","title":"Create new *_map_seq() functions — function_map_seq","text":"function_map_seq() engine powers grim_map_seq() debit_map_seq(). creates new, \"manufactured\" functions apply consistency tests GRIM DEBIT sequences specified variables. sequences centered around reported values variables. default, inconsistent values dispersed tested. provides easy powerful way assess whether small errors computing reporting may responsible inconsistencies published statistics. arguments set defaults arguments manufactured function. can still specified differently calling latter. functions created way exported packages, written created purrr adverbs; see explanations examples vignette(\"consistency-tests\"), section Creating mappers function_map().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create new *_map_seq() functions — function_map_seq","text":"","code":"function_map_seq(   .fun,   .var = Inf,   .reported,   .name_test,   .name_class = NULL,   .args_disabled = NULL,   .dispersion = 1:5,   .out_min = \"auto\",   .out_max = NULL,   .include_reported = FALSE,   .include_consistent = FALSE )"},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create new *_map_seq() functions — function_map_seq","text":".fun Function grim_map(): used test columns data frame consistency. Test results Boolean need contained column called \"consistency\" added input data frame. modified data frame returned .fun. .var String. Variables dispersed manufactured function. Defaults .reported. .reported String. variables manufactured function can disperse principle. .name_test String (length 1). name consistency test, \"GRIM\", optionally shown message using manufactured function. .name_class String. specified, tibbles returned manufactured function inherit string S3 class. Default NULL, .e., extra class. .args_disabled String. Optionally, names basic *_map() function's arguments. arguments throw error specified calling factory-made function. .dispersion Numeric. Sequence steps reported values. adjusted values' decimal level. example, reported 8.34, step size 0.01. Default 1:5, five steps . .out_min, .out_max specified calling factory-made function, output restricted .out_min .out_max. Defaults \"auto\" .out_min, .e., minimum one decimal unit zero; NULL .out_max, .e., maximum. .include_reported Boolean. reported values included sequences originating ? Default FALSE might redundant bias results. .include_consistent Boolean. function also process consistent cases (among reported), just inconsistent ones? Default FALSE focus clarifying inconsistencies.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create new *_map_seq() functions — function_map_seq","text":"function . (\"Testable statistics\" variables can selected via var, varied. variables except parentheses selected default.) factory-made function also dots, ..., pass arguments .fun, .e., basic mapper function.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_seq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create new *_map_seq() functions — function_map_seq","text":"function -called function factory: produces functions, grim_map_seq(). specifically, function operator (.k.. decorator) also takes functions inputs, grim_map(). See Wickham (2019, ch. 10-11).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_seq.html","id":"conventions","dir":"Reference","previous_headings":"","what":"Conventions","title":"Create new *_map_seq() functions — function_map_seq","text":"name function manufactured function_map_seq() mechanically follow input function. example, grim_map_seq() derives grim_map(). pattern fits best input function named test performs data frame, followed _map: grim_map() applies GRIM, debit_map() applies DEBIT, etc. Much true classes data frames returned manufactured function via .name_class argument function_map_seq(). function's name preceded name package contains acronym package's name. way, existing classes scr_grim_map_seq scr_debit_map_seq.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_seq.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create new *_map_seq() functions — function_map_seq","text":"Wickham, H. (2019). Advanced R (Second Edition). CRC Press/Taylor Francis Group. https://adv-r.hadley.nz/index.html","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create new *_map_seq() functions — function_map_seq","text":"","code":"# Function definition of `grim_map_seq()`: grim_map_seq <- function_map_seq(   .fun = grim_map,   .reported = c(\"x\", \"n\"),   .name_test = \"GRIM\", )   # Case study of SCHLIM, a new consistency test --------------  # (Note: This is a mock test without any real significance. # Its only purpose is to show the minimal steps necessary # for implementing a serious consistency test, and to use # it as a starting point for `function_map_total_n()`.)  # The \"SCHLIM test\" is analogous to GRIM as implemented # in scrutiny. This is also true for the function names. # Note that the analogue to `schlim_scalar()`, a function # called `grim_scalar()`, is not exported from scrutiny, # but used internally for `grim()`, `grim_map()`, and, # indirectly, `grim_map_seq()`.  # Basic test implementation: schlim_scalar <- function(y, n) {   (y / 3) > n }  # This step is not needed below, but # included for completeness: schlim <- Vectorize(schlim_scalar)  # This will be the input function for # `function_map_total_n()`: schlim_map <- function_map(   .fun = schlim_scalar,   .reported = c(\"y\", \"n\"),   .name_test = \"SCHLIM\" )  # Fire up the function factory: schlim_map_seq <- function_map_seq(   .fun = schlim_map,   .reported = c(\"y\", \"n\"),   .name_test = \"SCHLIM\", )  # Create some example data: df1 <- tibble::tibble(y = 16:25, n = 3:12)  # Call the manufactured function: out <- schlim_map_seq(df1) out #> # A tibble: 120 × 5 #>        y     n consistency  case var   #>    <int> <int> <lgl>       <int> <chr> #>  1    15     7 FALSE           1 y     #>  2    16     7 FALSE           1 y     #>  3    17     7 FALSE           1 y     #>  4    18     7 FALSE           1 y     #>  5    19     7 FALSE           1 y     #>  6    21     7 FALSE           1 y     #>  7    22     7 TRUE            1 y     #>  8    23     7 TRUE            1 y     #>  9    24     7 TRUE            1 y     #> 10    25     7 TRUE            1 y     #> # … with 110 more rows  # Summarize the results: audit_seq(out) #> Error in rlang::eval_bare(rlang::parse_expr(fun_test)): object 'schlim_map' not found"},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_total_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Create new *_map_total_n() functions — function_map_total_n","title":"Create new *_map_total_n() functions — function_map_total_n","text":"function_map_total_n() engine powers functions grim_map_total_n(). creates new, \"manufactured\" functions consistency tests. new functions take reported summary statistics means apply tests cases total sample size known, group sizes. works making disperse_total() create multiple pairs hypothetical group sizes, add reported total. need exactly two groups. functions created way exported packages, written created purrr adverbs; see explanations examples vignette(\"consistency-tests\"), section Creating mappers function_map().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_total_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create new *_map_total_n() functions — function_map_total_n","text":"","code":"function_map_total_n(   .fun,   .reported,   .name_test,   .name_class = NULL,   .dispersion = 0:5,   .n_min = 1L,   .n_max = NULL,   .constant = NULL,   .constant_index = NULL )"},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_total_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create new *_map_total_n() functions — function_map_total_n","text":".fun Function grim_map: used test columns data frame consistency. Test results Boolean need contained column called consistency added input data frame. modified data frame returned .fun. .reported String. Names columns containing group-specific statistics reported alongside total sample size(s). tested consistency hypothetical group sizes. Examples \"x\" GRIM c(\"x\", \"sd\") DEBIT. data frame reported group statistics manufactured function takes input, need fan like \"x1\", \"x2\", \"sd1\", \"sd2\". .name_test String (length 1). name consistency test, \"GRIM\", optionally shown message using manufactured function. .name_class String. specified, tibbles returned manufactured function inherit string S3 class. Default NULL, .e., extra class. .dispersion, .n_min, .n_max, .constant, .constant_index Arguments passed disperse_total(), using defaults .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_total_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create new *_map_total_n() functions — function_map_total_n","text":"function : factory-made function also dots, ..., pass arguments .fun, .e., basic mapper function.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_total_n.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create new *_map_total_n() functions — function_map_total_n","text":"function -called function factory: produces functions, grim_map_total_n(). specifically, function operator (.k.. decorator) also takes functions inputs, grim_map(). See Wickham (2019, ch. 10-11).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_total_n.html","id":"conventions","dir":"Reference","previous_headings":"","what":"Conventions","title":"Create new *_map_total_n() functions — function_map_total_n","text":"name function manufactured function_map_total_n() mechanically follow input function. example, grim_map_total_n() derives grim_map(). pattern fits best input function named test performs data frame, followed _map: grim_map() applies GRIM, debit_map() applies DEBIT, etc. Much true classes data frames returned manufactured function via .name_class argument function_map_total_n(). function's name preceded name package contains acronym package's name. way, existing classes scr_grim_map_total_n scr_debit_map_total_n.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_total_n.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create new *_map_total_n() functions — function_map_total_n","text":"Bauer, P. J., & Francis, G. (2021). Expression Concern: Light Dark? Recalling Moral Behavior Changes Perception Brightness. Psychological Science, 32(12), 2042–2043. https://journals.sagepub.com/doi/10.1177/09567976211058727 Wickham, H. (2019). Advanced R (Second Edition). CRC Press/Taylor Francis Group. https://adv-r.hadley.nz/index.html","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/function_map_total_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create new *_map_total_n() functions — function_map_total_n","text":"","code":"# Function definition of `grim_map_total_n()`: grim_map_total_n <- function_map_total_n(   .fun = grim_map,   .reported = \"x\",   .name_test = \"GRIM\",   .name_class = \"scr_grim_map_total_n\" )   # Case study of SCHLIM, a new consistency test --------------  # (Note: This is a mock test without any real significance. # Its only purpose is to show the minimal steps necessary # for implementing a serious consistency test, and to use # it as a starting point for `function_map_total_n()`.)  # The \"SCHLIM test\" is analogous to GRIM as implemented # in scrutiny. This is also true for the function names. # Note that the analogue to `schlim_scalar()`, a function # called `grim_scalar()`, is not exported from scrutiny, # but used internally for `grim()`, `grim_map()`, and, # indirectly, `grim_map_total_n()`.  # Basic test implementation: schlim_scalar <- function(y, n) {   (y / 3) > n }  # This step is not needed below, but # included for completeness: schlim <- Vectorize(schlim_scalar)  # This will be the input function for # `function_map_total_n()`: schlim_map <- function_map(   .fun = schlim_scalar,   .reported = c(\"y\", \"n\"),   .name_test = \"SCHLIM\" )  # Fire up the function factory: schlim_map_total_n <- function_map_total_n(   .fun = schlim_map,   .reported = \"y\",   .name_test = \"SCHLIM\", )  # Create some example data: df1 <- tibble::tibble(   y1 = 16:25,   y2 = 26:35,   n  = 12:21 ) df1 #> # A tibble: 10 × 3 #>       y1    y2     n #>    <int> <int> <int> #>  1    16    26    12 #>  2    17    27    13 #>  3    18    28    14 #>  4    19    29    15 #>  5    20    30    16 #>  6    21    31    17 #>  7    22    32    18 #>  8    23    33    19 #>  9    24    34    20 #> 10    25    35    21  # Call the manufactured function: out <- schlim_map_total_n(df1) out #> # A tibble: 240 × 7 #>        y     n n_change consistency both_consistent  case dir   #>    <int> <dbl>    <dbl> <lgl>       <lgl>           <int> <chr> #>  1    16     6        0 FALSE       FALSE               1 forth #>  2    26     6        0 TRUE        FALSE               1 forth #>  3    16     5       -1 TRUE        TRUE                1 forth #>  4    26     7        1 TRUE        TRUE                1 forth #>  5    16     4       -2 TRUE        TRUE                1 forth #>  6    26     8        2 TRUE        TRUE                1 forth #>  7    16     3       -3 TRUE        FALSE               1 forth #>  8    26     9        3 FALSE       FALSE               1 forth #>  9    16     2       -4 TRUE        FALSE               1 forth #> 10    26    10        4 FALSE       FALSE               1 forth #> # … with 230 more rows  # Summarize the results: audit_total_n(out) #> # A tibble: 10 × 8 #>       y1    y2     n hits_total hits_forth hits_back scenarios_total hit_rate #>    <int> <int> <dbl>      <dbl>      <dbl>     <dbl>           <dbl>    <dbl> #>  1    16    26    12          2          2         0              12   0.167  #>  2    17    27    13          1          1         0              12   0.0833 #>  3    18    28    14          1          1         0              12   0.0833 #>  4    19    29    15          1          1         0              12   0.0833 #>  5    20    30    16          0          0         0              12   0      #>  6    21    31    17          0          0         0              12   0      #>  7    22    32    18          0          0         0              12   0      #>  8    23    33    19          0          0         0              12   0      #>  9    24    34    20          0          0         0              12   0      #> 10    25    35    21          0          0         0              12   0"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim-stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Possible GRIM inconsistencies — grim-stats","title":"Possible GRIM inconsistencies — grim-stats","text":"Even without GRIM-testing, means / proportions sample sizes granular distributions entail key data: grim_total() returns absolute number GRIM-inconsistencies possible given mean percentage's number decimal places (D) corresponding sample size. grim_ratio() returns proportion normalized 10^D, therefore comparable across mean percentage values reported varying D. grim_ratio_upper() returns upper bound grim_ratio() given D. discussion, see vignette(\"grim\"), section GRIM statistics.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim-stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Possible GRIM inconsistencies — grim-stats","text":"","code":"grim_total(x, n, items = 1, percent = FALSE)  grim_ratio(x, n, items = 1, percent = FALSE)  grim_ratio_upper(x, percent = FALSE)"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim-stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Possible GRIM inconsistencies — grim-stats","text":"x String numeric. Mean percentage value computed data integer units (e.g., mean scores Likert scale percentage study participants condition). Note: Numeric inputs include trailing zeros, although important functions. See documentation grim(). n Integer. Sample size corresponding x. items Integer. Number items composing mean percentage value question. Default 1. percent Boolean. Set percent TRUE x expressed proportion 100 rather 1. functions account fact increasing decimal count 2. Default FALSE.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim-stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Possible GRIM inconsistencies — grim-stats","text":"Integer double. number proportion possible GRIM inconsistencies.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim-stats.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Possible GRIM inconsistencies — grim-stats","text":"Brown, N. J. L., & Heathers, J. . J. (2017). GRIM Test: Simple Technique Detects Numerous Anomalies Reporting Results Psychology. Social Psychological Personality Science, 8(4), 363–369. https://journals.sagepub.com/doi/10.1177/1948550616673876","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/grim-stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Possible GRIM inconsistencies — grim-stats","text":"","code":"# Many value sets are inconsistent here: grim_total(x = \"83.29\", n = 21) #> [1] 79 grim_ratio(x = \"83.29\", n = 21) #> [1] 0.79  # No sets are inconsistent in this case... grim_total(x = \"5.14\", n = 83) #> [1] 17 grim_ratio(x = \"5.14\", n = 83) #> [1] 0.17  # ... but most would be if `x` was a percentage: grim_total(x = \"5.14\", n = 83, percent = TRUE) #> [1] 9917 grim_ratio(x = \"5.14\", n = 83, percent = TRUE) #> [1] 0.9917"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim.html","id":null,"dir":"Reference","previous_headings":"","what":"The GRIM test (granularity-related inconsistency of means) — grim","title":"The GRIM test (granularity-related inconsistency of means) — grim","text":"grim() checks reported mean value integer data mathematically consistent reported sample size number items compose mean value. Set percent TRUE x percentage. convert x decimal number adjust decimal count accordingly. function vectorized, recommended use grim_map() testing multiple cases.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The GRIM test (granularity-related inconsistency of means) — grim","text":"","code":"grim(   x,   n,   items = 1,   percent = FALSE,   show_rec = FALSE,   rounding = \"up_or_down\",   threshold = 5,   symmetric = FALSE,   tolerance = .Machine$double.eps^0.5 )"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The GRIM test (granularity-related inconsistency of means) — grim","text":"x String. reported mean percentage value. n Integer. reported sample size. items Numeric. number items composing x. Default 1, common case. percent Boolean. Set percent TRUE x percentage. convert decimal number adjust decimal count (.e., increase 2). Default FALSE. show_rec Boolean. internal use .  set TRUE, output matrix also contains intermediary values GRIM-testing. specify manually; instead, use show_rec grim_map(). Default FALSE. rounding String. Rounding method methods used reconstructing values x compared. Default \"up_or_down\" (5). threshold Numeric. rounding set \"up_from\", \"down_from\", \"up_from_or_down_from\", set threshold number reconstructed values rounded . Otherwise, argument plays role. Default 5. symmetric Boolean. Set symmetric TRUE rounding negative numbers \"\", \"\", \"up_from\", \"down_from\" mirror positive numbers absolute values always equal. Default FALSE. tolerance Numeric. Tolerance comparison x possible mean percentage values. Default circa 0.000000015 (1.490116e-08), dplyr::near().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The GRIM test (granularity-related inconsistency of means) — grim","text":"Boolean. TRUE x, n, items mutually consistent, FALSE .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The GRIM test (granularity-related inconsistency of means) — grim","text":"x values need strings strings retain trailing zeros, important GRIM test decimal digits. Use restore_zeros() numeric values (values numeric values point) easily supply trailing zeros might . See documentation . Browse source code grim.R file. grim() vectorized version internal grim_scalar() function found .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim.html","id":"rounding","dir":"Reference","previous_headings":"","what":"Rounding","title":"The GRIM test (granularity-related inconsistency of means) — grim","text":"options rounding argument. Reconstructed mean percentage values can rounded either ways: Rounded \"even\" using base R's round(). Rounded \"\" \"\" 5. (Note SAS, SPSS, Stata, Matlab, Excel round \"\" 5, whereas Python rounds \"\" 5.) Rounded \"up_from\" \"down_from\" number, must specified via threshold argument. Given \"ceiling\" \"floor\" respective decimal place. Rounded towards zero \"trunc\" away zero \"anti_trunc\". default, \"up_or_down\", allows numbers rounded either \"\" \"\" 5 GRIM-testing; likewise \"up_from_or_down_from\" \"ceiling_or_floor\". rounding = \"up_or_down\", n 40 80 x two decimal places, values test inconsistent; note many either rounding = \"\" rounding = \"\", indeed rounding method. part general pattern: n 400 800 x three decimal places, etc. information methods, see documentation round(), round_up(), round_ceiling(). include ways rounding. reconstructed values rounded can also calibrated threshold symmetric arguments.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The GRIM test (granularity-related inconsistency of means) — grim","text":"Brown, N. J. L., & Heathers, J. . J. (2017). GRIM Test: Simple Technique Detects Numerous Anomalies Reporting Results Psychology. Social Psychological Personality Science, 8(4), 363–369. https://journals.sagepub.com/doi/10.1177/1948550616673876","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/grim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The GRIM test (granularity-related inconsistency of means) — grim","text":"","code":"# A mean of 5.19 is not consistent with a sample size of 28: grim(x = \"5.19\", n = 28)    # `x` in quotes! #>  5.19  #> FALSE   # However, it is consistent with a sample size of 32: grim(x = \"5.19\", n = 32) #> 5.19  #> TRUE   # For a scale composed of two items: grim(x = \"2.84\", n = 16, items = 2) #> 2.84  #> TRUE   # With percentages instead of means -- here, 71%: grim(x = \"71\", n = 43, percent = TRUE) #>    71  #> FALSE"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_granularity.html","id":null,"dir":"Reference","previous_headings":"","what":"Granularity of non-continuous scales — grim_granularity","title":"Granularity of non-continuous scales — grim_granularity","text":"grim_granularity() computes minimal difference two means proportions ordinal interval data. grim_items() reverse: converts granularity values number scale items, might used consistency testing functions grim().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_granularity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Granularity of non-continuous scales — grim_granularity","text":"","code":"grim_granularity(n, items = 1)  grim_items(n, gran, tolerance = .Machine$double.eps^0.5)"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_granularity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Granularity of non-continuous scales — grim_granularity","text":"n Numeric. Sample size. items Numeric. Number items composing scale. Default 1, hold non-Likert scales. gran Numeric. Granularity. tolerance Numeric. grim_items(), tolerance maximal amount results may differ whole numbers. exceed amount, warning shown.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_granularity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Granularity of non-continuous scales — grim_granularity","text":"Numeric. Granularity number items.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_granularity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Granularity of non-continuous scales — grim_granularity","text":"two functions differ names arguments --- underlying formula (simple). However, clarity, presented distinct. output grim_items() whole numbers, scale items granularity 1. differ next whole number numeric tolerance (determined argument name), warning shown. wrong determine scale's granularity minimal distance two values given distribution. signify values actually differ, can differ priori based scale design. Also, keep mind continuous scales granularity .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_granularity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Granularity of non-continuous scales — grim_granularity","text":"Brown, N. J. L., & Heathers, J. . J. (2017). GRIM Test: Simple Technique Detects Numerous Anomalies Reporting Results Psychology. Social Psychological Personality Science, 8(4), 363–369. https://journals.sagepub.com/doi/10.1177/1948550616673876","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_granularity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Granularity of non-continuous scales — grim_granularity","text":"","code":"# If a non-Likert scale ranges from 0 to 3 # and measures 16 cases: grim_granularity(n = 16)   # `items = 1` by default #> [1] 0.0625  # Same but Likert scale with 2 items: grim_granularity(n = 16, items = 2) #> [1] 0.03125  # If a scale is applied to a single case # and has a granularity of 0.5: grim_items(n = 1, gran = 0.5) #> [1] 2  # With more cases, a warning appears # because items can only be whole numbers: grim_items(n = c(10, 15, 20), gran = 0.5) #> Warning: 3 out of 3 item counts aren't whole numbers. #> → This concerns `0.2`, `0.133`, and `0.1`. #> ! Item counts have a granularity of 1, so they should be whole numbers. Are you #>   sure about the `n` and `gran` values? #> [1] 0.2000000 0.1333333 0.1000000"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map.html","id":null,"dir":"Reference","previous_headings":"","what":"GRIM-test many cases at once — grim_map","title":"GRIM-test many cases at once — grim_map","text":"Call grim_map() GRIM-test number combinations mean/proportion, sample size, number items. Mapping function GRIM-testing. Set percent TRUE x values percentages. convert x values decimals adjust decimal count accordingly. Display intermediary numbers GRIM-testing columns setting show_rec TRUE. summary statistics, call audit() results.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GRIM-test many cases at once — grim_map","text":"","code":"grim_map(   data,   items = 1,   merge_items = TRUE,   percent = FALSE,   x = NULL,   n = NULL,   show_rec = FALSE,   show_prob = FALSE,   rounding = \"up_or_down\",   threshold = 5,   symmetric = FALSE,   tolerance = .Machine$double.eps^0.5,   testables_only = FALSE,   extra = Inf )"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GRIM-test many cases at once — grim_map","text":"data Data frame columns x, n, optionally items (see documentation grim(). default, columns data returned alongside GRIM test results (see extra ). items Integer. items column data, specifies number items composing x values. Default 1, common case. merge_items Boolean. TRUE (default), items column output. Instead, values items column argument multiplied values n column. affect GRIM-testing. percent Boolean. Set percent TRUE x values percentages. convert decimal numbers adjust decimal count (.e., increase 2). also affects ratio column. Default FALSE. x, n Optionally, specify arguments column names data. show_rec Boolean. set TRUE, reconstructed numbers GRIM-testing shown columns. See section Reconstructed numbers . Default FALSE. show_prob Boolean. set TRUE, adds prob column contains probability GRIM inconsistency. simply ratio column censored range 0 1. Default FALSE. rounding, threshold, symmetric, tolerance parameters GRIM-testing; see documentation grim(). testables_only Boolean. testables_only set TRUE, GRIM-testable cases (.e., positive GRIM ratio) included. Default FALSE. extra String integer. column(s) data returned output tibble alongside test results, referenced name(s) number(s). Default Inf, returns columns. return none , set extra 0.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GRIM-test many cases at once — grim_map","text":"tibble columns -- x, n: inputs. consistency: GRIM consistency x, n, items. <extra>: columns data x, n, items. ratio: GRIM ratio; see grim_ratio(). tibble scr_grim_map class, recognized audit() generic.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map.html","id":"reconstructed-numbers","dir":"Reference","previous_headings":"","what":"Reconstructed numbers","title":"GRIM-test many cases at once — grim_map","text":"show_rec set TRUE, output includes following additional columns: rec_sum: sum total mean proportion ostensibly derived. rec_x_upper: upper reconstructed x value. rec_x_lower: lower reconstructed x value. rec_x_upper_rounded: rounded rec_x_upper value. rec_x_lower_rounded: rounded rec_x_lower value. default rounding, \"up_or_down\", last two columns replaced two columns specify rounding procedures (.e., \"_up\" \"_down\").","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map.html","id":"summaries-with-audit-","dir":"Reference","previous_headings":"","what":"Summaries with audit()","title":"GRIM-test many cases at once — grim_map","text":"S3 method audit(), can call audit() following grim_map() get summary grim_map()'s results. tibble single row columns -- incons_cases: number GRIM-inconsistent value sets. all_cases: total number value sets. incons_rate: proportion GRIM-inconsistent value sets. mean_grim_ratio: average GRIM ratios. incons_to_ratio: ratio incons_rate mean_grim_ratio. testable_cases: number GRIM-testable value sets (.e., positive ratio). testable_rate: proportion GRIM-testable value sets.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"GRIM-test many cases at once — grim_map","text":"Brown, N. J. L., & Heathers, J. . J. (2017). GRIM Test: Simple Technique Detects Numerous Anomalies Reporting Results Psychology. Social Psychological Personality Science, 8(4), 363–369. https://journals.sagepub.com/doi/10.1177/1948550616673876","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GRIM-test many cases at once — grim_map","text":"","code":"# Use `grim_map()` on data like these: pigs1 #> # A tibble: 12 × 2 #>    x         n #>    <chr> <dbl> #>  1 7.22     32 #>  2 4.74     25 #>  3 5.23     29 #>  4 2.57     24 #>  5 6.77     27 #>  6 2.68     28 #>  7 7.01     29 #>  8 7.38     26 #>  9 3.14     27 #> 10 6.89     31 #> 11 5.00     25 #> 12 0.24     28  # The `consistency` column shows # whether the values to its left # are GRIM-consistent: pigs1 %>%   grim_map() #> # A tibble: 12 × 4 #>    x         n consistency ratio #>    <chr> <dbl> <lgl>       <dbl> #>  1 7.22     32 TRUE         0.68 #>  2 4.74     25 FALSE        0.75 #>  3 5.23     29 FALSE        0.71 #>  4 2.57     24 FALSE        0.76 #>  5 6.77     27 FALSE        0.73 #>  6 2.68     28 TRUE         0.72 #>  7 7.01     29 FALSE        0.71 #>  8 7.38     26 TRUE         0.74 #>  9 3.14     27 FALSE        0.73 #> 10 6.89     31 FALSE        0.69 #> 11 5.00     25 TRUE         0.75 #> 12 0.24     28 FALSE        0.72  # Display intermediary numbers from # GRIM-testing with `show_rec = TRUE`: pigs1 %>%   grim_map(show_rec = TRUE) #> # A tibble: 12 × 11 #>    x         n consist…¹ rec_sum rec_x…² rec_x…³ rec_x…⁴ rec_x…⁵ rec_x…⁶ rec_x…⁷ #>    <chr> <dbl> <lgl>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #>  1 7.22     32 TRUE       231.     7.25    7.22     7.25    7.25    7.22    7.22 #>  2 4.74     25 FALSE      118.     4.76    4.72     4.76    4.76    4.72    4.72 #>  3 5.23     29 FALSE      152.     5.24    5.21     5.24    5.24    5.21    5.21 #>  4 2.57     24 FALSE       61.7    2.58    2.54     2.58    2.58    2.54    2.54 #>  5 6.77     27 FALSE      183.     6.78    6.74     6.78    6.78    6.74    6.74 #>  6 2.68     28 TRUE        75.0    2.71    2.68     2.71    2.71    2.68    2.68 #>  7 7.01     29 FALSE      203.     7.03    7.00     7.03    7.03    7       7    #>  8 7.38     26 TRUE       192.     7.38    7.35     7.38    7.38    7.35    7.35 #>  9 3.14     27 FALSE       84.8    3.15    3.11     3.15    3.15    3.11    3.11 #> 10 6.89     31 FALSE      214.     6.90    6.87     6.9     6.9     6.87    6.87 #> 11 5.00     25 TRUE       125      5.00    5.00     5       5       5       5    #> 12 0.24     28 FALSE        6.72   0.250   0.214    0.25    0.25    0.21    0.21 #> # … with 1 more variable: ratio <dbl>, and abbreviated variable names #> #   ¹​consistency, ²​rec_x_upper, ³​rec_x_lower, ⁴​rec_x_upper_rounded_up, #> #   ⁵​rec_x_upper_rounded_down, ⁶​rec_x_lower_rounded_up, #> #   ⁷​rec_x_lower_rounded_down  # Get summaries with `audit()`: pigs1 %>%   grim_map() %>%   audit() #> # A tibble: 1 × 7 #>   incons_cases all_cases incons_rate mean_grim_ratio incons_to…¹ testa…² testa…³ #>          <int>     <int>       <dbl>           <dbl>       <dbl>   <int>   <dbl> #> 1            8        12       0.667           0.724       0.921      12       1 #> # … with abbreviated variable names ¹​incons_to_ratio, ²​testable_cases, #> #   ³​testable_rate"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"GRIM-testing with dispersed inputs — grim_map_seq","title":"GRIM-testing with dispersed inputs — grim_map_seq","text":"grim_map_seq() performs GRIM-testing values surrounding input values. provides easy powerful way assess whether small errors computing reporting may responsible GRIM-inconsistencies published statistics. Call audit_seq() results summary statistics.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GRIM-testing with dispersed inputs — grim_map_seq","text":"","code":"grim_map_seq(   data,   x = NULL,   n = NULL,   var = .var,   dispersion = .dispersion,   out_min = .out_min,   out_max = .out_max,   include_reported = .include_reported,   include_consistent = .include_consistent,   ... )"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GRIM-testing with dispersed inputs — grim_map_seq","text":"data data frame grim_map() take. x, n Optionally, specify arguments column names data. var String. Names columns dispersed. Default c(\"x\", \"n\"). dispersion Numeric. Sequence steps var inputs. adjusted values' decimal levels. example, reported 8.34, step size 0.01. Default 1:5, five steps . out_min, out_max specified, output restricted out_min out_max. Defaults \"auto\" out_min, .e., minimum one decimal unit zero; NULL out_max, .e., maximum. include_reported Boolean. reported values included sequences originating ? Default FALSE might redundant bias results. include_consistent Boolean. function also process consistent cases (among reported), just inconsistent ones? Default FALSE focus clarifying inconsistencies. ... Arguments passed grim_map().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GRIM-testing with dispersed inputs — grim_map_seq","text":"tibble (data frame) detailed test results.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_seq.html","id":"summaries-with-audit-seq-","dir":"Reference","previous_headings":"","what":"Summaries with audit_seq()","title":"GRIM-testing with dispersed inputs — grim_map_seq","text":"can call audit_seq() following grim_map_seq(). return data frame columns: x n original inputs, tested consistency . hits_total total number GRIM-consistent value sets found within specified dispersion range. hits_x number GRIM-consistent value sets found varying x. Accordingly n hits_n. (Note consistent reported cases counted hits_* columns include_reported include_consistent set TRUE.) diff_x reports absolute difference x next consistent dispersed value (dispersion steps, actual numeric difference). diff_x_up diff_x_down report difference next higher lower consistent value, respectively. diff_n, diff_n_up, diff_n_down n. Call audit() following audit_seq() summarize results even .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GRIM-testing with dispersed inputs — grim_map_seq","text":"","code":"# `grim_map_seq()` can take any input # that `grim_map()` can take: pigs1 #> # A tibble: 12 × 2 #>    x         n #>    <chr> <dbl> #>  1 7.22     32 #>  2 4.74     25 #>  3 5.23     29 #>  4 2.57     24 #>  5 6.77     27 #>  6 2.68     28 #>  7 7.01     29 #>  8 7.38     26 #>  9 3.14     27 #> 10 6.89     31 #> 11 5.00     25 #> 12 0.24     28  # All the results: out <- grim_map_seq(pigs1, include_consistent = TRUE) out #> # A tibble: 240 × 6 #>    x         n consistency ratio  case var   #>    <chr> <dbl> <lgl>       <dbl> <int> <chr> #>  1 7.17     32 FALSE        0.68     1 x     #>  2 7.18     32 FALSE        0.68     1 x     #>  3 7.19     32 TRUE         0.68     1 x     #>  4 7.20     32 FALSE        0.68     1 x     #>  5 7.21     32 FALSE        0.68     1 x     #>  6 7.23     32 FALSE        0.68     1 x     #>  7 7.24     32 FALSE        0.68     1 x     #>  8 7.25     32 TRUE         0.68     1 x     #>  9 7.26     32 FALSE        0.68     1 x     #> 10 7.27     32 FALSE        0.68     1 x     #> # … with 230 more rows  # Case-wise summaries with `audit_seq()` # can be more important than the raw results: out %>%   audit_seq() #> # A tibble: 12 × 12 #>    x         n consistency hits_to…¹ hits_x hits_n diff_x diff_…² diff_…³ diff_n #>    <chr> <dbl> <lgl>           <int>  <int>  <int>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 7.22     32 TRUE                5      2      3      3       3      -3      4 #>  2 4.74     25 FALSE               4      2      2      2       2      -2      2 #>  3 5.23     29 FALSE               6      3      3      1       1      -2      1 #>  4 2.57     24 FALSE               6      3      3      1       1      -3      1 #>  5 6.77     27 FALSE               7      3      4      1       1      -3      1 #>  6 2.68     28 TRUE                4      2      2      3       3      -4      3 #>  7 7.01     29 FALSE               3      3      0      1       2      -1     NA #>  8 7.38     26 TRUE                5      2      3      3       4      -3      2 #>  9 3.14     27 FALSE               6      3      3      1       1      -3      1 #> 10 6.89     31 FALSE               8      4      4      1       1      -2      3 #> 11 5.00     25 TRUE               12      2     10      4       4      -4      1 #> 12 0.24     28 FALSE               6      3      3      1       1      -3      1 #> # … with 2 more variables: diff_n_up <dbl>, diff_n_down <dbl>, and abbreviated #> #   variable names ¹​hits_total, ²​diff_x_up, ³​diff_x_down"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_total_n.html","id":null,"dir":"Reference","previous_headings":"","what":"GRIM-testing with hypothetical group sizes — grim_map_total_n","title":"GRIM-testing with hypothetical group sizes — grim_map_total_n","text":"reporting group means, published studies report total sample size group sizes corresponding mean. However, group sizes crucial GRIM-testing. two-groups case, grim_map_total_n() helps ways: creates hypothetical group sizes. even total sample size, incrementally moves half total sample size. example, total sample size 40, starts 20, goes 19 21, 18 22, etc. odd sample sizes, starts two integers around half. GRIM-tests values together group means. reports scenarios \"dispersed\" hypothetical group sizes GRIM-consistent group means. works one total sample sizes time. Call audit_total_n() summary statistics.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_total_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GRIM-testing with hypothetical group sizes — grim_map_total_n","text":"","code":"grim_map_total_n(   data,   x1 = NULL,   x2 = NULL,   dispersion = .dispersion,   n_min = .n_min,   n_max = .n_max,   constant = .constant,   constant_index = .constant_index,   ... )"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_total_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GRIM-testing with hypothetical group sizes — grim_map_total_n","text":"data Data frame string columns x1 x2, numeric column n. first two group mean percentage values unknown group sizes, n total sample size. important whether value x1 x2 , first round tests, function switches roles x1 x2, reports outcomes ways. x1, x2 Optionally, specify arguments column names data. dispersion Numeric. Steps half n values. Default 0:5, .e., half n followed five steps . n_min Numeric. Minimal group size. Default 1. n_max Numeric. Maximal group size. Default NULL, .e., maximum. constant Optionally, add length-2 vector list length-2 vectors (data frame exactly two rows) accompany pairs dispersed values. Default NULL, .e., constant values. constant_index Integer (length 1). Index constant first constant column output tibble. NULL (default), constant go right n_change. ... Arguments passed grim_map().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_total_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GRIM-testing with hypothetical group sizes — grim_map_total_n","text":"tibble columns: x, group-wise reported input statistic, repeated row pairs. n dispersed half input n, n_change tracking differences. both_consistent flags scenarios reported x values consistent hypothetical n values. case corresponds row numbers input data frame. dir \"forth\" first half rows \"back\" second half. \"forth\" means x2 input paired larger dispersed n, whereas \"back\" means x1 paired larger dispersed n. columns grim_map() preserved.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_total_n.html","id":"summaries-with-audit-total-n-","dir":"Reference","previous_headings":"","what":"Summaries with audit_total_n()","title":"GRIM-testing with hypothetical group sizes — grim_map_total_n","text":"can call audit_total_n() following grim_map_total_n() get tibble summary statistics. columns: x1, x2, n original inputs. hits_total number scenarios x1 x2 GRIM-consistent. sum hits_forth hits_back . hits_forth number -consistent cases result pairing x2 larger dispersed n value. hits_back , except x1 paired larger dispersed n value. scenarios_total total number test scenarios, whether x1 x2 GRIM-consistent. hit_rate ratio hits_total scenarios_total. Call audit() following audit_total_n() summarize results even .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_total_n.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"GRIM-testing with hypothetical group sizes — grim_map_total_n","text":"Bauer, P. J., & Francis, G. (2021). Expression Concern: Light Dark? Recalling Moral Behavior Changes Perception Brightness. Psychological Science, 32(12), 2042–2043. https://journals.sagepub.com/doi/10.1177/09567976211058727 Brown, N. J. L., & Heathers, J. . J. (2017). GRIM Test: Simple Technique Detects Numerous Anomalies Reporting Results Psychology. Social Psychological Personality Science, 8(4), 363–369. https://journals.sagepub.com/doi/10.1177/1948550616673876","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_map_total_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GRIM-testing with hypothetical group sizes — grim_map_total_n","text":"","code":"# Run `grim_map_total_n()` on data like these: df <- tibble::tribble(   ~x1,    ~x2,   ~n,   \"3.43\", \"5.28\", 90,   \"2.97\", \"4.42\", 103 ) df #> # A tibble: 2 × 3 #>   x1    x2        n #>   <chr> <chr> <dbl> #> 1 3.43  5.28     90 #> 2 2.97  4.42    103  grim_map_total_n(df) #> # A tibble: 48 × 8 #>    x         n n_change consistency both_consistent ratio  case dir   #>    <chr> <dbl>    <dbl> <lgl>       <lgl>           <dbl> <int> <chr> #>  1 3.43     45        0 FALSE       FALSE            0.55     1 forth #>  2 5.28     45        0 FALSE       FALSE            0.55     1 forth #>  3 3.43     44       -1 TRUE        TRUE             0.56     1 forth #>  4 5.28     46        1 TRUE        TRUE             0.54     1 forth #>  5 3.43     43       -2 FALSE       FALSE            0.57     1 forth #>  6 5.28     47        2 TRUE        FALSE            0.53     1 forth #>  7 3.43     42       -3 TRUE        FALSE            0.58     1 forth #>  8 5.28     48        3 FALSE       FALSE            0.52     1 forth #>  9 3.43     41       -4 FALSE       FALSE            0.59     1 forth #> 10 5.28     49        4 FALSE       FALSE            0.51     1 forth #> # … with 38 more rows  # `audit_total_n()` summaries can be more important than # the detailed results themselves. # The `hits_total` column shows all scenarios in # which both divergent `n` values are GRIM-consistent # with the `x*` values when paired with them both ways: df %>%   grim_map_total_n() %>%   audit_total_n() #> # A tibble: 2 × 8 #>   x1    x2        n hits_total hits_forth hits_back scenarios_total hit_rate #>   <chr> <chr> <dbl>      <dbl>      <dbl>     <dbl>           <dbl>    <dbl> #> 1 3.43  5.28     90          3          2         1              12     0.25 #> 2 2.97  4.42    103          0          0         0              12     0     # By default (`dispersion = 0:5`), the function goes # five steps up and down from `n`. If this sequence # gets longer, the number of hits tends to increase: df %>%   grim_map_total_n(dispersion = 0:10) %>%   audit_total_n() #> # A tibble: 2 × 8 #>   x1    x2        n hits_total hits_forth hits_back scenarios_total hit_rate #>   <chr> <chr> <dbl>      <dbl>      <dbl>     <dbl>           <dbl>    <dbl> #> 1 3.43  5.28     90          6          3         3              22   0.273  #> 2 2.97  4.42    103          2          0         2              22   0.0909"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize GRIM test results — grim_plot","title":"Visualize GRIM test results — grim_plot","text":"grim_plot() visualizes summary data mutual GRIM consistency. Call function data frame resulted call grim_map(). Consistent inconsistent value pairs input data frame shown distinctive colors. default, consistent value pairs blue inconsistent ones red. parameters underlying geoms can controlled via arguments. background raster follows rounding argument grim_map() call (unless plotted mean proportion values 2 decimal places, case gradient shown, raster).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize GRIM test results — grim_plot","text":"","code":"grim_plot(   data = NULL,   show_data = TRUE,   show_raster = TRUE,   show_gradient = TRUE,   n = NULL,   digits = NULL,   rounding = \"up_or_down\",   color_cons = \"royalblue1\",   color_incons = \"red\",   tile_alpha = 1,   tile_size = 1.5,   raster_alpha = 1,   raster_color = \"grey75\" )"},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize GRIM test results — grim_plot","text":"data Data frame. Result call grim_map(). show_data Boolean. set FALSE, test results data displayed. Choose want show background raster. can control plot parameters directly via n, digits, rounding arguments. Default TRUE. show_raster Boolean. TRUE (default), plot background raster. show_gradient Boolean. number decimal places 3 greater, gradient shown signal overall probability GRIM inconsistency? Default TRUE. n Integer. Maximal value x-axis. Default NULL, case n becomes 10 ^ digits (e.g., 100 digits 2). digits Integer. relevant show_data set FALSE. plot constructed data x values many decimal places. Default 2. rounding String. relevant show_data set FALSE. plot constructed data rounded particular way. Default \"up_or_down\". color_cons, color_incons Strings. Fill colors consistent inconsistent scatter points. Defaults \"royalblue1\" (consistent) \"red\" (inconsistent). tile_alpha, tile_size Numeric. parameters scatter points: opacity , indirectly, size. Defaults 1 1.5. raster_alpha, raster_color Numeric string, respectively. Parameters background raster: opacity fill color. Defaults 1 \"grey75\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize GRIM test results — grim_plot","text":"ggplot object.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_plot.html","id":"background-raster","dir":"Reference","previous_headings":"","what":"Background raster","title":"Visualize GRIM test results — grim_plot","text":"background raster shows probability GRIM-inconsistency random means proportions, 0 (inconsistent) greatest number x-axis (consistent). number decimal places inputs -- means percentages -- 3 greater, individual points small display. cases, raster gradient, showing overall trend. raster makes sense respect one specific number decimal places, function throw error numbers differ among input x values (show_raster TRUE). can avoid error force plotting specifying digits number decimal places raster gradient displayed. 1 2 decimal places, raster specific rounding procedure. raster varies rounding procedure, automatically correspond rounding argument specified preceding grim_map() call. works fast raster based data saved package , data need generated anew every time function called. Inconsistent value sets marked dark boxes. places raster denote consistent value sets. raster independent data -- follows rounding specification grim_map() call digits argument grim_plot(). Display \"empty\" plot, one without empirical test results, setting show_data FALSE. can control key parameters plot digits rounding. grim_map()'s default rounding, \"up_or_down\", strikingly values flagged inconsistent sample sizes 40 80 (4 8). effect disappears rounding set value. list values rounding can take, see documentation grim(), section Rounding. 4/8 leniency effect arises accepting values rounded either careful conservative rounding procedure. case, grim_plot() cause effect --- reveals .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_plot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Visualize GRIM test results — grim_plot","text":"Brown, N. J. L., & Heathers, J. . J. (2017). GRIM Test: Simple Technique Detects Numerous Anomalies Reporting Results Psychology. Social Psychological Personality Science, 8(4), 363–369. https://journals.sagepub.com/doi/10.1177/1948550616673876","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grim_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize GRIM test results — grim_plot","text":"","code":"# Call `grim_plot()` following `grim_map()`: pigs1 %>%   grim_map() %>%   grim_plot()   # If you change the rounding procedure # in `grim_map()`, the plot will # follow automatically if there is # a difference: pigs1 %>%   grim_map(rounding = \"ceiling\") %>%   grim_plot()   # For percentages, the y-axis # label also changes automatically: pigs2 %>%   grim_map(percent = TRUE) %>%   grim_plot() #> ℹ `x` converted from percentage"},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer.html","id":null,"dir":"Reference","previous_headings":"","what":"The GRIMMER test (granularity-related inconsistency of means mapped to error\nrepeats) — grimmer","title":"The GRIMMER test (granularity-related inconsistency of means mapped to error\nrepeats) — grimmer","text":"grimmer() checks reported mean SD values integer data mathematically consistent reported sample size number items compose mean value. works much like grim(). function vectorized, recommended use grimmer_map() testing multiple cases.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The GRIMMER test (granularity-related inconsistency of means mapped to error\nrepeats) — grimmer","text":"","code":"grimmer(   x,   sd,   n,   items = 1,   show_reason = FALSE,   rounding = \"up_or_down\",   threshold = 5,   symmetric = FALSE,   tolerance = .Machine$double.eps^0.5 )"},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The GRIMMER test (granularity-related inconsistency of means mapped to error\nrepeats) — grimmer","text":"x String. reported mean value. sd String. reported standard deviation. n Integer. reported sample size. items (NOTE: use items argument. currently contains bug fixed scrutiny's next CRAN release.) Integer. number items composing x sd values. Default 1, common case. show_reason Boolean. internal use . set TRUE, output list length-2 lists also contain reasons inconsistencies. specify manually; instead, use show_reason grimmer_map(). Default FALSE. rounding String. Rounding method methods used reconstructing values x compared. Default \"up_or_down\" (5). threshold Numeric. rounding set \"up_from\", \"down_from\", \"up_from_or_down_from\", set threshold number reconstructed values rounded . Otherwise, argument plays role. Default 5. symmetric Boolean. Set symmetric TRUE rounding negative numbers \"\", \"\", \"up_from\", \"down_from\" mirror positive numbers absolute values always equal. Default FALSE. tolerance Numeric. Tolerance comparison x possible mean percentage values. Default circa 0.000000015 (1.490116e-08), dplyr::near().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The GRIMMER test (granularity-related inconsistency of means mapped to error\nrepeats) — grimmer","text":"Boolean. TRUE x, sd, n, items mutually consistent, FALSE .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The GRIMMER test (granularity-related inconsistency of means mapped to error\nrepeats) — grimmer","text":"GRIMMER originally devised Anaya (2016). present implementation follows Allard's (2018) refined Analytic-GRIMMER (-GRIMMER) algorithm. adapts R function aGrimmer() provided Allard modifies accord scrutiny's standards, laid vignette(\"consistency-tests\"), sections 1-2. resulting grimmer() function, , vectorized version basic implementation. context variable name translations, see top R/grimmer.R, source file. present implementation can differ Allard's small number cases. cases, means original flags value set inconsistent, scrutiny's grimmer*() functions . details, see end tests/testthat/test-grimmer.R, grimmer() test file.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The GRIMMER test (granularity-related inconsistency of means mapped to error\nrepeats) — grimmer","text":"Allard, . (2018). Analytic-GRIMMER: new way testing possibility standard deviations. https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/ Anaya, J. (2016). GRIMMER test: method testing validity reported measures variability. PeerJ Preprints. https://peerj.com/preprints/2400v1/","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The GRIMMER test (granularity-related inconsistency of means mapped to error\nrepeats) — grimmer","text":"","code":"# A mean of 5.23 is not consistent with an SD of 2.55 # and a sample size of 35: grimmer(x = \"5.23\", sd = \"2.55\", n = 35) #>  5.23  #> FALSE   # However, mean and SD are consistent with a # sample size of 31: grimmer(x = \"5.23\", sd = \"2.55\", n = 31) #> 5.23  #> TRUE   # For a scale composed of two items: grimmer(x = \"2.74\", sd = \"0.96\", n = 63, items = 2) #> 2.74  #> TRUE"},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map.html","id":null,"dir":"Reference","previous_headings":"","what":"GRIMMER-test many cases at once — grimmer_map","title":"GRIMMER-test many cases at once — grimmer_map","text":"Call grimmer_map() GRIMMER-test number combinations mean, standard deviation, sample size, number items. Mapping function GRIMMER-testing. summary statistics, call audit() results. Visualize results using grim_plot(), GRIM results.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GRIMMER-test many cases at once — grimmer_map","text":"","code":"grimmer_map(   data,   items = 1,   merge_items = TRUE,   x = NULL,   sd = NULL,   n = NULL,   show_reason = TRUE,   rounding = \"up_or_down\",   threshold = 5,   symmetric = FALSE,   tolerance = .Machine$double.eps^0.5 )"},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GRIMMER-test many cases at once — grimmer_map","text":"data Data frame columns x, sd, n, optionally items (see documentation grim()). columns data returned alongside GRIMMER test results. items (NOTE: use items argument. currently contains bug fixed scrutiny's next CRAN release.) Integer. items column data, specifies number items composing x sd values. Default 1, common case. merge_items Boolean. TRUE (default), items column output. Instead, values items column argument multiplied values n column. affect GRIM- GRIMMER-testing. x, sd, n Optionally, specify arguments column names data. show_reason Boolean (length 1). reason column shows reasons inconsistencies (NA consistent values)? Default FALSE. rounding, threshold, symmetric, tolerance parameters GRIMMER-testing; see documentation grimmer().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GRIMMER-test many cases at once — grimmer_map","text":"tibble columns -- x, sd, n: inputs. consistency: GRIMMER consistency x, n, items. <extra>: columns data x, n, items. tibble scr_grimmer_map class, recognized audit() generic. also scr_grim_map class, can visualized grim_plot().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map.html","id":"summaries-with-audit-","dir":"Reference","previous_headings":"","what":"Summaries with audit()","title":"GRIMMER-test many cases at once — grimmer_map","text":"S3 method audit(), can call audit() following grimmer_map() get summary grimmer_map()'s results. tibble single row columns -- incons_cases: number GRIMMER-inconsistent value sets. all_cases: total number value sets. incons_rate: proportion GRIMMER-inconsistent value sets. fail_grim: number value sets fail GRIM test. fail_test1: number value sets fail first GRIMMER test (sum squares whole number) fail_test2: number value sets fail second GRIMMER test (matching SDs) fail_test3: number value sets fail third GRIMMER test (equal parity)","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"GRIMMER-test many cases at once — grimmer_map","text":"Allard, . (2018). Analytic-GRIMMER: new way testing possibility standard deviations. https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/ Anaya, J. (2016). GRIMMER test: method testing validity reported measures variability. PeerJ Preprints. https://peerj.com/preprints/2400v1/","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GRIMMER-test many cases at once — grimmer_map","text":"","code":"# Use `grimmer_map()` on data like these: pigs5 #> # A tibble: 12 × 3 #>    x     sd        n #>    <chr> <chr> <dbl> #>  1 7.22  5.30     38 #>  2 4.74  6.55     31 #>  3 5.23  2.55     35 #>  4 2.57  2.57     30 #>  5 6.77  2.18     33 #>  6 2.68  2.59     34 #>  7 7.01  6.68     35 #>  8 7.38  3.65     32 #>  9 3.14  5.32     33 #> 10 6.89  4.18     37 #> 11 5.00  2.18     31 #> 12 0.24  6.43     34  # The `consistency` column shows whether # the values to its left are GRIMMER-consistent. # If they aren't, the `reason` column says why: pigs5 %>%   grimmer_map() #> # A tibble: 12 × 5 #>    x     sd        n consistency reason                        #>    <chr> <chr> <dbl> <lgl>       <chr>                         #>  1 7.22  5.30     38 FALSE       GRIM inconsistent             #>  2 4.74  6.55     31 TRUE        Passed all                    #>  3 5.23  2.55     35 FALSE       GRIMMER inconsistent (test 3) #>  4 2.57  2.57     30 FALSE       GRIMMER inconsistent (test 3) #>  5 6.77  2.18     33 FALSE       GRIM inconsistent             #>  6 2.68  2.59     34 TRUE        Passed all                    #>  7 7.01  6.68     35 FALSE       GRIM inconsistent             #>  8 7.38  3.65     32 TRUE        Passed all                    #>  9 3.14  5.32     33 FALSE       GRIM inconsistent             #> 10 6.89  4.18     37 TRUE        Passed all                    #> 11 5.00  2.18     31 TRUE        Passed all                    #> 12 0.24  6.43     34 TRUE        Passed all                     # Get summaries with `audit()`: pigs5 %>%   grimmer_map() %>%   audit() #> # A tibble: 1 × 7 #>   incons_cases all_cases incons_rate fail_grim fail_test1 fail_test2 fail_test3 #>          <int>     <int>       <dbl>     <int>      <int>      <int>      <int> #> 1            6        12         0.5         4          0          0          2"},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"GRIMMER-testing with dispersed inputs — grimmer_map_seq","title":"GRIMMER-testing with dispersed inputs — grimmer_map_seq","text":"grimmer_map_seq() performs GRIMMER-testing values surrounding input values. provides easy powerful way assess whether small errors computing reporting may responsible GRIMMER-inconsistencies published statistics. Call audit_seq() results summary statistics.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GRIMMER-testing with dispersed inputs — grimmer_map_seq","text":"","code":"grimmer_map_seq(   data,   x = NULL,   sd = NULL,   n = NULL,   var = .var,   dispersion = .dispersion,   out_min = .out_min,   out_max = .out_max,   include_reported = .include_reported,   include_consistent = .include_consistent,   ... )"},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GRIMMER-testing with dispersed inputs — grimmer_map_seq","text":"data data frame grimmer_map() take. x, sd, n Optionally, specify arguments column names data. var String. Names columns dispersed. Default c(\"x\", \"sd\", \"n\"). dispersion Numeric. Sequence steps var inputs. adjusted values' decimal levels. example, reported 8.34, step size 0.01. Default 1:5, five steps . out_min, out_max specified, output restricted out_min out_max. Defaults \"auto\" out_min, .e., minimum one decimal unit zero; NULL out_max, .e., maximum. include_reported Boolean. reported values included sequences originating ? Default FALSE might redundant bias results. include_consistent Boolean. function also process consistent cases (among reported), just inconsistent ones? Default FALSE focus clarifying inconsistencies. ... Arguments passed grimmer_map(). (NOTE: use items argument. currently contains bug fixed scrutiny's next CRAN release.)","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GRIMMER-testing with dispersed inputs — grimmer_map_seq","text":"tibble (data frame) detailed test results.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_seq.html","id":"summaries-with-audit-seq-","dir":"Reference","previous_headings":"","what":"Summaries with audit_seq()","title":"GRIMMER-testing with dispersed inputs — grimmer_map_seq","text":"can call audit_seq() following grimmer_map_seq(). return data frame columns: x, sd, n original inputs, tested consistency . hits_total total number GRIMMER-consistent value sets found within specified dispersion range. hits_x number GRIMMER-consistent value sets found varying x. Accordingly sd hits_sd well n hits_n. (Note consistent reported cases counted hits_* columns include_reported include_consistent set TRUE.) diff_x reports absolute difference x next consistent dispersed value (dispersion steps, actual numeric difference). diff_x_up diff_x_down report difference next higher lower consistent value, respectively. diff_sd, diff_sd_up, diff_sd_down sd. Likewise diff_n, diff_n_up, diff_n_down.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GRIMMER-testing with dispersed inputs — grimmer_map_seq","text":"","code":"# `grimmer_map_seq()` can take any input # that `grimmer_map()` can take: pigs5 #> # A tibble: 12 × 3 #>    x     sd        n #>    <chr> <chr> <dbl> #>  1 7.22  5.30     38 #>  2 4.74  6.55     31 #>  3 5.23  2.55     35 #>  4 2.57  2.57     30 #>  5 6.77  2.18     33 #>  6 2.68  2.59     34 #>  7 7.01  6.68     35 #>  8 7.38  3.65     32 #>  9 3.14  5.32     33 #> 10 6.89  4.18     37 #> 11 5.00  2.18     31 #> 12 0.24  6.43     34  # All the results: out <- grimmer_map_seq(pigs5, include_consistent = TRUE) out #> # A tibble: 360 × 7 #>    x     sd        n consistency reason             case var   #>    <chr> <chr> <dbl> <lgl>       <chr>             <int> <chr> #>  1 7.17  5.30     38 FALSE       GRIM inconsistent     1 x     #>  2 7.18  5.30     38 TRUE        Passed all            1 x     #>  3 7.19  5.30     38 FALSE       GRIM inconsistent     1 x     #>  4 7.20  5.30     38 FALSE       GRIM inconsistent     1 x     #>  5 7.21  5.30     38 TRUE        Passed all            1 x     #>  6 7.23  5.30     38 FALSE       GRIM inconsistent     1 x     #>  7 7.24  5.30     38 TRUE        Passed all            1 x     #>  8 7.25  5.30     38 FALSE       GRIM inconsistent     1 x     #>  9 7.26  5.30     38 TRUE        Passed all            1 x     #> 10 7.27  5.30     38 FALSE       GRIM inconsistent     1 x     #> # … with 350 more rows  # Case-wise summaries with `audit_seq()` # can be more important than the raw results: out %>%   audit_seq() #> # A tibble: 12 × 17 #>    x     sd        n consistency hits_total hits_x hits_sd hits_n diff_x diff_…¹ #>    <chr> <chr> <dbl> <lgl>            <int>  <int>   <int>  <int>  <dbl>   <dbl> #>  1 7.22  5.30     38 FALSE                8      4       0      4      1       2 #>  2 4.74  6.55     31 TRUE                15      2      10      3      3       3 #>  3 5.23  2.55     35 FALSE               16      2      10      4      3       3 #>  4 2.57  2.57     30 FALSE               11      1       8      2      3       3 #>  5 6.77  2.18     33 FALSE                6      4       0      2      1       2 #>  6 2.68  2.59     34 TRUE                12      2       8      2      3       3 #>  7 7.01  6.68     35 FALSE                4      4       0      0      1       2 #>  8 7.38  3.65     32 TRUE                16      3      10      3      1       3 #>  9 3.14  5.32     33 FALSE                9      4       0      5      1       1 #> 10 6.89  4.18     37 TRUE                16      3      10      3      3       3 #> 11 5.00  2.18     31 TRUE                18      2       6     10      3       3 #> 12 0.24  6.43     34 TRUE                17      3      10      4      2       2 #> # … with 7 more variables: diff_x_down <dbl>, diff_sd <dbl>, diff_sd_up <dbl>, #> #   diff_sd_down <dbl>, diff_n <dbl>, diff_n_up <dbl>, diff_n_down <dbl>, and #> #   abbreviated variable name ¹​diff_x_up"},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_total_n.html","id":null,"dir":"Reference","previous_headings":"","what":"GRIMMER-testing with hypothetical group sizes — grimmer_map_total_n","title":"GRIMMER-testing with hypothetical group sizes — grimmer_map_total_n","text":"reporting group means, published studies report total sample size group sizes corresponding mean. However, group sizes crucial GRIMMER-testing. two-groups case, grimmer_map_total_n() helps ways: creates hypothetical group sizes. even total sample size, incrementally moves half total sample size. example, total sample size 40, starts 20, goes 19 21, 18 22, etc. odd sample sizes, starts two integers around half. GRIMMER-tests values together group means. reports scenarios \"dispersed\" hypothetical group sizes GRIMMER-consistent group means. works one total sample sizes time. Call audit_total_n() summary statistics.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_total_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GRIMMER-testing with hypothetical group sizes — grimmer_map_total_n","text":"","code":"grimmer_map_total_n(   data,   x1 = NULL,   x2 = NULL,   sd1 = NULL,   sd2 = NULL,   dispersion = .dispersion,   n_min = .n_min,   n_max = .n_max,   constant = .constant,   constant_index = .constant_index,   ... )"},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_total_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GRIMMER-testing with hypothetical group sizes — grimmer_map_total_n","text":"data Data frame string columns x1, x2, sd1, sd2, well numeric column n. first two reported group means. sd1 sd2 reported group SDs. n reported total sample size. important whether value x1 x2 , first round tests, function switches roles x1 x2, reports outcomes ways. applies sd1 sd2. However, make sure x* sd* values paired accurately, reported. x1, x2, sd1, sd2 Optionally, specify arguments column names data. dispersion Numeric. Steps half n values. Default 0:5, .e., half n followed five steps . n_min Numeric. Minimal group size. Default 1. n_max Numeric. Maximal group size. Default NULL, .e., maximum. constant Optionally, add length-2 vector list length-2 vectors (data frame exactly two rows) accompany pairs dispersed values. Default NULL, .e., constant values. constant_index Integer (length 1). Index constant first constant column output tibble. NULL (default), constant go right n_change. ... Arguments passed grimmer_map(). (NOTE: use items argument. currently contains bug fixed scrutiny's next CRAN release.)","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_total_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GRIMMER-testing with hypothetical group sizes — grimmer_map_total_n","text":"tibble columns: x, group-wise reported input statistic, repeated row pairs. n dispersed half input n, n_change tracking differences. both_consistent flags scenarios reported x values consistent hypothetical n values. case corresponds row numbers input data frame. dir \"forth\" first half rows \"back\" second half. \"forth\" means x2 input paired larger dispersed n, whereas \"back\" means x1 paired larger dispersed n. columns grimmer_map() preserved","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_total_n.html","id":"summaries-with-audit-total-n-","dir":"Reference","previous_headings":"","what":"Summaries with audit_total_n()","title":"GRIMMER-testing with hypothetical group sizes — grimmer_map_total_n","text":"can call audit_total_n() following grimmer_map_total_n() get tibble summary statistics. columns: x1, x2, sd1, sd2, n original inputs. hits_total number scenarios x1, x2, sd1, sd2 GRIMMER-consistent. sum hits_forth hits_back . hits_forth number -consistent cases result pairing x2 sd2 larger dispersed n value. hits_back , except x1 sd1 paired larger dispersed n value. scenarios_total total number test scenarios, whether x1 sd1 well x2 sd2 GRIMMER-consistent. hit_rate ratio hits_total scenarios_total.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_total_n.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"GRIMMER-testing with hypothetical group sizes — grimmer_map_total_n","text":"Bauer, P. J., & Francis, G. (2021). Expression Concern: Light Dark? Recalling Moral Behavior Changes Perception Brightness. Psychological Science, 32(12), 2042–2043. https://journals.sagepub.com/doi/10.1177/09567976211058727 Allard, . (2018). Analytic-GRIMMER: new way testing possibility standard deviations. https://aurelienallard.netlify.app/post/anaytic-grimmer-possibility-standard-deviations/ Bauer, P. J., & Francis, G. (2021). Expression Concern: Light Dark? Recalling Moral Behavior Changes Perception Brightness. Psychological Science, 32(12), 2042–2043. https://journals.sagepub.com/doi/10.1177/09567976211058727","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/grimmer_map_total_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GRIMMER-testing with hypothetical group sizes — grimmer_map_total_n","text":"","code":"# Run `grimmer_map_total_n()` on data like these: df <- tibble::tribble(   ~x1,    ~x2,    ~sd1,   ~sd2,   ~n,   \"3.43\", \"5.28\", \"1.09\", \"2.12\", 70,   \"2.97\", \"4.42\", \"0.43\", \"1.65\", 65 ) df #> # A tibble: 2 × 5 #>   x1    x2    sd1   sd2       n #>   <chr> <chr> <chr> <chr> <dbl> #> 1 3.43  5.28  1.09  2.12     70 #> 2 2.97  4.42  0.43  1.65     65  grimmer_map_total_n(df) #> # A tibble: 48 × 9 #>    x     sd        n n_change consistency both_consistent reason      case dir   #>    <chr> <chr> <dbl>    <dbl> <lgl>       <lgl>           <chr>      <int> <chr> #>  1 3.43  1.09     35        0 FALSE       FALSE           GRIMMER i…     1 forth #>  2 5.28  2.12     35        0 FALSE       FALSE           GRIM inco…     1 forth #>  3 3.43  1.09     34       -1 FALSE       FALSE           GRIM inco…     1 forth #>  4 5.28  2.12     36        1 FALSE       FALSE           GRIMMER i…     1 forth #>  5 3.43  1.09     33       -2 FALSE       FALSE           GRIM inco…     1 forth #>  6 5.28  2.12     37        2 FALSE       FALSE           GRIM inco…     1 forth #>  7 3.43  1.09     32       -3 FALSE       FALSE           GRIM inco…     1 forth #>  8 5.28  2.12     38        3 FALSE       FALSE           GRIM inco…     1 forth #>  9 3.43  1.09     31       -4 FALSE       FALSE           GRIM inco…     1 forth #> 10 5.28  2.12     39        4 FALSE       FALSE           GRIMMER i…     1 forth #> # … with 38 more rows  # `audit_total_n()` summaries can be more important than # the detailed results themselves. # The `hits_total` column shows all scenarios in # which both divergent `n` values are GRIMMER-consistent # with the `x*` values when paired with them both ways: df %>%   grimmer_map_total_n() %>%   audit_total_n() #> # A tibble: 2 × 10 #>   x1    x2    sd1   sd2       n hits_total hits_forth hits_back scenar…¹ hit_r…² #>   <chr> <chr> <chr> <chr> <dbl>      <dbl>      <dbl>     <dbl>    <dbl>   <dbl> #> 1 3.43  5.28  1.09  2.12     70          1          1         0       12  0.0833 #> 2 2.97  4.42  0.43  1.65     65          1          0         1       12  0.0833 #> # … with abbreviated variable names ¹​scenarios_total, ²​hit_rate  # By default (`dispersion = 0:5`), the function goes # five steps up and down from `n`. If this sequence # gets longer, the number of hits tends to increase: df %>%   grimmer_map_total_n(dispersion = 0:10) %>%   audit_total_n() #> # A tibble: 2 × 10 #>   x1    x2    sd1   sd2       n hits_total hits_forth hits_back scenar…¹ hit_r…² #>   <chr> <chr> <chr> <chr> <dbl>      <dbl>      <dbl>     <dbl>    <dbl>   <dbl> #> 1 3.43  5.28  1.09  2.12     70          1          1         0       22  0.0455 #> 2 2.97  4.42  0.43  1.65     65          1          0         1       22  0.0455 #> # … with abbreviated variable names ¹​scenarios_total, ²​hit_rate"},{"path":"https://lhdjung.github.io/scrutiny/reference/is_numeric_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether a vector is numeric or coercible to numeric — is_numeric_like","title":"Test whether a vector is numeric or coercible to numeric — is_numeric_like","text":"is_numeric_like() tests whether object \"coercible numeric\" particular standards scrutiny. means: Integer double vectors TRUE. Booleans FALSE, non-vector objects. vectors (likely strings) TRUE non-NA values can coerced non-NA numeric values, FALSE otherwise. Factors first coerced string, tested. Lists tested like atomic vectors unless elements length greater 1, case always FALSE. values non-numeric, non-Boolean NA, output also NA. See details discussion.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/is_numeric_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether a vector is numeric or coercible to numeric — is_numeric_like","text":"","code":"is_numeric_like(x)"},{"path":"https://lhdjung.github.io/scrutiny/reference/is_numeric_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether a vector is numeric or coercible to numeric — is_numeric_like","text":"x Object tested.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/is_numeric_like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test whether a vector is numeric or coercible to numeric — is_numeric_like","text":"Boolean (length 1).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/is_numeric_like.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test whether a vector is numeric or coercible to numeric — is_numeric_like","text":"scrutiny package often deals \"number-strings\", .e., strings can coerced numeric without introducing new NAs. matter displaying data certain way, opposed storage mode. is_numeric_like() returns FALSE Booleans simply displayed words, numbers, usual coercion rules misleading context. Likewise, function treats factors like strings displayed: fact factors stored integers irrelevant. store numbers strings factors? data types can preserve trailing zeros, data originally entered strings. See vignette(\"wrangling\"), section Trailing zeros.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/is_numeric_like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether a vector is numeric or coercible to numeric — is_numeric_like","text":"","code":"# Numeric vectors are `TRUE`: is_numeric_like(x = 1:5) #> [1] TRUE is_numeric_like(x = 2.47) #> [1] TRUE  # Booleans are always `FALSE`: is_numeric_like(x = c(TRUE, FALSE)) #> [1] FALSE  # Strings are `TRUE` if all of their non-`NA` # values can be coerced to non-`NA` numbers, # and `FALSE` otherwise: is_numeric_like(x = c(\"42\", \"0.7\", NA)) #> [1] TRUE is_numeric_like(x = c(\"42\", \"xyz\", NA)) #> [1] FALSE  # Factors are treated like their # string equivalents: is_numeric_like(x = as.factor(c(\"42\", \"0.7\", NA))) #> [1] TRUE is_numeric_like(x = as.factor(c(\"42\", \"0.7\", NA))) #> [1] TRUE  # Lists behave like atomic vectors if all of their # elements have length 1... is_numeric_like(x = list(\"42\", \"0.7\", NA)) #> [1] TRUE is_numeric_like(x = list(\"42\", \"xyz\", NA)) #> [1] FALSE  # ...but if they don't, they are `FALSE`: is_numeric_like(x = list(\"42\", \"0.7\", NA, c(1, 2, 3))) #> [1] FALSE  # If all values are `NA`, so is the output... is_numeric_like(x = as.character(c(NA, NA, NA))) #> [1] NA  # ...unless the `NA`s are numeric or Boolean: is_numeric_like(x = as.numeric(c(NA, NA, NA))) #> [1] TRUE is_numeric_like(x = c(NA, NA, NA)) #> [1] FALSE"},{"path":"https://lhdjung.github.io/scrutiny/reference/manage_helper_col.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper column operations — manage_helper_col","title":"Helper column operations — manage_helper_col","text":"consistency test mapper function supports helper columns, call manage_helper_col() internally; every column. check whether helper column compatible eponymous argument, .e., argument specified user default value. default (affix = TRUE), function add column mapper's input data frame. returns input data frame, reassign output variable. works mapper functions \"handwritten\" using function(), opposed produced function_map(). See vignette(\"consistency-tests\"), section Writing mappers manually.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/manage_helper_col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper column operations — manage_helper_col","text":"","code":"manage_helper_col(data, var_arg, default, affix = TRUE)"},{"path":"https://lhdjung.github.io/scrutiny/reference/manage_helper_col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper column operations — manage_helper_col","text":"data data frame mapper function's first argument. var_arg argument mapper function name helper column want manage. default default argument specified var_arg. affix Boolean (length 1). data include helper column already, var_arg added data, bearing proper name? Default TRUE.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/manage_helper_col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper column operations — manage_helper_col","text":"input data frame,  data, possibly modified (see affix argument).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/manage_key_colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Enable name-independent key column identification — manage_key_colnames","title":"Enable name-independent key column identification — manage_key_colnames","text":"handwritten mapper function consistency tests, grim_map(), may include arguments named key columns input data frame. argument specified user column name input data frame, identifies differently-named column key column. Create functionality three steps: Add arguments mapper function named respective key columns. NULL default; e.g., x = NULL, n = NULL. Within mapper, capture user input quoting using rlang::enexpr(). Reassign values argument variables; e.g., x <- rlang::enexpr(x) n <- rlang::enexpr(n). every argument, call manage_key_colnames() reassign value input data frame variable, adding short description; e.g.,data <- manage_key_colnames(data, x, \"mean/proportion\") data <-   manage_key_colnames(data, n, \"sample size\").","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/manage_key_colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enable name-independent key column identification — manage_key_colnames","text":"","code":"manage_key_colnames(data, arg, description = NULL)"},{"path":"https://lhdjung.github.io/scrutiny/reference/manage_key_colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enable name-independent key column identification — manage_key_colnames","text":"data mapper function's input data frame. arg Symbol. quoted input variable, captured rlang::enexpr(). description String (length 1). Short description column question, inserted error message.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/manage_key_colnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enable name-independent key column identification — manage_key_colnames","text":"input data frame, data, possibly modified.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/parens-extractors.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract substrings from before and inside parentheses — parens-extractors","title":"Extract substrings from before and inside parentheses — parens-extractors","text":"Two functions extract substrings inside parentheses, similar separators like brackets curly braces: before_parens() inside_parens(). See split_by_parens() split columns data frame parts.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/parens-extractors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract substrings from before and inside parentheses — parens-extractors","text":"","code":"before_parens(string, sep = \"parens\")  inside_parens(string, sep = \"parens\")"},{"path":"https://lhdjung.github.io/scrutiny/reference/parens-extractors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract substrings from before and inside parentheses — parens-extractors","text":"string Vector strings parentheses similar. sep String. split . Either \"parens\", \"brackets\", \"braces\", length-2 vector custom separators. See examples split_by_parens(). Default \"parens\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/parens-extractors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract substrings from before and inside parentheses — parens-extractors","text":"String vector length string. part string inside sep, respectively.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/parens-extractors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract substrings from before and inside parentheses — parens-extractors","text":"","code":"x <- c(   \"3.72 (0.95)\",   \"5.86 (2.75)\",   \"3.06 (6.48)\" )  before_parens(string = x) #> [1] \"3.72\" \"5.86\" \"3.06\"  inside_parens(string = x) #> [1] \"0.95\" \"2.75\" \"6.48\""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs1.html","id":null,"dir":"Reference","previous_headings":"","what":"Means and sample sizes for GRIM-testing — pigs1","title":"Means and sample sizes for GRIM-testing — pigs1","text":"fictional dataset means sample sizes flying pigs. can used demonstrate functionality grim_map() functions building .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Means and sample sizes for GRIM-testing — pigs1","text":"","code":"pigs1"},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Means and sample sizes for GRIM-testing — pigs1","text":"tibble (data frame) 12 rows 2 columns. columns : x String. Means. n Numeric. Sample sizes.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Means and sample sizes for GRIM-testing — pigs1","text":"tibble (data frame).","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs2.html","id":null,"dir":"Reference","previous_headings":"","what":"Percentages and sample sizes for GRIM-testing — pigs2","title":"Percentages and sample sizes for GRIM-testing — pigs2","text":"fictional dataset percentages sample sizes flying pigs. can used demonstrate functionality grim_map(), particularly percent argument, functions building .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Percentages and sample sizes for GRIM-testing — pigs2","text":"","code":"pigs2"},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Percentages and sample sizes for GRIM-testing — pigs2","text":"tibble (data frame) 6 rows 2 columns. columns : x String. Percentages. n Numeric. Sample sizes.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Percentages and sample sizes for GRIM-testing — pigs2","text":"tibble (data frame).","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs3.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary means and standard deviations for using DEBIT — pigs3","title":"Binary means and standard deviations for using DEBIT — pigs3","text":"fictional dataset means standard deviations binary distribution related flying pigs. can used demonstrate functionality debit_map() functions building .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary means and standard deviations for using DEBIT — pigs3","text":"","code":"pigs3"},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs3.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Binary means and standard deviations for using DEBIT — pigs3","text":"tibble (data frame) 7 rows 3 columns. columns : x String. Means. sd String. Standard deviations. n Numeric. Sample sizes.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binary means and standard deviations for using DEBIT — pigs3","text":"tibble (data frame).","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs4.html","id":null,"dir":"Reference","previous_headings":"","what":"Data with duplications — pigs4","title":"Data with duplications — pigs4","text":"fictional dataset observations flying pigs. Two pairs values duplicates. dataset can used demonstrate functionality duplicate_detect() functions building .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data with duplications — pigs4","text":"","code":"pigs4"},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs4.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data with duplications — pigs4","text":"tibble (data frame) 7 rows 3 columns. columns : x String. Means. sd String. Standard deviations. n Numeric. Sample sizes.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs4.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data with duplications — pigs4","text":"tibble (data frame).","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs5.html","id":null,"dir":"Reference","previous_headings":"","what":"Means, SDs, and sample sizes for GRIMMER-testing — pigs5","title":"Means, SDs, and sample sizes for GRIMMER-testing — pigs5","text":"fictional dataset means, standard deviations (SDs), sample sizes flying pigs. can used demonstrate functionality grimmer_map() functions building .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Means, SDs, and sample sizes for GRIMMER-testing — pigs5","text":"","code":"pigs5"},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs5.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Means, SDs, and sample sizes for GRIMMER-testing — pigs5","text":"tibble (data frame) 12 rows 3 columns. columns : x String. Means. sd String. Standard deviations. n Numeric. Sample sizes.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pigs5.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Means, SDs, and sample sizes for GRIMMER-testing — pigs5","text":"tibble (data frame).","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"pipe, %>%, imported magrittr reexported scrutiny users. See magrittr::%>% details.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://lhdjung.github.io/scrutiny/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reround.html","id":null,"dir":"Reference","previous_headings":"","what":"General interface to reconstructing rounded numbers — reround","title":"General interface to reconstructing rounded numbers — reround","text":"reround() takes one intermediate reconstructed values rounds specific way -- namely, way supposed rounded originally, process generated reported values. function provides interface scrutiny's rounding functions well base::round(). used helper within grim() debit(), might find use places consistency testing reconstruction statistical analyses.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reround.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General interface to reconstructing rounded numbers — reround","text":"","code":"reround(   x,   digits = 0L,   rounding = \"up_or_down\",   threshold = 5,   symmetric = FALSE )"},{"path":"https://lhdjung.github.io/scrutiny/reference/reround.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General interface to reconstructing rounded numbers — reround","text":"x Numeric. Vector possibly original values. digits Integer. Number decimal places reported key values (.e., mean percentage within grim(), standard deviation within debit()). rounding String. rounding method supposed used originally. See documentation grim(), section Rounding. Default \"up_or_down\", returns two values: x rounded . threshold Integer. rounding set \"up_from\", \"down_from\", \"up_from_or_down_from\", threshold must set number reconstructed values rounded . Otherwise irrelevant. Default 5. symmetric Boolean. Set symmetric TRUE rounding negative numbers \"up_or_down\", \"\", \"\", \"up_from_or_down_from\", \"up_from\", \"down_from\" mirror positive numbers absolute values always equal. Otherwise irrelevant. Default FALSE.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reround.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General interface to reconstructing rounded numbers — reround","text":"Numeric vector length 1 2. (length 1 unless rounding \"up_or_down\", \"up_from_or_down_from\", \"ceiling_or_floor\", case length 2.)","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reround.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"General interface to reconstructing rounded numbers — reround","text":"reround() internally calls appropriate rounding function(s) determined rounding argument. See documentation grim(), section Rounding, complete list values rounding can take. nine rounding functions , see documentation round_up(), round_ceiling(), base::round().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/restore_zeros.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore trailing zeros — restore_zeros","title":"Restore trailing zeros — restore_zeros","text":"restore_zeros() takes vector values might lost trailing zeros, likely registered numeric. turns value string adds trailing zeros mantissa hits limit. default limit number digits longest mantissa vector's values. length integer part plays role. rely default limit without checking: original width larger longest extant mantissa might lost trailing zeros. restore_zeros_df() variant data frames. wraps restore_zeros() , default, applies columns coercible numeric.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/restore_zeros.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore trailing zeros — restore_zeros","text":"","code":"restore_zeros(x, width = NULL, sep_in = \"\\\\.\", sep_out = sep_in, sep = NULL)  restore_zeros_df(   data,   cols = everything(),   check_numeric_like = TRUE,   check_decimals = FALSE,   width = NULL,   sep_in = \"\\\\.\",   sep_out = NULL,   sep = NULL,   ... )"},{"path":"https://lhdjung.github.io/scrutiny/reference/restore_zeros.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore trailing zeros — restore_zeros","text":"x Numeric (string coercible numeric). Vector numbers might lost trailing zeros. width Integer. Number decimal places mantissas , including restored zeros. Default NULL, case number characters longest mantissa used instead. sep_in Substring separates input's mantissa integer part. Default \"\\\\.\", renders decimal point. sep_out Substring returned output separate mantissa integer part. default, sep_out sep_in. sep [Deprecated] Use sep_in, sep. sep specified nonetheless, sep_in takes sep's value. data Data frame matrix. restore_zeros_df(), instead x. cols restore_zeros_df(). Select columns data using tidyselect. Default everything(), selects columns pass test check_numeric_like. check_numeric_like Boolean. restore_zeros_df(). TRUE (default), function skip columns numeric coercible numeric, determined is_numeric_like(). check_decimals Boolean. restore_zeros_df(). set TRUE, function skip columns values decimal places. Default FALSE. ... restore_zeros_df(). dots must empty.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/restore_zeros.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restore trailing zeros — restore_zeros","text":"restore_zeros(), string vector. least strings newly restored zeros, unless (1) input values number decimal places, (2) width specified number greater single number decimal places. restore_zeros_df(), data frame.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/restore_zeros.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restore trailing zeros — restore_zeros","text":"functions exploit fact groups summary values means percentages often reported number decimal places. number known values entered strings, trailing zeros lost. case, restore_zeros() restore_zeros_df() helpful prepare data consistency testing functions grim_map() grimmer_map().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/restore_zeros.html","id":"displaying-decimal-places","dir":"Reference","previous_headings":"","what":"Displaying decimal places","title":"Restore trailing zeros — restore_zeros","text":"might see decimal places numeric values vector, consequently wonder restore_zeros(), applied vector, adds many zeros. displayed numbers, unlike stored numbers, often rounded. vector x, can count characters longest mantissa among values like : x %>% decimal_places() %>% max()","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/restore_zeros.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restore trailing zeros — restore_zeros","text":"","code":"# By default, the target width is that of # the longest mantissa: vec <- c(212, 75.38, 4.9625) vec %>%   restore_zeros() #> [1] \"212.0000\" \"75.3800\"  \"4.9625\"    # Alternatively, supply a number via `width`: vec %>%   restore_zeros(width = 6) #> [1] \"212.000000\" \"75.380000\"  \"4.962500\"    # For better printing: iris <- tibble::as_tibble(iris)  # Apply `restore_zeros()` to all numeric # columns, but not to the factor column: iris %>%   restore_zeros_df() #> # A tibble: 150 × 5 #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>    <chr>        <chr>       <chr>        <chr>       <fct>   #>  1 5.1          3.5         1.4          0.2         setosa  #>  2 4.9          3.0         1.4          0.2         setosa  #>  3 4.7          3.2         1.3          0.2         setosa  #>  4 4.6          3.1         1.5          0.2         setosa  #>  5 5.0          3.6         1.4          0.2         setosa  #>  6 5.4          3.9         1.7          0.4         setosa  #>  7 4.6          3.4         1.4          0.3         setosa  #>  8 5.0          3.4         1.5          0.2         setosa  #>  9 4.4          2.9         1.4          0.2         setosa  #> 10 4.9          3.1         1.5          0.1         setosa  #> # … with 140 more rows  # Select columns as in `dplyr::select()`: iris %>%   restore_zeros_df(starts_with(\"Sepal\"), width = 3) #> # A tibble: 150 × 5 #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>    <chr>        <chr>              <dbl>       <dbl> <fct>   #>  1 5.100        3.500                1.4         0.2 setosa  #>  2 4.900        3.000                1.4         0.2 setosa  #>  3 4.700        3.200                1.3         0.2 setosa  #>  4 4.600        3.100                1.5         0.2 setosa  #>  5 5.000        3.600                1.4         0.2 setosa  #>  6 5.400        3.900                1.7         0.4 setosa  #>  7 4.600        3.400                1.4         0.3 setosa  #>  8 5.000        3.400                1.5         0.2 setosa  #>  9 4.400        2.900                1.4         0.2 setosa  #> 10 4.900        3.100                1.5         0.1 setosa  #> # … with 140 more rows"},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Reverse the *_map_seq() process — reverse_map_seq","title":"Reverse the *_map_seq() process — reverse_map_seq","text":"reverse_map_seq() takes output function created function_map_seq() reconstructs original data frame. See audit_seq(), takes reverse_map_seq() basis.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reverse the *_map_seq() process — reverse_map_seq","text":"","code":"reverse_map_seq(data)"},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reverse the *_map_seq() process — reverse_map_seq","text":"data Data frame inherits \"scr_map_seq\" class.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reverse the *_map_seq() process — reverse_map_seq","text":"reconstructed tibble (data frame) factory-made *_map_seq() function took data argument.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reverse the *_map_seq() process — reverse_map_seq","text":"","code":"# Originally reported summary data... pigs1 #> # A tibble: 12 × 2 #>    x         n #>    <chr> <dbl> #>  1 7.22     32 #>  2 4.74     25 #>  3 5.23     29 #>  4 2.57     24 #>  5 6.77     27 #>  6 2.68     28 #>  7 7.01     29 #>  8 7.38     26 #>  9 3.14     27 #> 10 6.89     31 #> 11 5.00     25 #> 12 0.24     28  # ...GRIM-tested with varying inputs... out <- grim_map_seq(pigs1, include_consistent = TRUE)  # ...and faithfully reconstructed: reverse_map_seq(out) #> # A tibble: 12 × 2 #>    x         n #>    <chr> <dbl> #>  1 7.22     32 #>  2 4.74     25 #>  3 5.23     29 #>  4 2.57     24 #>  5 6.77     27 #>  6 2.68     28 #>  7 7.01     29 #>  8 7.38     26 #>  9 3.14     27 #> 10 6.89     31 #> 11 5.00     25 #> 12 0.24     28"},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_total_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Reverse the *_map_total_n() process — reverse_map_total_n","title":"Reverse the *_map_total_n() process — reverse_map_total_n","text":"reverse_map_total_n() takes output function created function_map_total_n() reconstructs original data frame. See audit_total_n(), takes reverse_map_total_n() basis.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_total_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reverse the *_map_total_n() process — reverse_map_total_n","text":"","code":"reverse_map_total_n(data)"},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_total_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reverse the *_map_total_n() process — reverse_map_total_n","text":"data Data frame inherits \"scr_map_total_n\" class.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_total_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reverse the *_map_total_n() process — reverse_map_total_n","text":"reconstructed tibble (data frame) factory-made *_map_total_n() function took data argument.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/reverse_map_total_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reverse the *_map_total_n() process — reverse_map_total_n","text":"","code":"# Originally reported summary data... df <- tibble::tribble(   ~x1,    ~x2,   ~n,   \"3.43\", \"5.28\", 90,   \"2.97\", \"4.42\", 103 ) df #> # A tibble: 2 × 3 #>   x1    x2        n #>   <chr> <chr> <dbl> #> 1 3.43  5.28     90 #> 2 2.97  4.42    103  # ...GRIM-tested with dispersed `n` values... out <- grim_map_total_n(df) out #> # A tibble: 48 × 8 #>    x         n n_change consistency both_consistent ratio  case dir   #>    <chr> <dbl>    <dbl> <lgl>       <lgl>           <dbl> <int> <chr> #>  1 3.43     45        0 FALSE       FALSE            0.55     1 forth #>  2 5.28     45        0 FALSE       FALSE            0.55     1 forth #>  3 3.43     44       -1 TRUE        TRUE             0.56     1 forth #>  4 5.28     46        1 TRUE        TRUE             0.54     1 forth #>  5 3.43     43       -2 FALSE       FALSE            0.57     1 forth #>  6 5.28     47        2 TRUE        FALSE            0.53     1 forth #>  7 3.43     42       -3 TRUE        FALSE            0.58     1 forth #>  8 5.28     48        3 FALSE       FALSE            0.52     1 forth #>  9 3.43     41       -4 FALSE       FALSE            0.59     1 forth #> 10 5.28     49        4 FALSE       FALSE            0.51     1 forth #> # … with 38 more rows  # ...and faithfully reconstructed: reverse_map_total_n(out) #> # A tibble: 2 × 3 #>   x1    x2        n #>   <chr> <chr> <dbl> #> 1 3.43  5.28     90 #> 2 2.97  4.42    103"},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-common.html","id":null,"dir":"Reference","previous_headings":"","what":"Common rounding procedures — rounding-common","title":"Common rounding procedures — rounding-common","text":"round_up() rounds 5, round_down() rounds 5. Otherwise, functions work like base::round(). round_up() round_down() special cases round_up_from() round_down_from(), allow users choose custom thresholds rounding , respectively.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-common.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Common rounding procedures — rounding-common","text":"","code":"round_up_from(x, digits = 0L, threshold, symmetric = FALSE)  round_down_from(x, digits = 0L, threshold, symmetric = FALSE)  round_up(x, digits = 0L, symmetric = FALSE)  round_down(x, digits = 0L, symmetric = FALSE)"},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-common.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common rounding procedures — rounding-common","text":"x Numeric. decimal number round. digits Integer. Number digits round x . Default 0. threshold Integer. round_up_from() round_down_from(). Threshold rounding , respectively. Value 5 round_up()'s internal call round_up_from() round_down()'s internal call round_down_from(). symmetric Boolean. Set symmetric TRUE rounding negative numbers mirror positive numbers absolute values equal. Default FALSE.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-common.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Common rounding procedures — rounding-common","text":"Numeric. x rounded digits.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-common.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Common rounding procedures — rounding-common","text":"functions differ base::round() mainly insofar decision rounding 5 based integer portion x (.e., \"rounding even\"). Instead, round_up_from(), decision determined threshold argument rounding , likewise round_down_from(). threshold constant 5 round_up() round_down(). result, functions predictable less prone floating-point number quirks base::round(). Compare round_down() base::round() data frame rounding 5 created Examples section : round_down() yields continuous sequence final digits 0 9, whereas base::round() behaves way can explained floating point issues. However, surprising behavior part base::round() necessarily flaw (see documentation, vignette: https://rpubs.com/maechler/Rounding). present version R (4.0.0 later), base::round() works fine, functions presented meant replace . main purpose helpers within scrutiny reconstruct computations researchers might used different software. example, SAS, SPSS, Stata, Matlab, Excel round 5, whereas Python rounds 5. use cases might possibly include journal requirements.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-common.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Common rounding procedures — rounding-common","text":"","code":"# Both `round_up()` and `round_down()` work like # `base::round()` unless the closest digit to be # cut off by rounding is 5:     round_up(x = 9.273, digits = 1)     # 7 cut off #> [1] 9.3  round_down(x = 9.273, digits = 1)     # 7 cut off #> [1] 9.3 base::round(x = 9.273, digits = 1)     # 7 cut off #> [1] 9.3     round_up(x = 7.584, digits = 2)     # 4 cut off #> [1] 7.58  round_down(x = 7.584, digits = 2)     # 4 cut off #> [1] 7.58 base::round(x = 7.584, digits = 2)     # 4 cut off #> [1] 7.58   # Here is the borderline case of 5 rounded by # `round_up()`, `round_down()`, and `base::round()`:  original <- c(     # Define example values     0.05, 0.15, 0.25, 0.35, 0.45,     0.55, 0.65, 0.75, 0.85, 0.95     ) tibble::tibble(        # Output table     original,     round_up = round_up(x = original, digits = 1),     round_down = round_down(x = original, digits = 1),     base_round = base::round(x = original, digits = 1)     ) #> # A tibble: 10 × 4 #>    original round_up round_down base_round #>       <dbl>    <dbl>      <dbl>      <dbl> #>  1     0.05      0.1        0          0   #>  2     0.15      0.2        0.1        0.1 #>  3     0.25      0.3        0.2        0.2 #>  4     0.35      0.4        0.3        0.3 #>  5     0.45      0.5        0.4        0.4 #>  6     0.55      0.6        0.5        0.6 #>  7     0.65      0.7        0.6        0.7 #>  8     0.75      0.8        0.7        0.8 #>  9     0.85      0.9        0.8        0.8 #> 10     0.95      1          0.9        0.9  # (Note: Defining `original` as `seq(0.05:0.95, by = 0.1)` # would lead to wrong results unless `original` is rounded # to 2 or so digits before it's rounded to 1.)"},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-uncommon.html","id":null,"dir":"Reference","previous_headings":"","what":"Uncommon rounding procedures — rounding-uncommon","title":"Uncommon rounding procedures — rounding-uncommon","text":"Always round , , toward zero, away : round_ceiling() always rounds . round_floor() always rounds . round_trunc() always rounds toward zero. round_anti_trunc() always rounds away zero. (0 rounded 1.) Despite widely used, featured case needed reconstruction.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-uncommon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uncommon rounding procedures — rounding-uncommon","text":"","code":"round_ceiling(x, digits = 0L)  round_floor(x, digits = 0L)  round_trunc(x, digits = 0L)  anti_trunc(x)  round_anti_trunc(x, digits = 0L)"},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-uncommon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uncommon rounding procedures — rounding-uncommon","text":"x Numeric. decimal number round. digits Integer. Number digits round x . Default 0.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-uncommon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uncommon rounding procedures — rounding-uncommon","text":"Numeric. x rounded digits (except anti_trunc(), digits argument).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-uncommon.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Uncommon rounding procedures — rounding-uncommon","text":"round_ceiling(), round_floor(), round_trunc() generalize base functions ceiling(), floor(), trunc(), include special cases: default value digits, 0, round_* functions equivalent respective base counterparts. last round_* function, round_anti_trunc(), generalizes another function presented : anti_trunc() works like trunc() except moves away 0, rather towards . , whereas trunc() minimizes absolute value x (compared rounding functions), anti_trunc() maximizes . anti_trunc(x) therefore equal trunc(x)  + 1 x positive, trunc(x) - 1 x negative. round_anti_trunc(), , generalizes anti_trunc() just round_ceiling() generalizes ceiling(), etc. Moreover, round_trunc() equivalent round_floor() positive numbers round_ceiling() negative numbers. reverse true round_anti_trunc(): equivalent round_ceiling() positive numbers round_floor() negative numbers.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding-uncommon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uncommon rounding procedures — rounding-uncommon","text":"","code":"# Always round up: round_ceiling(x = 4.52, digits = 1)        # 2 cut off #> [1] 4.6  # Always round down: round_floor(x = 4.67, digits = 1)          # 7 cut off #> [1] 4.6  # Always round toward 0: round_trunc(8.439, digits = 2)             # 9 cut off #> [1] 8.43 round_trunc(-8.439, digits = 2)            # 9 cut off #> [1] -8.43  # Always round away from 0: round_anti_trunc(x = 8.421, digits = 2)    # 1 cut off #> [1] 8.43 round_anti_trunc(x = -8.421, digits = 2)   # 1 cut off #> [1] -8.43"},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding_bias.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute rounding bias — rounding_bias","title":"Compute rounding bias — rounding_bias","text":"Rounding often leads bias, mean rounded distribution different mean original distribution. Call rounding_bias() compute amount bias.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding_bias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute rounding bias — rounding_bias","text":"","code":"rounding_bias(   x,   digits,   rounding = \"up\",   threshold = 5,   symmetric = FALSE,   mean = TRUE )"},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding_bias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute rounding bias — rounding_bias","text":"x Numeric string coercible numeric. digits Integer. Number decimal digits x rounded. rounding String. Rounding procedure applied x. See documentation grim(), section Rounding. Default \"\". threshold, symmetric arguments passed reround(). mean Boolean. TRUE (default), mean total bias returned. Set mean FALSE get vector individual biases length x.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding_bias.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute rounding bias — rounding_bias","text":"Numeric. default mean, length 1; otherwise, length x.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding_bias.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute rounding bias — rounding_bias","text":"Bias calculated subtracting original vector, x, vector rounded specified way. function passes arguments except mean reround(). , however, rounding \"\" default, set \"up_or_down\", \"up_from_or_down_from\", \"ceiling_or_floor\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/rounding_bias.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute rounding bias — rounding_bias","text":"","code":"# Define example vector: vec <- seq_distance(0.01, string_output = FALSE) vec #>  [1] 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10  # The default rounds `x` up from 5: rounding_bias(x = vec, digits = 1) #> [1] 0.005  # Other rounding procedures are supported, # such as rounding down from 5... rounding_bias(x = vec, digits = 1, rounding = \"down\") #> [1] -0.005  # ...or rounding to even with `base::round()`: rounding_bias(x = vec, digits = 1, rounding = \"even\") #> [1] -0.005"},{"path":"https://lhdjung.github.io/scrutiny/reference/row_to_colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn row values into column names — row_to_colnames","title":"Turn row values into column names — row_to_colnames","text":"Data frames sometimes wrong column names, correct column names stored one rows data frame . remedy issue, call row_to_colnames() data frame: replaces column names values specified rows (default, first one). rows dropped default.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/row_to_colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn row values into column names — row_to_colnames","text":"","code":"row_to_colnames(data, row = 1L, collapse = \" \", drop = TRUE)"},{"path":"https://lhdjung.github.io/scrutiny/reference/row_to_colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn row values into column names — row_to_colnames","text":"data Data frame matrix. row Integer. Position rows (one ) jointly contain correct column names. Default 1. collapse String. length row greater 1, new column name many row values pasted together. collapse, , substring two former row values final column names. Default \" \" (space). drop Boolean. TRUE (default), rows specified row removed.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/row_to_colnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn row values into column names — row_to_colnames","text":"tibble (data frame).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/row_to_colnames.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Turn row values into column names — row_to_colnames","text":"multiple rows specified, row values individual column pasted together. special characters might missing. function might useful importing tables PDF, e.g. tabulizer. R, data frames (converted matrices) sometimes issue described .","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/sd-binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard deviation of binary data — sd-binary","title":"Standard deviation of binary data — sd-binary","text":"Compute sample SD binary data (.e., 0 1 values) either four ways, based different inputs: sd_binary_groups() takes cell sizes groups, coded 0 coded 1. sd_binary_0_n() takes cell size group coded 0 total sample size. sd_binary_1_n() takes cell size group coded 1 total sample size. sd_binary_mean_n() takes mean total sample size. functions used helpers inside debit(), consequently debit_map().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/sd-binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard deviation of binary data — sd-binary","text":"","code":"sd_binary_groups(group_0, group_1)  sd_binary_0_n(group_0, n)  sd_binary_1_n(group_1, n)  sd_binary_mean_n(mean, n)"},{"path":"https://lhdjung.github.io/scrutiny/reference/sd-binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard deviation of binary data — sd-binary","text":"group_0 Integer. Cell size group coded 0. group_1 Integer. Cell size group coded 1. n Integer. Total sample size. mean Numeric. Mean binary data.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/sd-binary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard deviation of binary data — sd-binary","text":"Numeric. Sample standard deviation.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/sd-binary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard deviation of binary data — sd-binary","text":"Heathers, James . J., Brown, Nicholas J. L. 2019. DEBIT: Simple Consistency Test Binary Data. https://osf.io/5vb3u/.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/sd-binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standard deviation of binary data — sd-binary","text":"","code":"# If 127 values are coded as 0 and 153 as 1... sd_binary_groups(group_0 = 127, group_1 = 153) #> [1] 0.4987311  # ...so that n = 280: sd_binary_0_n(group_0 = 127, n = 280) #> [1] 0.4987311 sd_binary_1_n(group_1 = 153, n = 280) #> [1] 0.4987311  # If only the mean and total sample size are # given, or these are more convenient to use, # they still lead to the same result as above # if the mean is given with a sufficiently # large number of decimal places: sd_binary_mean_n(mean = 0.5464286, n = 280) #> [1] 0.4987311"},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-decimal.html","id":null,"dir":"Reference","previous_headings":"","what":"Sequence generation at decimal level — seq-decimal","title":"Sequence generation at decimal level — seq-decimal","text":"Functions provide smooth interface generating sequences based input values' decimal depth. function creates sequence step size one unit level input values' ultimate decimal digit (e.g., 2.45, 2.46, 2.47, ...): seq_endpoint() creates sequence one input value another. step size, goes value decimal places. seq_distance() takes starting point , instead endpoint, desired output length. step size, goes starting point default. seq_endpoint_df() seq_distance_df() variants create data frame. columns can added tibble::tibble(). Regular arguments respective non-df function, dot .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-decimal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sequence generation at decimal level — seq-decimal","text":"","code":"seq_endpoint(from, to, offset_from = 0L, offset_to = 0L, string_output = TRUE)  seq_distance(   from,   by = NULL,   length_out = 10L,   dir = 1,   offset_from = 0L,   string_output = TRUE )  seq_endpoint_df(   .from,   .to,   ...,   .offset_from = 0L,   .offset_to = 0L,   .string_output = TRUE )  seq_distance_df(   .from,   .by = NULL,   ...,   .length_out = 10L,   .dir = 1,   .offset_from = 0L,   .string_output = TRUE )"},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-decimal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sequence generation at decimal level — seq-decimal","text":", .Numeric (string coercible numeric). Starting point sequence. , .Numeric (string coercible numeric). Endpoint sequence. seq_endpoint() seq_endpoint_df(). offset_from, .offset_from Integer. set non-zero number, starting point offset many units level last decimal digit. Default 0. offset_to, .offset_to Integer. set non-zero number, endpoint offset many units level last decimal digit. Default 0. seq_endpoint() seq_endpoint_df(). string_output, .string_output Boolean string. TRUE (default), output string vector. Decimal places padded zeros match 's ('s) number decimal places. \"auto\" works like TRUE (.) string. , .Numeric. seq_distance() seq_distance_df(). Step size sequence. set, inferred automatically. Default NULL. length_out, .length_out Integer. Length output vector (.e., number values). Default 10. seq_distance() seq_distance_df(). dir, .dir Integer. set -1, sequence goes backward. Default 1. seq_distance() seq_distance_df(). ... columns, added tibble::tibble(). seq_endpoint_df() seq_distance_df().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-decimal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sequence generation at decimal level — seq-decimal","text":"String default string_output, numeric otherwise.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-decimal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sequence generation at decimal level — seq-decimal","text":"either ends zero, sure enter value string! crucial trailing zeros get dropped numeric values. handy way format numeric values number-strings correctly restore_zeros(). output present functions like default (string_output). seq_endpoint() seq_endpoint_df(), step size determined , whichever decimal places. seq_distance() seq_distance_df(), determined decimal places . functions scrutiny's take base::seq(), wrappers around .","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-decimal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sequence generation at decimal level — seq-decimal","text":"","code":"# Sequence between two points: seq_endpoint(from = 4.7, to = 5) #> [1] \"4.7\" \"4.8\" \"4.9\" \"5.0\"  # Sequence of some length; default is 10: seq_distance(from = 0.93) #>  [1] \"0.93\" \"0.94\" \"0.95\" \"0.96\" \"0.97\" \"0.98\" \"0.99\" \"1.00\" \"1.01\" \"1.02\" seq_distance(from = 0.93, length_out = 5) #> [1] \"0.93\" \"0.94\" \"0.95\" \"0.96\" \"0.97\"  # Both of these functions can offset the # starting point... seq_endpoint(from = 14.2, to = 15, offset_from = 4) #> [1] \"14.6\" \"14.7\" \"14.8\" \"14.9\" \"15.0\" seq_distance(from = 14.2, offset_from = 4) #>  [1] \"14.6\" \"14.7\" \"14.8\" \"14.9\" \"15.0\" \"15.1\" \"15.2\" \"15.3\" \"15.4\" \"15.5\"  # ...but only `seq_endpoint()` can offset the # endpoint, because of its `to` argument: seq_endpoint(from = 9.5, to = 10, offset_to = 2) #> [1] \"9.5\"  \"9.6\"  \"9.7\"  \"9.8\"  \"9.9\"  \"10.0\" \"10.1\" \"10.2\"  # In return, `seq_distance()` can reverse its direction: seq_distance(from = 20.03, dir = -1) #>  [1] \"20.03\" \"20.02\" \"20.01\" \"20.00\" \"19.99\" \"19.98\" \"19.97\" \"19.96\" \"19.95\" #> [10] \"19.94\"  # Both functions have a `_df` variant that returns # a data frame. Arguments are the same but with a # dot, and further columns can be added as in # `tibble::tibble()`: seq_endpoint_df(.from = 4.7, .to = 5, n = 20) #> # A tibble: 4 × 2 #>   x         n #>   <chr> <dbl> #> 1 4.7      20 #> 2 4.8      20 #> 3 4.9      20 #> 4 5.0      20 seq_distance_df(.from = 0.43, .length_out = 5, sd = 0.08) #> # A tibble: 5 × 2 #>   x        sd #>   <chr> <dbl> #> 1 0.43   0.08 #> 2 0.44   0.08 #> 3 0.45   0.08 #> 4 0.46   0.08 #> 5 0.47   0.08"},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-predicates.html","id":null,"dir":"Reference","previous_headings":"","what":"Is a vector a certain kind of sequence? — seq-predicates","title":"Is a vector a certain kind of sequence? — seq-predicates","text":"Predicate functions test whether x numeric vector (coercible numeric) special properties: is_seq_linear() tests whether every two consecutive elements x differ constant amount. is_seq_ascending() is_seq_descending() test whether difference every two consecutive values positive negative, respectively. is_seq_dispersed() tests whether x values grouped around specific central value, , distance sides per value pair. default (test_linear = TRUE), functions also test linearity, like is_seq_linear(). NA elements x handled nuanced way. See Value section examples vignette(\"infrastructure\"), section NA handling.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-predicates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is a vector a certain kind of sequence? — seq-predicates","text":"","code":"is_seq_linear(x, tolerance = .Machine$double.eps^0.5)  is_seq_ascending(x, test_linear = TRUE, tolerance = .Machine$double.eps^0.5)  is_seq_descending(x, test_linear = TRUE, tolerance = .Machine$double.eps^0.5)  is_seq_dispersed(   x,   from,   test_linear = TRUE,   tolerance = .Machine$double.eps^0.5 )"},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-predicates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is a vector a certain kind of sequence? — seq-predicates","text":"x Numeric coercible numeric, determined is_numeric_like(). Vector tested. tolerance Numeric. Tolerance comparison numbers testing. Default circa 0.000000015 (1.490116e-08), dplyr::near(). test_linear Boolean. functions is_seq_linear(), x also tested linearity? Default TRUE. Numeric coercible numeric. is_seq_dispersed(). test whether center x, every pair values equidistant .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-predicates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is a vector a certain kind of sequence? — seq-predicates","text":"single Boolean value. x contains least one NA element, functions return either NA FALSE: elements x NA, functions return NA. elements NA, check x might sequence kind question: linear (/ ascending, etc.) sequence NAs replaced appropriate values? , return NA; otherwise, return FALSE.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/seq-predicates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Is a vector a certain kind of sequence? — seq-predicates","text":"","code":"# These are linear sequences... is_seq_linear(x = 3:7) #> [1] TRUE is_seq_linear(x = c(3:7, 8)) #> [1] TRUE  # ...but these aren't: is_seq_linear(x = c(3:7, 9)) #> [1] FALSE is_seq_linear(x = c(10, 3:7)) #> [1] FALSE  # All other `is_seq_*()` functions # also test for linearity by default: is_seq_ascending(x = c(2, 7, 9)) #> [1] FALSE is_seq_ascending(x = c(2, 7, 9), test_linear = FALSE) #> [1] TRUE  is_seq_descending(x = c(9, 7, 2)) #> [1] FALSE is_seq_descending(x = c(9, 7, 2), test_linear = FALSE) #> [1] TRUE  is_seq_dispersed(x = c(2, 3, 5, 7, 8), from = 5) #> [1] FALSE is_seq_dispersed(x = c(2, 3, 5, 7, 8), from = 5, test_linear = FALSE) #> [1] TRUE  # These fail their respective # individual test even # without linearity testing: is_seq_ascending(x = c(1, 7, 4), test_linear = FALSE) #> [1] FALSE is_seq_descending(x = c(9, 15, 3), test_linear = FALSE) #> [1] FALSE is_seq_dispersed(1:10, from = 5, test_linear = FALSE) #> [1] FALSE"},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_disperse.html","id":null,"dir":"Reference","previous_headings":"","what":"Sequence generation with dispersion at decimal level — seq_disperse","title":"Sequence generation with dispersion at decimal level — seq_disperse","text":"seq_disperse() creates sequence around given number. goes specified number steps . Step size depends number's decimal places. example, 7.93 surrounded values like 7.91, 7.92, 7.94, 7.95, etc. seq_disperse_df() variant creates data frame. columns can added tibble::tibble(). Regular arguments seq_disperse(), dot .","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_disperse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sequence generation with dispersion at decimal level — seq_disperse","text":"","code":"seq_disperse(   from,   by = NULL,   dispersion = 1:5,   offset_from = 0L,   out_min = \"auto\",   out_max = NULL,   string_output = TRUE,   include_reported = TRUE,   track_var_change = FALSE )  seq_disperse_df(   .from,   .by = NULL,   ...,   .dispersion = 1:5,   .offset_from = 0L,   .out_min = \"auto\",   .out_max = NULL,   .string_output = TRUE,   .include_reported = TRUE,   .track_var_change = FALSE )"},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_disperse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sequence generation with dispersion at decimal level — seq_disperse","text":", .Numeric (string coercible numeric). Starting point sequence. , .Numeric. Step size sequence. set, inferred automatically. Default NULL. dispersion, .dispersion Numeric. Vector determines steps , starting (., respectively) proceeding level last decimal place. Default 1:5, .e., five steps . offset_from, .offset_from Integer. set non-zero number, starting point offset many units level last decimal digit. Default 0. out_min, .out_min, out_max, .out_max specified, output restricted out_min out_max. Defaults \"auto\" out_min, .e., minimum one decimal unit zero; NULL out_max, .e., maximum. string_output, .string_output Boolean string. TRUE (default), output string vector. Decimal places padded zeros match 's number decimal places. \"auto\" works like TRUE (.) string. include_reported, .include_reported Boolean. (.) part sequence built around ? Default TRUE sake continuity, can misleading focus dispersed values, opposed input. track_var_change, .track_var_change Boolean. seq_disperse(), ignore argument. seq_disperse_df(), default TRUE, creates \"var_change\" output column. ... columns, added tibble::tibble(). seq_disperse_df().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_disperse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sequence generation with dispersion at decimal level — seq_disperse","text":"seq_disperse() returns string vector default (string_output = TRUE) numeric otherwise. seq_disperse_df() returns tibble (data frame). sequence stored x column. x string default (.string_output = TRUE), numeric otherwise. columns might added via dots (...).","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_disperse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sequence generation with dispersion at decimal level — seq_disperse","text":"Unlike seq_endpoint() friends, present functions necessarily return continuous even regular sequences. greater flexibility due dispersion (.dispersion) argument, takes numeric vector. default, however, output sequence regular continuous. Underlying difference fact seq_disperse() seq_disperse_df() wrap around base::seq(), although otherwise similar seq_endpoint() friends.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_disperse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sequence generation with dispersion at decimal level — seq_disperse","text":"","code":"# Basic usage: seq_disperse(from = 4.02) #>  [1] \"3.97\" \"3.98\" \"3.99\" \"4.00\" \"4.01\" \"4.02\" \"4.03\" \"4.04\" \"4.05\" \"4.06\" #> [11] \"4.07\"  # If trailing zeros don't matter, # the output can be numeric: seq_disperse(from = 4.02, string_output = FALSE) #>  [1] 3.97 3.98 3.99 4.00 4.01 4.02 4.03 4.04 4.05 4.06 4.07  # Control steps up and down with # `dispersion` (default is `1:5`): seq_disperse(from = 4.02, dispersion = 1:10) #>  [1] \"3.92\" \"3.93\" \"3.94\" \"3.95\" \"3.96\" \"3.97\" \"3.98\" \"3.99\" \"4.00\" \"4.01\" #> [11] \"4.02\" \"4.03\" \"4.04\" \"4.05\" \"4.06\" \"4.07\" \"4.08\" \"4.09\" \"4.10\" \"4.11\" #> [21] \"4.12\"  # Sequences might be discontinuous... disp1 <- seq(from = 2, to = 10, by = 2) seq_disperse(from = 4.02, dispersion = disp1) #>  [1] \"3.92\" \"3.94\" \"3.96\" \"3.98\" \"4.00\" \"4.02\" \"4.04\" \"4.06\" \"4.08\" \"4.10\" #> [11] \"4.12\"  # ...or even irregular: disp2 <- c(2, 3, 7) seq_disperse(from = 4.02, dispersion = disp2) #> [1] \"3.95\" \"3.99\" \"4.00\" \"4.02\" \"4.04\" \"4.05\" \"4.09\"  # The data fame variant supports further # columns added as in `tibble::tibble()`: seq_disperse_df(.from = 4.02, n = 45) #> # A tibble: 11 × 2 #>    x         n #>    <chr> <dbl> #>  1 3.97     45 #>  2 3.98     45 #>  3 3.99     45 #>  4 4.00     45 #>  5 4.01     45 #>  6 4.02     45 #>  7 4.03     45 #>  8 4.04     45 #>  9 4.05     45 #> 10 4.06     45 #> 11 4.07     45"},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_length.html","id":null,"dir":"Reference","previous_headings":"","what":"Set sequence length — seq_length","title":"Set sequence length — seq_length","text":"seq_length() seamlessly extends shortens linear sequence using sequence's step size. Alternatively, can directly set length linear sequence way: seq_length(x) <- value.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_length.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set sequence length — seq_length","text":"","code":"seq_length(x, value)  seq_length(x) <- value"},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_length.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set sequence length — seq_length","text":"x Numeric coercible numeric. x must linear, .e., elements must differ next amount. value Numeric (whole number, length 1). new length x.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_length.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set sequence length — seq_length","text":"vector type x, length value. value > length(x), original element x preserved. number new elements equal difference appended end. value == length(x), nothing changes. value < length(x), number elements x equal difference removed end.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_length.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set sequence length — seq_length","text":"","code":"x <- 3:7  # Increase the length of `x` from 5 to 10: seq_length(x, 10) #>  [1]  3  4  5  6  7  8  9 10 11 12  # Modify `x` directly (but get # the same results otherwise): seq_length(x) <- 10 x #>  [1]  3  4  5  6  7  8  9 10 11 12  # Likewise, decrease the length: x <- 3:7 seq_length(x, 2) #> [1] 3 4  seq_length(x) <- 2 x #> [1] 3 4  # The functions are sensitive to decimal levels. # They also return a string vector if (and only if) # `x` is a string vector: x <- seq_endpoint(from = 0, to = 0.5) x #> [1] \"0.0\" \"0.1\" \"0.2\" \"0.3\" \"0.4\" \"0.5\"  seq_length(x, 10) #>  [1] \"0.0\" \"0.1\" \"0.2\" \"0.3\" \"0.4\" \"0.5\" \"0.6\" \"0.7\" \"0.8\" \"0.9\"  seq_length(x) <- 10 x #>  [1] \"0.0\" \"0.1\" \"0.2\" \"0.3\" \"0.4\" \"0.5\" \"0.6\" \"0.7\" \"0.8\" \"0.9\"  # Same with decreasing the length: seq_length(x, 2) #> [1] \"0.0\" \"0.1\"  seq_length(x) <- 2 x #> [1] \"0.0\" \"0.1\""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_test_ranking.html","id":null,"dir":"Reference","previous_headings":"","what":"Rank sequence test results — seq_test_ranking","title":"Rank sequence test results — seq_test_ranking","text":"Run function generating sequence seq_endpoint_df() seq_distance_df() testing one scrutiny's mapping functions, grim_map(). rank test's consistent inconsistent results positions sequence.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_test_ranking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rank sequence test results — seq_test_ranking","text":"","code":"seq_test_ranking(x, explain = TRUE)"},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_test_ranking.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rank sequence test results — seq_test_ranking","text":"x Data frame. explain TRUE (default), results come explanation.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_test_ranking.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rank sequence test results — seq_test_ranking","text":"tibble (data frame). function also print explanation results. See examples.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_test_ranking.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rank sequence test results — seq_test_ranking","text":"function checks provenance test results throws warning correct.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/seq_test_ranking.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rank sequence test results — seq_test_ranking","text":"","code":"seq_distance_df(.from = \"0.00\", n = 50) %>%   grim_map() %>%   seq_test_ranking() #> Explanation: #> ℹ There are 5 consistent value sets, starting with row number 1 in the data #>   frame created by `grim_map()`. #> ℹ All other value sets are inconsistent. #> ℹ The consistent sets lead the inconsistent ones by numbers of places from 1 to #>   1 in the `grim_map()` data frame. #> # A tibble: 5 × 3 #>   consistent inconsistent lead_lag #>        <int>        <int>    <int> #> 1          1            2        1 #> 2          3            4        1 #> 3          5            6        1 #> 4          7            8        1 #> 5          9           10        1"},{"path":"https://lhdjung.github.io/scrutiny/reference/split_by_parens.html","id":null,"dir":"Reference","previous_headings":"","what":"Split columns by parentheses, brackets, braces, or similar — split_by_parens","title":"Split columns by parentheses, brackets, braces, or similar — split_by_parens","text":"Summary statistics often presented like \"2.65 (0.27)\". working tables copied R, can tedious separate values inside parentheses. split_by_parens() automatically. default, operates columns. Output can optionally pivoted longer format setting transform TRUE. Choose separators parentheses sep argument.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/split_by_parens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split columns by parentheses, brackets, braces, or similar — split_by_parens","text":"","code":"split_by_parens(   data,   cols = everything(),   check_sep = TRUE,   keep = FALSE,   transform = FALSE,   sep = \"parens\",   end1 = \"x\",   end2 = \"sd\",   ... )"},{"path":"https://lhdjung.github.io/scrutiny/reference/split_by_parens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split columns by parentheses, brackets, braces, or similar — split_by_parens","text":"data Data frame. cols Select columns data using tidyselect. Default everything(), selects columns pass check_sep. check_sep Boolean. TRUE (default), columns excluded contain sep elements. keep Boolean. set TRUE, originally selected columns split function also appear output. Default FALSE. transform Boolean. set TRUE, output pivoted better suitable typical follow-tasks. Default FALSE. sep String. split . Either \"parens\", \"brackets\", \"braces\"; length-2 vector custom separators (see Examples). Default \"parens\". end1, end2 Strings. Endings two column names result splitting column. Default \"x\" end1 \"sd\" end2. ... dots must empty.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/split_by_parens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split columns by parentheses, brackets, braces, or similar — split_by_parens","text":"Data frame.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/split_by_parens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split columns by parentheses, brackets, braces, or similar — split_by_parens","text":"","code":"# Call `split_by_parens()` on data like these: df1 <- tibble::tribble(   ~drone,           ~selfpilot,   \"0.09 (0.21)\",    \"0.19 (0.13)\",   \"0.19 (0.28)\",    \"0.53 (0.10)\",   \"0.62 (0.16)\",    \"0.50 (0.11)\",   \"0.15 (0.35)\",    \"0.57 (0.16)\", )  # Basic usage: df1 %>%   split_by_parens() #> # A tibble: 4 × 4 #>   drone_x drone_sd selfpilot_x selfpilot_sd #>   <chr>   <chr>    <chr>       <chr>        #> 1 0.09    0.21     0.19        0.13         #> 2 0.19    0.28     0.53        0.10         #> 3 0.62    0.16     0.50        0.11         #> 4 0.15    0.35     0.57        0.16          # Name specific columns with `cols` to only split those: df1 %>%   split_by_parens(cols = drone) #> # A tibble: 4 × 3 #>   drone_x drone_sd selfpilot   #>   <chr>   <chr>    <chr>       #> 1 0.09    0.21     0.19 (0.13) #> 2 0.19    0.28     0.53 (0.10) #> 3 0.62    0.16     0.50 (0.11) #> 4 0.15    0.35     0.57 (0.16)  # Pivot the data into a longer format # by setting `transform` to `TRUE`: df1 %>%   split_by_parens(transform = TRUE) #> # A tibble: 8 × 3 #>   .origin   x     sd    #>   <chr>     <chr> <chr> #> 1 drone     0.09  0.21  #> 2 drone     0.19  0.28  #> 3 drone     0.62  0.16  #> 4 drone     0.15  0.35  #> 5 selfpilot 0.19  0.13  #> 6 selfpilot 0.53  0.10  #> 7 selfpilot 0.50  0.11  #> 8 selfpilot 0.57  0.16   # Choose different column names or # name suffixes with `end1` and `end2`: df1 %>%   split_by_parens(end1 = \"beta\", end2 = \"se\") #> # A tibble: 4 × 4 #>   drone_beta drone_se selfpilot_beta selfpilot_se #>   <chr>      <chr>    <chr>          <chr>        #> 1 0.09       0.21     0.19           0.13         #> 2 0.19       0.28     0.53           0.10         #> 3 0.62       0.16     0.50           0.11         #> 4 0.15       0.35     0.57           0.16          df1 %>%   split_by_parens(     transform = TRUE,     end1 = \"beta\", end2 = \"se\"   ) #> # A tibble: 8 × 3 #>   .origin   beta  se    #>   <chr>     <chr> <chr> #> 1 drone     0.09  0.21  #> 2 drone     0.19  0.28  #> 3 drone     0.62  0.16  #> 4 drone     0.15  0.35  #> 5 selfpilot 0.19  0.13  #> 6 selfpilot 0.53  0.10  #> 7 selfpilot 0.50  0.11  #> 8 selfpilot 0.57  0.16   # With a different separator... df2 <- tibble::tribble(   ~drone,           ~selfpilot,   \"0.09 [0.21]\",    \"0.19 [0.13]\",   \"0.19 [0.28]\",    \"0.53 [0.10]\",   \"0.62 [0.16]\",    \"0.50 [0.11]\",   \"0.15 [0.35]\",    \"0.57 [0.16]\", )  # ... specify `sep`: df2 %>%   split_by_parens(sep = \"brackets\") #> # A tibble: 4 × 4 #>   drone_x drone_sd selfpilot_x selfpilot_sd #>   <chr>   <chr>    <chr>       <chr>        #> 1 0.09    0.21     0.19        0.13         #> 2 0.19    0.28     0.53        0.10         #> 3 0.62    0.16     0.50        0.11         #> 4 0.15    0.35     0.57        0.16          # (Accordingly with `{}` and `\"braces\"`.)  # If the separator is yet a different one... df3 <- tibble::tribble(   ~drone,           ~selfpilot,   \"0.09 <0.21>\",    \"0.19 <0.13>\",   \"0.19 <0.28>\",    \"0.53 <0.10>\",   \"0.62 <0.16>\",    \"0.50 <0.11>\",   \"0.15 <0.35>\",    \"0.57 <0.16>\", )  # ... `sep` should be a length-2 vector # that contains the separating elements: df3 %>%   split_by_parens(sep = c(\"<\", \">\")) #> # A tibble: 4 × 4 #>   drone_x drone_sd selfpilot_x selfpilot_sd #>   <chr>   <chr>    <chr>       <chr>        #> 1 0.09    0.21     0.19        0.13         #> 2 0.19    0.28     0.53        0.10         #> 3 0.62    0.16     0.50        0.11         #> 4 0.15    0.35     0.57        0.16"},{"path":"https://lhdjung.github.io/scrutiny/reference/subset-superset.html","id":null,"dir":"Reference","previous_headings":"","what":"Test for subsets, supersets, and equal sets — subset-superset","title":"Test for subsets, supersets, and equal sets — subset-superset","text":"Predicate functions take vector test whether particular relation another vector. second vector entered either three ways -- Enter directly (basic functions): is_subset_of() tests vector subset another vector; .e., elements contained second one. is_superset_of() reverse: tests first vector contains elements second one. is_equal_set() tests vectors exactly values. Enter values: is_subset_of_vals(), is_superset_of_vals(), is_equal_set_vals() variants take single vector plus number arguments. treated like elements second vector basic functions . Enter multiple vectors jointly contain values: Finally, is_subset_of_vecs(), is_superset_of_vecs(), is_equal_set_vecs() take one vector plus number vectors treat elements (!) like elements second vector basic functions . is_subset*() function is_proper_subset*() variant. variants also test whether sets unequal, x subset y y subset x. applies is_superset*() functions is_proper_superset*() variants.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/subset-superset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for subsets, supersets, and equal sets — subset-superset","text":"","code":"is_subset_of(x, y)  is_superset_of(x, y)  is_equal_set(x, y)  is_proper_subset_of(x, y)  is_proper_superset_of(x, y)  is_subset_of_vals(x, ...)  is_superset_of_vals(x, ...)  is_equal_set_vals(x, ...)  is_proper_subset_of_vals(x, ...)  is_proper_superset_of_vals(x, ...)  is_subset_of_vecs(x, ...)  is_superset_of_vecs(x, ...)  is_equal_set_vecs(x, ...)  is_proper_subset_of_vecs(x, ...)  is_proper_superset_of_vecs(x, ...)"},{"path":"https://lhdjung.github.io/scrutiny/reference/subset-superset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for subsets, supersets, and equal sets — subset-superset","text":"x vector. y vector. basic functions, *_vals() *_vecs(). ... *_vals() functions, number values x might contain; *_vecs() functions, number vectors elements x might contain.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/subset-superset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test for subsets, supersets, and equal sets — subset-superset","text":"single Boolean value. TRUE respective test passed, FALSE otherwise.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/subset-superset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test for subsets, supersets, and equal sets — subset-superset","text":"*_vals() variants meant flexible, interactive subset/superset testing. , order test whether certain values collectively fulfill role second vector, can just add function call. *_vecs() variants likewise offer flexibility, also bridge gap vectors values contained . functions simply check values present, regardless often value occurs. words, look types count tokens.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/subset-superset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test for subsets, supersets, and equal sets — subset-superset","text":"","code":"# Define example vectors: ab <- c(\"a\", \"b\") abc <- c(\"a\", \"b\", \"c\") abcde <- c(\"a\", \"b\", \"c\", \"d\", \"e\")  # `is_subset_of()` tests if a vector is # completely covered by another one: abc %>% is_subset_of(ab) #> [1] FALSE abc %>% is_subset_of(abc) #> [1] TRUE abc %>% is_subset_of(abcde) #> [1] TRUE  # To the contrary, `is_superset_of()` tests if the # first vector completely covers the second one: abc %>% is_superset_of(ab) #> [1] TRUE abc %>% is_superset_of(abc) #> [1] TRUE abc %>% is_superset_of(abcde) #> [1] FALSE  # `is_equal_set()` tests both of the above -- # i.e., if both vectors have exactly the # same values: abc %>% is_equal_set(ab) #> [1] FALSE abc %>% is_equal_set(abc) #> [1] TRUE abc %>% is_equal_set(abcde) #> [1] FALSE  # Each of the three functions has a `*_vals()` variant # that doesn't take a second vector like the first # one, but any number of other arguments. These are # jointly treated like the elements of the second # vector in the basic functions: abc %>% is_subset_of_vals(\"a\", \"b\") #> [1] FALSE abc %>% is_subset_of_vals(\"a\", \"b\", \"c\") #> [1] TRUE abc %>% is_subset_of_vals(\"a\", \"b\", \"c\", \"d\", \"e\") #> [1] TRUE  # (... and likewise for supersets and equal sets.)"},{"path":"https://lhdjung.github.io/scrutiny/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported scrutiny rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way.   enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions).   simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data pronoun object represents current slice data. variable name string, use .data pronoun subset variable [[.   Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround.   Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually :   Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data %>%     group_by(...) %>%     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data %>%     group_by(!!!dots) %>%     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars %>% summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data %>%     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data %>%     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"},{"path":"https://lhdjung.github.io/scrutiny/reference/tidyeval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy eval helpers — tidyeval","text":"enquo() returns expression, enquos() returns list expressions. as_name() as_label() return string vector length 1. .data pronoun used within tidy eval functions. := return value. throw error called outside dynamic dots tidy eval function. See description learn functionality objects. (value section added scrutiny; rlang tidy eval developers.)","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/unnest_consistency_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Unnest a test result column — unnest_consistency_cols","title":"Unnest a test result column — unnest_consistency_cols","text":"Within consistency test mapper function, may become necessary unpack column resulting basic *_scalar() testing function. case show_* argument mapper function like show_rec grim_map() TRUE, *_scalar() function returns list values, just single value. point list stored data frame column (likely \"consistency\"), call unnest_consistency_cols() unnest results multiple columns.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/unnest_consistency_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unnest a test result column — unnest_consistency_cols","text":"","code":"unnest_consistency_cols(results, col_names, index = FALSE, col = \"consistency\")"},{"path":"https://lhdjung.github.io/scrutiny/reference/unnest_consistency_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unnest a test result column — unnest_consistency_cols","text":"results Data frame containing list-column name passed col. col_names String vector new names unnested columns. start string given col. index Boolean. list-column indexed ? Default FALSE. col String (length 1). Name list-column within results operate . Default \"consistency\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/unnest_consistency_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unnest a test result column — unnest_consistency_cols","text":"Data frame. column names determined col_names.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/unnest_consistency_cols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unnest a test result column — unnest_consistency_cols","text":"function custom workaround place tidyr::unnest_wider(), mirroring latter's functionality. created unnest_wider() can slow use helper function.","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/unround.html","id":null,"dir":"Reference","previous_headings":"","what":"Reconstruct rounding bounds — unround","title":"Reconstruct rounding bounds — unround","text":"unround() takes rounded number returns range original value: lower upper bounds hypothetical earlier number later rounded input number. also displays range inequation signs, showing whether bounds inclusive . default, presumed rounding method rounding () 5. See Rounding section methods.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/unround.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reconstruct rounding bounds — unround","text":"","code":"unround(x, rounding = \"up_or_down\", threshold = 5, digits = NULL)"},{"path":"https://lhdjung.github.io/scrutiny/reference/unround.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reconstruct rounding bounds — unround","text":"x String numeric. Rounded number. x must string unless digits specified (likely function uses unround() helper). rounding String. Rounding method presumably used create x. Default \"up_or_down\". , see section Rounding. threshold Integer. Number round . rounding methods affected. Default 5. digits Integer. argument meant make unround() efficient use helper function need redundantly count decimal places. specify otherwise. Default NULL, case decimal places really counted internally x must string.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/unround.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reconstruct rounding bounds — unround","text":"tibble seven columns: range, rounding, lower, incl_lower, x, incl_upper, upper. range column handy representation information stored columns lower upper, order.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/unround.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reconstruct rounding bounds — unround","text":"function vectorized x rounding. can useful unround multiple numbers , check single number unrounded different assumed rounding methods. vectors length greater 1, must length. However, pair numbers rounding methods, can confusing. recommended least one input vectors length 1. x need string digits specified? case, unround() must count decimal places . x numeric, trailing zeros get dropped numerics. Trailing zeros important reconstructing boundary values trailing digits . Strings drop trailing zeros, used instead.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/unround.html","id":"rounding","dir":"Reference","previous_headings":"","what":"Rounding","title":"Reconstruct rounding bounds — unround","text":"Depending x rounded, boundary values can inclusive exclusive. incl_lower incl_upper columns resulting tibble TRUE first case FALSE second. range column reflects equation inequation signs. However, ranges based assumptions way x rounded. Set rounding rounding method hypothetically lead x: Base R's round() (R version >= 4.0.0), referenced rounding = \"even\", reconstructed way \"up_or_down\", whether boundary values inclusive hard predict. Therefore, unround() checks , informs .","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/unround.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reconstruct rounding bounds — unround","text":"","code":"# By default, the function assumes that `x` # was either rounded up or down: unround(x = \"2.7\") #> # A tibble: 1 × 7 #>   range                  rounding   lower incl_lower x     incl_upper upper #>   <chr>                  <chr>      <dbl> <lgl>      <chr> <lgl>      <dbl> #> 1 2.65 <= x(2.7) <= 2.75 up_or_down  2.65 TRUE       2.7   TRUE        2.75  # If `x` was rounded up, run this: unround(x = \"2.7\", rounding = \"up\") #> # A tibble: 1 × 7 #>   range                 rounding lower incl_lower x     incl_upper upper #>   <chr>                 <chr>    <dbl> <lgl>      <chr> <lgl>      <dbl> #> 1 2.65 <= x(2.7) < 2.75 up        2.65 TRUE       2.7   FALSE       2.75  # Likewise with rounding down... unround(x = \"2.7\", rounding = \"down\") #> # A tibble: 1 × 7 #>   range                 rounding lower incl_lower x     incl_upper upper #>   <chr>                 <chr>    <dbl> <lgl>      <chr> <lgl>      <dbl> #> 1 2.65 < x(2.7) <= 2.75 down      2.65 FALSE      2.7   TRUE        2.75  # ...and with `base::round()` which, broadly # speaking, rounds to the nearest even number: unround(x = \"2.7\", rounding = \"even\") #> # A tibble: 1 × 7 #>   range                rounding lower incl_lower x     incl_upper upper #>   <chr>                <chr>    <dbl> <lgl>      <chr> <lgl>      <dbl> #> 1 2.65 < x(2.7) < 2.75 even      2.65 FALSE      2.7   FALSE       2.75  # Multiple input number-strings return # multiple rows in the output data frame: unround(x = c(3.6, \"5.20\", 5.174)) #> # A tibble: 3 × 7 #>   range                        rounding   lower incl_lower x     incl_up…¹ upper #>   <chr>                        <chr>      <dbl> <lgl>      <chr> <lgl>     <dbl> #> 1 3.55 <= x(3.6) <= 3.65       up_or_down  3.55 TRUE       3.6   TRUE       3.65 #> 2 5.195 <= x(5.20) <= 5.205    up_or_down  5.20 TRUE       5.20  TRUE       5.20 #> 3 5.1735 <= x(5.174) <= 5.1745 up_or_down  5.17 TRUE       5.174 TRUE       5.17 #> # … with abbreviated variable name ¹​incl_upper"},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit.html","id":null,"dir":"Reference","previous_headings":"","what":"Documentation template for audit() — write_doc_audit","title":"Documentation template for audit() — write_doc_audit","text":"write_doc_audit() creates roxygen2 block section inserted documentation mapper function grim_map() debit_map(): functions , , audit() methods. section informs users ways audit() summarizes results respective mapper function. Copy output console paste roxygen2 block *_map() function. preserve numbered list structure indenting roxygen2 comments Ctrl+Shift+/, leave empty lines pasted output rest block.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Documentation template for audit() — write_doc_audit","text":"","code":"write_doc_audit(sample_output, name_test)"},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Documentation template for audit() — write_doc_audit","text":"sample_output Data frame. Result call audit() data frame resulted call mapper function wrote audit() method, audit(grim_map(pigs1)) audit(debit_map(pigs3)). name_test String (length 1). Name consistency test mapper function applies, \"GRIM\" \"DEBIT\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Documentation template for audit() — write_doc_audit","text":"string vector formatted glue::glue().","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Documentation template for audit() — write_doc_audit","text":"","code":"# Start by running `audit()`: out_grim  <- audit(grim_map(pigs1)) out_debit <- audit(debit_map(pigs3))  out_grim #> # A tibble: 1 × 7 #>   incons_cases all_cases incons_rate mean_grim_ratio incons_to…¹ testa…² testa…³ #>          <int>     <int>       <dbl>           <dbl>       <dbl>   <int>   <dbl> #> 1            8        12       0.667           0.724       0.921      12       1 #> # … with abbreviated variable names ¹​incons_to_ratio, ²​testable_cases, #> #   ³​testable_rate out_debit #> # A tibble: 1 × 6 #>   incons_cases all_cases incons_rate mean_x mean_sd distinct_n #>          <int>     <int>       <dbl>  <dbl>   <dbl>      <int> #> 1            1         7       0.143  0.474   0.403          1  # Documenting the `audit()` method for `grim_map()`: write_doc_audit(sample_output = out_grim, name_test = \"GRIM\") #> #' @section Summaries with `audit()`: There is an S3 method for `audit()`, so  #> #'   you can call `audit()` following `grim_map()` to get a summary of  #> #'   `grim_map()`'s results. It is a tibble with a single row and these  #> #'   columns --  #> #'  #> #' 1. `incons_cases`: number of GRIM-inconsistent value sets. #> #' 2. `all_cases`: total number of value sets. #> #' 3. `incons_rate`: proportion of GRIM-inconsistent value sets. #> #' 4. `mean_grim_ratio`:  #> #' 5. `incons_to_ratio`:  #> #' 6. `testable_cases`:  #> #' 7. `testable_rate`:   # Documenting the `audit()` method for `debit_map()`: write_doc_audit(sample_output = out_debit, name_test = \"DEBIT\") #> #' @section Summaries with `audit()`: There is an S3 method for `audit()`, so  #> #'   you can call `audit()` following `debit_map()` to get a summary of  #> #'   `debit_map()`'s results. It is a tibble with a single row and these  #> #'   columns --  #> #'  #> #' 1. `incons_cases`: number of DEBIT-inconsistent value sets. #> #' 2. `all_cases`: total number of value sets. #> #' 3. `incons_rate`: proportion of DEBIT-inconsistent value sets. #> #' 4. `mean_x`:  #> #' 5. `mean_sd`:  #> #' 6. `distinct_n`:"},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Documentation template for audit_seq() — write_doc_audit_seq","title":"Documentation template for audit_seq() — write_doc_audit_seq","text":"write_doc_audit_seq() creates roxygen2 block section inserted documentation functions created function_map_seq(). section informs users ways audit_seq() summarizes results manufactured *_map_seq() function. Copy output console paste roxygen2 block *_map_seq() function. preserve bullet-point structure indenting roxygen2 comments Ctrl+Shift+/, leave empty lines pasted output rest block.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Documentation template for audit_seq() — write_doc_audit_seq","text":"","code":"write_doc_audit_seq(key_args, name_test)"},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Documentation template for audit_seq() — write_doc_audit_seq","text":"key_args String vector names key columns tested consistency *_map_seq() function. values need order function's output. name_test String (length 1). Name consistency test *_map_seq() function applies, \"GRIM\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Documentation template for audit_seq() — write_doc_audit_seq","text":"string vector formatted glue::glue().","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Documentation template for audit_seq() — write_doc_audit_seq","text":"","code":"# For GRIM and `grim_map_seq()`: write_doc_audit_seq(key_args = c(\"x\", \"n\"), name_test = \"GRIM\") #> #' @section Summaries with `audit_seq()`: You can call `audit_seq()` following  #> #'   `grim_map_seq()`. It will return a data frame with these columns:  #> #'   - `x` and `n` are the original inputs,  #> #'   tested for `consistency` here.  #> #'   - `hits_total` is the total number of GRIM-consistent value sets  #> #'   found within the specified `dispersion` range.  #> #'   - `hits_x` is the number of GRIM-consistent value sets  #> #'   found by varying `x`.  #> #'   - Accordingly with `n` and `hits_n`.  #> #'   - (Note that any consistent reported cases will be counted by the  #> #'   `hits_*` columns if both `include_reported` and `include_consistent`  #> #'   are set to `TRUE`.)  #> #'   - `diff_x` reports the absolute difference between `x` and the next  #> #'   consistent dispersed value (in dispersion steps, not the actual numeric  #> #'   difference). `diff_x_up` and `diff_x_down` report the difference to the  #> #'   next higher or lower consistent value, respectively.  #> #'   - `diff_n`, `diff_n_up`, and `diff_n_down` do the same for `n`.  #> #'  #> #'   Call `audit()` following `audit_seq()` to summarize results even further.   # For DEBIT and `debit_map_seq()`: write_doc_audit_seq(key_args = c(\"x\", \"sd\", \"n\"), name_test = \"DEBIT\") #> #' @section Summaries with `audit_seq()`: You can call `audit_seq()` following  #> #'   `debit_map_seq()`. It will return a data frame with these columns:  #> #'   - `x`, `sd`, and `n` are the original inputs,  #> #'   tested for `consistency` here.  #> #'   - `hits_total` is the total number of DEBIT-consistent value sets  #> #'   found within the specified `dispersion` range.  #> #'   - `hits_x` is the number of DEBIT-consistent value sets  #> #'   found by varying `x`.  #> #'   - Accordingly with `sd` and `hits_sd` as well as `n` and `hits_n`.  #> #'   - (Note that any consistent reported cases will be counted by the  #> #'   `hits_*` columns if both `include_reported` and `include_consistent`  #> #'   are set to `TRUE`.)  #> #'   - `diff_x` reports the absolute difference between `x` and the next  #> #'   consistent dispersed value (in dispersion steps, not the actual numeric  #> #'   difference). `diff_x_up` and `diff_x_down` report the difference to the  #> #'   next higher or lower consistent value, respectively.  #> #'   - `diff_sd`, `diff_sd_up`, and `diff_sd_down` do the same for `sd`.  #> #'   -  Likewise with `diff_n`, `diff_n_up`, and `diff_n_down`.  #> #'  #> #'   Call `audit()` following `audit_seq()` to summarize results even further."},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_total_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Documentation template for audit_total_n() — write_doc_audit_total_n","title":"Documentation template for audit_total_n() — write_doc_audit_total_n","text":"write_doc_audit_total_n() creates roxygen2 block section inserted documentation functions created function_map_total_n(). section informs users ways audit_seq() summarizes results manufactured *_map_total_n() function. Copy output console paste roxygen2 block *_map_total_n() function. preserve bullet-point structure indenting roxygen2 comments Ctrl+Shift+/, leave empty lines pasted output rest block.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_total_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Documentation template for audit_total_n() — write_doc_audit_total_n","text":"","code":"write_doc_audit_total_n(key_args, name_test)"},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_total_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Documentation template for audit_total_n() — write_doc_audit_total_n","text":"key_args String vector names key columns tested consistency *_map_seq() function. (original variable names, without \"1\" \"2\" suffixes.) values need order function's output. name_test String (length 1). Name consistency test *_map_seq() function applies, \"GRIM\".","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_total_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Documentation template for audit_total_n() — write_doc_audit_total_n","text":"string vector formatted glue::glue().","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_audit_total_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Documentation template for audit_total_n() — write_doc_audit_total_n","text":"","code":"# For GRIM and `grim_map_total_n()`: write_doc_audit_total_n(key_args = c(\"x\", \"n\"), name_test = \"GRIM\") #> #' @section Summaries with `audit_total_n()`: You can call  #> #'   `audit_total_n()` following up on `grim_map_total_n()`  #> #'   to get a tibble with summary statistics. It will have these columns:  #> #'  - `x1`, `x2`, and `n` are the original inputs.  #> #'  - `hits_total` is the number of scenarios in which both  #> #'  `x1` and `x2` are GRIM-consistent. It is the sum  #> #'  of `hits_forth` and `hits_back` below.  #> #'  - `hits_forth` is the number of both-consistent cases that result  #> #'  from pairing `x2` with the larger dispersed `n` value.  #> #'  - `hits_back` is the same, except `x1` is  #> #'  paired with the larger dispersed `n` value.  #> #'  - `scenarios_total` is the total number of test scenarios,  #> #'  whether or not both `x1` and `x2`  #> #'  are GRIM-consistent.  #> #'  - `hit_rate` is the ratio of `hits_total` to `scenarios_total`.  #> #'  #> #'  Call `audit()` following `audit_total_n()` to summarize results  #> #'  even further.   # For DEBIT and `debit_map_total_n()`: write_doc_audit_total_n(key_args = c(\"x\", \"sd\", \"n\"), name_test = \"DEBIT\") #> #' @section Summaries with `audit_total_n()`: You can call  #> #'   `audit_total_n()` following up on `debit_map_total_n()`  #> #'   to get a tibble with summary statistics. It will have these columns:  #> #'  - `x1`, `x2`, `sd1`, `sd2`, and `n` are the original inputs.  #> #'  - `hits_total` is the number of scenarios in which all of  #> #'  `x1`, `x2`, `sd1`, and `sd2` are DEBIT-consistent. It is the sum  #> #'  of `hits_forth` and `hits_back` below.  #> #'  - `hits_forth` is the number of both-consistent cases that result  #> #'  from pairing `x2` and `sd2` with the larger dispersed `n` value.  #> #'  - `hits_back` is the same, except `x1` and `sd1` are  #> #'  paired with the larger dispersed `n` value.  #> #'  - `scenarios_total` is the total number of test scenarios,  #> #'  whether or not both `x1` and `sd1` as well as `x2` and `sd2`  #> #'  are DEBIT-consistent.  #> #'  - `hit_rate` is the ratio of `hits_total` to `scenarios_total`.  #> #'  #> #'  Call `audit()` following `audit_total_n()` to summarize results  #> #'  even further."},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_factory_map_conventions.html","id":null,"dir":"Reference","previous_headings":"","what":"Documentation template for *_map() function factory conventions — write_doc_factory_map_conventions","title":"Documentation template for *_map() function factory conventions — write_doc_factory_map_conventions","text":"write_doc_factory_map_conventions() creates roxygen2 block section inserted documentation function factory function_map_seq() function_map_total_n(). lays naming guidelines users function factory follow creating new manufactured functions. Copy output console paste roxygen2 block function factory.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_factory_map_conventions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Documentation template for *_map() function factory conventions — write_doc_factory_map_conventions","text":"","code":"write_doc_factory_map_conventions(   ending,   name_test1 = \"GRIM\",   name_test2 = \"DEBIT\" )"},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_factory_map_conventions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Documentation template for *_map() function factory conventions — write_doc_factory_map_conventions","text":"ending String (length 1). part function factory's name function_map_. name_test1, name_test2 Strings (length 1). Plain-text names example consistency tests. Defaults \"GRIM\" \"DEBIT\", respectively.","code":""},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_factory_map_conventions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Documentation template for *_map() function factory conventions — write_doc_factory_map_conventions","text":"string vector formatted glue::glue().","code":""},{"path":[]},{"path":"https://lhdjung.github.io/scrutiny/reference/write_doc_factory_map_conventions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Documentation template for *_map() function factory conventions — write_doc_factory_map_conventions","text":"","code":"# For `function_map_seq()`: write_doc_factory_map_conventions(ending = \"seq\") #> #' @section Conventions: The name of a function manufactured with  #> #'   `function_map_seq()` should mechanically follow from that of the input  #> #'   function. For example, `grim_map_seq()` derives from `grim_map()`.  #> #'   This pattern fits best if the input function itself is named after the test  #> #'   it performs on a data frame, followed by `_map`: `grim_map()` applies GRIM,  #> #'   `debit_map()` applies DEBIT, etc.  #> #'  #> #'   Much the same is true for the classes of data frames returned by the  #> #'   manufactured function via the `.name_class` argument of  #> #'   `function_map_seq()`. It should be the function's own name preceded by  #> #'   the name of the package that contains it or by an acronym of that package's  #> #'   name. In this way, existing classes are `scr_grim_map_seq` and  #> #'   `scr_debit_map_seq`.   # For `function_map_total_n()`: write_doc_factory_map_conventions(ending = \"total_n\") #> #' @section Conventions: The name of a function manufactured with  #> #'   `function_map_total_n()` should mechanically follow from that of the input  #> #'   function. For example, `grim_map_total_n()` derives from `grim_map()`.  #> #'   This pattern fits best if the input function itself is named after the test  #> #'   it performs on a data frame, followed by `_map`: `grim_map()` applies GRIM,  #> #'   `debit_map()` applies DEBIT, etc.  #> #'  #> #'   Much the same is true for the classes of data frames returned by the  #> #'   manufactured function via the `.name_class` argument of  #> #'   `function_map_total_n()`. It should be the function's own name preceded by  #> #'   the name of the package that contains it or by an acronym of that package's  #> #'   name. In this way, existing classes are `scr_grim_map_total_n` and  #> #'   `scr_debit_map_total_n`."},{"path":"https://lhdjung.github.io/scrutiny/news/index.html","id":"scrutiny-024","dir":"Changelog","previous_headings":"","what":"scrutiny 0.2.4","title":"scrutiny 0.2.4","text":"CRAN release: 2023-01-20 New decimal_places_df() function takes data frame counts decimal places numeric-like columns. Four new predicate functions centered around is_map_df() test whether object output scrutiny-style mapper function consistency tests. Newly exported is_numeric_like() function test whether object (e.g., string vector) can coerced numeric. New grim_ratio_upper() function gives upper bound grim_ratio(). function now uses cols argument instead dots (...). follows tidyselect development guidelines. default, cols = everything(), select columns contain sep elements (default, parentheses). Set new check_sep argument FALSE select columns regardless. arguments renamed: longer start dot. Furthermore, .col1 .col2 renamed end1 end2. warning now issued one columns can’t split (de-selected splitting). occurs column doesn’t contain sep elements. Internal changes compatibility dplyr 1.1.0. restore_zeros_df() well, dots (...) replaced cols argument, argument longer prefix dot. follows changes split_by_parens(), note default selection restrictions new check_numeric_like argument. optional check_decimals argument goes even . Prevent false-positive warnings printing ggplot objects (occurred since ggplot2 3.4.0).","code":""},{"path":"https://lhdjung.github.io/scrutiny/news/index.html","id":"scrutiny-023","dir":"Changelog","previous_headings":"","what":"scrutiny 0.2.3","title":"scrutiny 0.2.3","text":"CRAN release: 2022-12-11 new features bugfixes: New audit() methods output audit_seq() audit_total_n(). New duplicate_count_colpair() function checks combination columns data frame duplicates. New restore_zeros_df() function easily restore trailing zeros numeric-like columns data frame. New seq_length() function extend shorten linear sequences. Bugfixes is_seq_*() functions. Argument evaluation now forced function factories: function_map(), function_map_seq(), function_map_total_n(). possible corner case issues split_by_parens() now prevented. Internal changes compatibility purrr 1.0.0 tidyselect 1.2.0.","code":""},{"path":"https://lhdjung.github.io/scrutiny/news/index.html","id":"scrutiny-022","dir":"Changelog","previous_headings":"","what":"scrutiny 0.2.2","title":"scrutiny 0.2.2","text":"CRAN release: 2022-08-22 patch CRAN compliance. package now requires R version >= 3.4.0 rlang version >= 1.0.2. Subtle changes split_by_parens() users generally won’t notice. Minor shifts documentation (e.g., vignette(\"consistency-tests\") now instructions exporting factory-made functions.).","code":""},{"path":"https://lhdjung.github.io/scrutiny/news/index.html","id":"scrutiny-021","dir":"Changelog","previous_headings":"","what":"scrutiny 0.2.1","title":"scrutiny 0.2.1","text":"patch. reduces scope examples CRAN compliance. Minor vignette changes.","code":""},{"path":"https://lhdjung.github.io/scrutiny/news/index.html","id":"scrutiny-020","dir":"Changelog","previous_headings":"","what":"scrutiny 0.2.0","title":"scrutiny 0.2.0","text":"massive release, many new features improvements scrutiny. notably, package now includes entirely new system implementing consistency tests. new vignette lays implement consistency tests using scrutiny’s infrastructure. describes many features mentioned . GRIMMER support added, explained another new vignette. GRIM DEBIT functions mentioned GRIMMER analogues. example, grimmer_map_seq() analogous grim_map_seq(). new, stricter rules consistency tests, output grim_map() longer includes items column default. Instead, numbers items (1 default) factored output’s n column. focuses presentation essence GRIM. GRIM DEBIT functions now somewhat less likely flag value sets inconsistent. measures taken reduce spurious, computer-induced differences comparing floating-point numbers. applies new GRIMMER functions. function_map() enables users quickly create consistency test functions data frames much like grim_map() debit_map(). grim_map_seq() checks GRIM inconsistencies might due small errors, true values might close reported ones. varies inputs specified range, holding respective ones constant, tests combinations. summaries, call audit_seq() results. debit_map_seq() DEBIT. two powered function_map_seq(), allows users easily create functions just like consistency test. ’s needed data-frame-level consistency testing function like grim_map() debit_map(). grim_map_total_n() applies GRIM cases group sizes reported, total sample sizes. systematically matches possible group sizes (around half total) reported mean proportion values, GRIM-tests , counts scenarios matches consistent. summaries, call audit_total_n() results. debit_map_total_n() DEBIT. two powered function_map_total_n(), allows users easily create new functions like grim_map_total_n() debit_map_total_n(), provided data-frame-level consistency testing function like grim_map() debit_map(). lower level still, disperse_total() takes total sample size (comprised two unknown group sizes interest) calls appropriate group-level function: disperse() even totals, disperse2() odd ones. seq_disperse() seq_disperse_df() extend scrutiny’s support string decimal sequences trailing zeros. construct sequences centered around input; use case directly covered base::seq(). Predicate functions around is_seq_linear() test whether vector represents certain kind numeric sequence. debit_map(), x column now left sd column show_rec FALSE, accordance show_rec = TRUE default. debit() now vectorized. functions around is_subset_of() is_superset_of() functions now stricter variants grouped around is_proper_subset_of() is_proper_superset_of(). split_by_parens() now accepts pair separators passed .sep length-2 vector.","code":""},{"path":"https://lhdjung.github.io/scrutiny/news/index.html","id":"scrutiny-011","dir":"Changelog","previous_headings":"","what":"scrutiny 0.1.1","title":"scrutiny 0.1.1","text":"patch, mainly fixing bug used affect presentation input data grim_map()’s results. needs emphasized bug affected convenience feature, namely presentation certain input data output, GRIM test . Previously, percent set TRUE, x values converted percentages. need presented strings, percentage conversion involves restoring correct number trailing zeros. bug, , x values appearing output (internal computations!) restored “length” single longest one. now remedied, x values restored individually appropriate number trailing zeros. Another bugfix concerns versioning. Previously, package incorrect version number. now corrected. last change remove outdated potentially misleading paragraph documentation reround_to_fraction().","code":""},{"path":"https://lhdjung.github.io/scrutiny/news/index.html","id":"scrutiny-010","dir":"Changelog","previous_headings":"","what":"scrutiny 0.1.0","title":"scrutiny 0.1.0","text":"version includes overhaul grim_plot(): extends function cover cases decimals values greater 2, using gradient instead raster. enables data-free calls grim_plot() new show_data argument. Resulting plots display background raster. mirrors Figure 1 Brown Heathers’ GRIM paper. (Although grim_plot() whole modeled figure, default addition empirical summary data specific scrutiny.) Like Brown Heathers, users may wish create raster-plots order demonstrate principled points. key parameters decimals rounding can controlled directly make lack information data. function now checks input means proportions (x) number decimal places. don’t, throws error. strict criterion can circumvented specifying decimals argument. However, since raster specific one number decimal places (hence interpreted regarding x values different number), recommended solution plot x values separately — number decimal places. show_full_range argument removed now think superfluous. Previously, space raster y-axis. now removed. Test result data points, shown blue /red default, now built top raster, makes distinct appearance. Two new functions, reround_to_fraction(), reround_to_fraction_level(), enable fractional rounding, inspired janitor::round_to_fraction(). example, might round 0.4 0.5 fractions 2. tells new functions apart come flexibility reround(). Furthermore, reround_to_fraction_level() closer conventional rounding function two. new version also fixes bug row_to_colnames(), rewriting function’s core. Another bug fixed grim() grim_map(), concerning show_rec: rounding strings lead four reconstructed numbers per x value rather just two, used case two values corresponding first two rounding procedures displayed output tibble. Now, four displayed, bearing appropriate names. Another bugfix threshold argument reround(), didn’t work properly . used affect higher-level functions grim(), grim_map(), debit(), debit_map(), well. default threshold now 5 functions. Note rounding 5 fully functional independently . Also reround(), rec argument renamed x accordance general naming conventions. decimals argument renamed digits accordance naming conventions among rounding functions. split_by_parens(), ellipsis support added protect user silent, unexpected results following named arguments tidy evaluation. ellipsis package added Suggests field DESCRIPTION. high-level functions, internal checks now determine lengths multiple arguments factored internal function call mutually congruent. , two arguments length > 1, need length (throw warning). Otherwise, explicit specific error message. Finally, minor refactoring small changes users generally won’t notice.","code":""},{"path":"https://lhdjung.github.io/scrutiny/news/index.html","id":"scrutiny-001","dir":"Changelog","previous_headings":"","what":"scrutiny 0.0.1","title":"scrutiny 0.0.1","text":"Added vignette packages error detection, called Related software. Exported grim_plot(). Minor refactoring.","code":""},{"path":"https://lhdjung.github.io/scrutiny/news/index.html","id":"scrutiny-0009000","dir":"Changelog","previous_headings":"","what":"scrutiny 0.0.0.9000","title":"scrutiny 0.0.0.9000","text":"Added NEWS.md file track changes package.","code":""}]
